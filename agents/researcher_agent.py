"""
Researcher Agent - –∞–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –ø–æ –≥—Ä–∞–Ω—Ç–æ–≤—ã–º –∑–∞—è–≤–∫–∞–º
"""
import sys
import os
from typing import Dict, Any, List
import logging
import asyncio

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –º–æ–¥—É–ª—è–º
sys.path.append('/var/GrantService/shared')
sys.path.append('/var/GrantService/telegram-bot/services')

from .base_agent import BaseAgent

try:
    from llm.unified_llm_client import UnifiedLLMClient
    from llm.config import AGENT_CONFIGS
    UNIFIED_CLIENT_AVAILABLE = True
except ImportError:
    UNIFIED_CLIENT_AVAILABLE = False
    UnifiedLLMClient = None
    AGENT_CONFIGS = {}

try:
    from services.llm_router import LLMRouter, LLMProvider
    LLM_ROUTER_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è LLM Router –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    LLMRouter = None
    LLMProvider = None
    LLM_ROUTER_AVAILABLE = False

logger = logging.getLogger(__name__)

class ResearcherAgent(BaseAgent):
    """–ê–≥–µ–Ω—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞ –∏ –ø–æ–∏—Å–∫–∞ –≥—Ä–∞–Ω—Ç–æ–≤"""
    
    def __init__(self, db, llm_provider: str = "auto"):
        super().__init__("researcher", db, llm_provider)
        
        if UNIFIED_CLIENT_AVAILABLE:
            self.llm_client = UnifiedLLMClient()
            self.config = AGENT_CONFIGS.get("researcher", AGENT_CONFIGS.get("writer", {}))
        elif LLM_ROUTER_AVAILABLE:
            self.llm_router = LLMRouter()
        else:
            self.llm_client = None
            self.llm_router = None
            print("‚ö†Ô∏è Researcher –∞–≥–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ LLM —Å–µ—Ä–≤–∏—Å–æ–≤")
    
    def _get_goal(self) -> str:
        return "–ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä—ã–Ω–∫–∞, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ –≥—Ä–∞–Ω—Ç–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"
    
    def _get_backstory(self) -> str:
        return """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —Ä—ã–Ω–∫–∞ —Å 15-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º –≤ –æ–±–ª–∞—Å—Ç–∏ –≥—Ä–∞–Ω—Ç–æ–≤–æ–≥–æ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è. 
        –¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—à—å—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π. 
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–≤–µ—Å—Ç–∏ –≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏ –Ω–∞–π—Ç–∏ –ª—É—á—à–∏–µ –≥—Ä–∞–Ω—Ç–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏."""
    
    async def research_grant_async(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            description = data.get('description', '')
            llm_provider = data.get('llm_provider', 'auto')
            model = data.get('model', 'auto')
            temperature = data.get('temperature', 0.3)
            max_tokens = data.get('max_tokens', 1000)
            
            logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞: {description[:100]}...")
            
            if UNIFIED_CLIENT_AVAILABLE:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º UnifiedLLMClient
                config = AGENT_CONFIGS.get("researcher", AGENT_CONFIGS["writer"])
                
                async with UnifiedLLMClient(
                    provider=config["provider"],
                    model=config["model"],
                    temperature=config["temperature"]
                ) as client:
                    
                    prompt = f"""
                    –ü—Ä–æ–≤–µ–¥–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏:
                    
                    {description}
                    
                    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:
                    1. –†—ã–Ω–æ—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª
                    2. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—É—é —Å—Ä–µ–¥—É
                    3. –ì—Ä–∞–Ω—Ç–æ–≤—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
                    4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∑–∞—è–≤–∫–∏
                    
                    –î–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.
                    """
                    
                    result_text = await client.generate_text(prompt, config["max_tokens"])
                    
                    return {
                        'status': 'success',
                        'result': result_text,
                        'agent_type': 'researcher',
                        'provider_used': config["provider"],
                        'input_data': description,
                        'llm_settings': {
                            'provider': config["provider"],
                            'model': config["model"],
                            'temperature': config["temperature"],
                            'max_tokens': config["max_tokens"]
                        }
                    }
            else:
                # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É
                return self.research_grant(data)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
            return {
                'status': 'error',
                'message': f"–û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {str(e)}",
                'agent_type': 'researcher',
                'provider_used': llm_provider if 'llm_provider' in locals() else 'unknown'
            }
    
    def research_grant(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏ (fallback)"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            description = data.get('description', '')
            llm_provider = data.get('llm_provider', 'auto')
            model = data.get('model', 'auto')
            temperature = data.get('temperature', 0.3)
            max_tokens = data.get('max_tokens', 1000)
            
            logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞: {description[:100]}...")
            
            if not UNIFIED_CLIENT_AVAILABLE:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                if llm_provider == "auto":
                    target_provider = None  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä
                elif llm_provider == "gigachat":
                    target_provider = LLMProvider.GIGACHAT
                elif llm_provider == "local":
                    target_provider = LLMProvider.LOCAL
                else:
                    target_provider = None
                
                # –ü—Ä–æ–≤–æ–¥–∏–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM Router
                result = self.llm_router.analyze_grant_application(
                    application_text=description,
                    grant_criteria="–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä—ã–Ω–∫–∞, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ –≥—Ä–∞–Ω—Ç–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π",
                    preferred_provider=target_provider
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                result['agent_type'] = 'researcher'
                result['input_data'] = description
                result['llm_settings'] = {
                    'provider': llm_provider,
                    'model': model,
                    'temperature': temperature,
                    'max_tokens': max_tokens
                }
                
                logger.info(f"‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {result.get('provider_used', 'Unknown')}")
                
                return result
            else:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                return asyncio.run(self.research_grant_async(data))
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
            return {
                'status': 'error',
                'message': f"–û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {str(e)}",
                'agent_type': 'researcher',
                'provider_used': llm_provider if 'llm_provider' in locals() else 'unknown'
            }
    
    def analyze_market(self, project_description: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            prompt = f"""
–ü—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞:

{project_description}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:
1. –†–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞
2. –ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –æ—Ç—Ä–∞—Å–ª–∏
3. –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è
4. –†—ã–Ω–æ—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
5. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏

–î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Ñ–∞–∫—Ç—ã.
"""
            
            if UNIFIED_CLIENT_AVAILABLE:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º UnifiedLLMClient
                config = AGENT_CONFIGS.get("researcher", AGENT_CONFIGS["writer"])
                
                async def analyze_async():
                    async with UnifiedLLMClient(
                        provider=config["provider"],
                        model=config["model"],
                        temperature=config["temperature"]
                    ) as client:
                        return await client.generate_text(prompt, config["max_tokens"])
                
                result_text = asyncio.run(analyze_async())
                
                return {
                    'status': 'success',
                    'result': result_text,
                    'agent_type': 'researcher',
                    'provider_used': config["provider"]
                }
            else:
                # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É
                result = self.llm_router.analyze_grant_application(
                    application_text=project_description,
                    grant_criteria="–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π —Å—Ä–µ–¥—ã"
                )
                return result
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞: {e}")
            return {
                'status': 'error',
                'message': f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞: {str(e)}",
                'agent_type': 'researcher'
            }
    
    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        return self.research_grant(data)
    
    def research_anketa(self, anketa_id: str) -> Dict[str, Any]:
        """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∫–µ—Ç—ã"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∫–µ—Ç—É –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            anketa = self.db.get_session_by_anketa_id(anketa_id)
            
            if not anketa:
                return {
                    'status': 'error',
                    'message': f'–ê–Ω–∫–µ—Ç–∞ {anketa_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞',
                    'agent_type': 'researcher'
                }
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_data = {
                "telegram_id": anketa["telegram_id"],
                "username": anketa.get("username"),
                "first_name": anketa.get("first_name"),
                "last_name": anketa.get("last_name")
            }
            
            # –ü—Ä–æ–≤–æ–¥–∏–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤—å—é –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            interview_text = ""
            if isinstance(anketa["interview_data"], dict):
                for key, value in anketa["interview_data"].items():
                    interview_text += f"{key}: {value}\n"
            else:
                interview_text = str(anketa["interview_data"])
            
            research_results = self.research_grant({
                "description": interview_text,
                "llm_provider": "perplexity"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Perplexity –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
            })
            
            if research_results.get('status') == 'error':
                return research_results
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            research_data = {
                "anketa_id": anketa_id,
                "user_data": user_data,
                "session_id": anketa["id"],
                "research_type": "comprehensive",
                "llm_provider": research_results.get('provider_used', 'perplexity'),
                "model": research_results.get('llm_settings', {}).get('model', 'sonar'),
                "research_results": research_results.get('result', ''),
                "metadata": {
                    "tokens_used": research_results.get('llm_settings', {}).get('tokens_used', 0),
                    "processing_time_seconds": research_results.get('processing_time', 0),
                    "cost": research_results.get('cost', 0.0)
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            research_id = self.db.save_research_results(research_data)
            
            if research_id:
                return {
                    'status': 'success',
                    'research_id': research_id,
                    'anketa_id': anketa_id,
                    'result': research_results.get('result', ''),
                    'agent_type': 'researcher',
                    'provider_used': research_results.get('provider_used', 'perplexity')
                }
            else:
                return {
                    'status': 'error',
                    'message': '–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è',
                    'agent_type': 'researcher'
                }
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∞–Ω–∫–µ—Ç—ã {anketa_id}: {e}")
            return {
                'status': 'error',
                'message': f"–û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∞–Ω–∫–µ—Ç—ã: {str(e)}",
                'agent_type': 'researcher'
            }