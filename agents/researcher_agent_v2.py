#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Researcher Agent V2 - –∞–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —á–µ—Ä–µ–∑ 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê (–æ–±–Ω–æ–≤–ª–µ–Ω–æ 2025-10-11, v2.3):
- Database-Driven: WebSearch –ø—Ä–æ–≤–∞–π–¥–µ—Ä —á–∏—Ç–∞–µ—Ç—Å—è –∏–∑ ai_agent_settings.config.websearch_provider
- WebSearchRouter: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —Å fallback (Perplexity ‚Üí Claude Code)
- –ù–ï —Ö–∞—Ä–¥–∫–æ–¥–∏–º: –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ UI, –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- DatabasePromptManager –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ 27 –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –ë–î (3 –±–ª–æ–∫–∞: 10+10+7)
- WebSearchRouter –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ WebSearch –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
  - Perplexity API (primary): ~$0.01/–∑–∞–ø—Ä–æ—Å, —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–∑ –†–§, 100% success rate
  - Claude Code WebSearch (fallback): –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- researcher_research —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSONB

–ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è v2.3:
- –ó–∞–º–µ–Ω–µ–Ω PerplexityWebSearchClient –Ω–∞ WebSearchRouter
- –ü—Ä–æ–≤–∞–π–¥–µ—Ä —á–∏—Ç–∞–µ—Ç—Å—è –∏–∑ –ë–î —á–µ—Ä–µ–∑ get_agent_settings('researcher')
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ fallback —á–µ—Ä–µ–∑ websearch_fallback config
- Metadata —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∞–ª—å–Ω—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä

–ê–≤—Ç–æ—Ä: AI Integration Specialist
–î–∞—Ç–∞: 2025-10-11
–í–µ—Ä—Å–∏—è: 2.3
"""

import sys
import os
from typing import Dict, Any, List, Optional
import logging
import asyncio
import time
from datetime import datetime
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –º–æ–¥—É–ª—è–º
sys.path.append('/var/GrantService/shared')
sys.path.append('/var/GrantService/agents')
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ web-admin (—Å –¥–µ—Ñ–∏—Å–æ–º)
current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, 'web-admin'))

from agents.base_agent import BaseAgent
from agents.prompt_loader import ResearcherPromptLoader  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è fallback
from shared.llm.websearch_router import WebSearchRouter

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º DatabasePromptManager
try:
    from utils.prompt_manager import DatabasePromptManager, get_database_prompt_manager
    PROMPT_MANAGER_AVAILABLE = True
except ImportError:
    print("[WARN] DatabasePromptManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ResearcherPromptLoader")
    PROMPT_MANAGER_AVAILABLE = False

logger = logging.getLogger(__name__)


class ResearcherAgentV2(BaseAgent):
    """
    Researcher Agent V2: 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥—Ä–∞–Ω—Ç–æ–≤—ã—Ö –∑–∞—è–≤–æ–∫

    Workflow:
    1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–∫–µ—Ç—É –∏–∑ –ë–î
    2. –ò–∑–≤–ª–µ—á—å placeholders —á–µ—Ä–µ–∑ PromptLoader
    3. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 27 –∑–∞–ø—Ä–æ—Å–æ–≤ (–±–ª–æ–∫ 1: 10, –±–ª–æ–∫ 2: 10, –±–ª–æ–∫ 3: 7)
    4. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ PerplexityWebSearchClient (Perplexity API)
    5. –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSONB —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    6. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ researcher_research.research_results

    NOTE: Switched from Claude Code WebSearch to Perplexity API due to geographical restrictions
    """

    def __init__(self, db, llm_provider: str = "claude_code", websearch_provider: str = None, websearch_fallback: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞

        Args:
            db: Database instance
            llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é claude_code)
            websearch_provider: WebSearch –ø—Ä–æ–≤–∞–π–¥–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ None - —á–∏—Ç–∞–µ—Ç—Å—è –∏–∑ –ë–î)
            websearch_fallback: WebSearch fallback (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ None - —á–∏—Ç–∞–µ—Ç—Å—è –∏–∑ –ë–î)
        """
        super().__init__("researcher_v2", db, llm_provider)

        # –ï—Å–ª–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∞–ø—Ä—è–º—É—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
        if websearch_provider:
            self.websearch_provider = websearch_provider
            self.websearch_fallback = websearch_fallback or 'perplexity'
            logger.info(f"[ResearcherAgentV2] WebSearch provider (from params): {self.websearch_provider}")
            logger.info(f"[ResearcherAgentV2] WebSearch fallback (from params): {self.websearch_fallback}")
        else:
            # –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ WebSearch –∏–∑ –ë–î (–ù–ï –∑–∞—Ö–∞—Ä–¥–∫–æ–∂–µ–Ω—ã!)
            try:
                # –ò–º–ø–æ—Ä—Ç –∏–∑ web-admin (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–µ—Ñ–∏—Å–æ–º)
                import importlib.util
                utils_path = os.path.join(current_dir, 'web-admin', 'utils', 'agent_settings.py')
                spec = importlib.util.spec_from_file_location("agent_settings", utils_path)
                agent_settings_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(agent_settings_module)
                get_agent_settings = agent_settings_module.get_agent_settings

                settings = get_agent_settings('researcher')
                config = settings.get('config', {})

                # WebSearch –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–ù–ï —Ö–∞—Ä–¥–∫–æ–¥!)
                self.websearch_provider = config.get('websearch_provider', 'perplexity')
                self.websearch_fallback = config.get('websearch_fallback', 'claude_code')

                logger.info(f"[ResearcherAgentV2] WebSearch provider from DB: {self.websearch_provider}")
                logger.info(f"[ResearcherAgentV2] WebSearch fallback from DB: {self.websearch_fallback}")

            except Exception as e:
                logger.warning(f"[ResearcherAgentV2] Failed to load WebSearch settings from DB: {e}")
                logger.info("[ResearcherAgentV2] Using defaults: websearch_provider=claude_code, NO fallback (Claude Code ONLY policy)")
                self.websearch_provider = 'claude_code'
                self.websearch_fallback = None  # NO fallback - Claude Code ONLY

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DatabasePromptManager
        self.prompt_manager: Optional[DatabasePromptManager] = None
        if PROMPT_MANAGER_AVAILABLE:
            try:
                self.prompt_manager = get_database_prompt_manager()
                logger.info("[OK] Researcher V2: DatabasePromptManager connected (27 queries from DB)")
            except Exception as e:
                logger.warning(f"[WARN] Could not initialize PromptManager: {e}")

        logger.info(f"[OK] ResearcherAgentV2 initialized with WebSearchRouter (provider={self.websearch_provider})")

    def _get_goal(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å goal –∞–≥–µ–Ω—Ç–∞ –∏–∑ –ë–î —Å fallback"""
        if self.prompt_manager:
            try:
                goal = self.prompt_manager.get_prompt('researcher_v2', 'goal')
                if goal:
                    return goal
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ goal –∏–∑ –ë–î: {e}")

        # Fallback –Ω–∞ hardcoded
        return "–ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö WebSearch –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏"

    def _get_backstory(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å backstory –∞–≥–µ–Ω—Ç–∞ –∏–∑ –ë–î —Å fallback"""
        if self.prompt_manager:
            try:
                backstory = self.prompt_manager.get_prompt('researcher_v2', 'backstory')
                if backstory:
                    return backstory
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ backstory –∏–∑ –ë–î: {e}")

        # Fallback –Ω–∞ hardcoded
        return """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å —Å 15-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –≤ –≥—Ä–∞–Ω—Ç–æ–≤–æ–º –∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥–µ.
        –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –ø–æ–∏—Å–∫ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, –∞–Ω–∞–ª–∏–∑ –≥–æ—Å–ø—Ä–æ–≥—Ä–∞–º–º, –∏–∑—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–µ—à—å —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: –†–æ—Å—Å—Ç–∞—Ç, –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞, –Ω–∞—Ü–ø—Ä–æ–µ–∫—Ç—ã."""

    async def research_with_expert_prompts(self, anketa_id: str) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏

        Args:
            anketa_id: ID –∞–Ω–∫–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            {
                'research_id': 'RES-...',
                'status': 'completed',
                'research_results': {
                    'block1_problem': {...},
                    'block2_geography': {...},
                    'block3_goals': {...},
                    'metadata': {...}
                }
            }
        """
        start_time = time.time()

        try:
            logger.info(f"üîç –ó–∞–ø—É—Å–∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è anketa_id={anketa_id}")

            # 1. –ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∫–µ—Ç—É –∏–∑ –ë–î
            anketa = await self._get_anketa(anketa_id)
            if not anketa:
                raise ValueError(f"Anketa {anketa_id} not found")

            logger.info(f"‚úÖ –ê–Ω–∫–µ—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: user_id={anketa.get('user_id', anketa.get('telegram_id'))}")

            # 2. –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å –≤ researcher_research (status='pending')
            research_id = await self._create_research_record(anketa_id, anketa)
            logger.info(f"üìù –°–æ–∑–¥–∞–Ω–∞ –∑–∞–ø–∏—Å—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {research_id}")

            # 3. –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ 'processing'
            await self._update_research_status(research_id, 'processing')

            # 4. –ò–∑–≤–ª–µ—á—å placeholders
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ResearcherPromptLoader —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è placeholders
            loader = ResearcherPromptLoader()
            placeholders = loader.extract_placeholders(anketa)

            logger.info(f"üìã Placeholders –∏–∑–≤–ª–µ—á–µ–Ω—ã:")
            logger.info(f"   - –ü–†–û–ë–õ–ï–ú–ê: {placeholders['–ü–†–û–ë–õ–ï–ú–ê'][:50]}...")
            logger.info(f"   - –†–ï–ì–ò–û–ù: {placeholders['–†–ï–ì–ò–û–ù']}")
            logger.info(f"   - –°–§–ï–†–ê: {placeholders['–°–§–ï–†–ê']}")

            # 5. –ó–∞–≥—Ä—É–∑–∏—Ç—å 27 –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –ë–î (DatabasePromptManager) –∏–ª–∏ fallback –Ω–∞ PromptLoader
            all_queries = await self._load_queries_from_db_or_fallback(placeholders)

            logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
            logger.info(f"   - –ë–ª–æ–∫ 1: {len(all_queries['block1'])} –∑–∞–ø—Ä–æ—Å–æ–≤")
            logger.info(f"   - –ë–ª–æ–∫ 2: {len(all_queries['block2'])} –∑–∞–ø—Ä–æ—Å–æ–≤")
            logger.info(f"   - –ë–ª–æ–∫ 3: {len(all_queries['block3'])} –∑–∞–ø—Ä–æ—Å–æ–≤")

            # 6. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ WebSearchRouter (—á–∏—Ç–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ë–î!)
            async with WebSearchRouter(self.db) as websearch_router:

                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ API
                healthy = await websearch_router.check_health()
                if not healthy:
                    logger.warning(f"[WARN] WebSearch provider {self.websearch_provider} not responding, attempting to continue...")

                # –ë–õ–û–ö 1: –ü—Ä–æ–±–ª–µ–º–∞ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (10 –∑–∞–ø—Ä–æ—Å–æ–≤)
                logger.info("üîç –ë–õ–û–ö 1: –ü—Ä–æ–±–ª–µ–º–∞ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (10 –∑–∞–ø—Ä–æ—Å–æ–≤)")
                block1_results = await self._execute_block_queries(
                    block_name="block1_problem",
                    queries=all_queries['block1'],
                    websearch_client=websearch_router,  # Router –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞!
                    allowed_domains=[
                        'rosstat.gov.ru',
                        'fedstat.ru',
                        'government.ru',
                        'nationalprojects.ru',
                        f"{placeholders.get('–ü–†–û–§–ò–õ–¨–ù–û–ï_–ú–ò–ù–ò–°–¢–ï–†–°–¢–í–û', 'minsport')}.gov.ru",
                        'edu.gov.ru',
                        'minzdrav.gov.ru'
                    ],
                    placeholders=placeholders
                )

                logger.info(f"‚úÖ –ë–ª–æ–∫ 1 –∑–∞–≤–µ—Ä—à—ë–Ω: {block1_results['total_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

                # üíæ –°–û–•–†–ê–ù–ò–¢–¨ –î–ê–ù–ù–´–ï –ë–õ–û–ö–ê 1 –°–†–ê–ó–£!
                await self._save_block_results(research_id, 'block1_problem', block1_results)

                # –ë–õ–û–ö 2: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è (10 –∑–∞–ø—Ä–æ—Å–æ–≤)
                logger.info("üåç –ë–õ–û–ö 2: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è (10 –∑–∞–ø—Ä–æ—Å–æ–≤)")
                block2_results = await self._execute_block_queries(
                    block_name="block2_geography",
                    queries=all_queries['block2'],
                    websearch_client=websearch_router,  # Router –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞!
                    allowed_domains=[
                        'rosstat.gov.ru',
                        'fedstat.ru',
                        'government.gov.ru',
                        f"{placeholders['–†–ï–ì–ò–û–ù'].lower().replace(' ', '')}.gov.ru",  # –†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä—Ç–∞–ª
                        'minjust.gov.ru',
                        'asi.ru'
                    ],
                    placeholders=placeholders
                )

                logger.info(f"‚úÖ –ë–ª–æ–∫ 2 –∑–∞–≤–µ—Ä—à—ë–Ω: {block2_results['total_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

                # üíæ –°–û–•–†–ê–ù–ò–¢–¨ –î–ê–ù–ù–´–ï –ë–õ–û–ö–ê 2 –°–†–ê–ó–£!
                await self._save_block_results(research_id, 'block2_geography', block2_results)

                # –ë–õ–û–ö 3: –ó–∞–¥–∞—á–∏, –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –≥–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å (7 –∑–∞–ø—Ä–æ—Å–æ–≤)
                logger.info("üéØ –ë–õ–û–ö 3: –ó–∞–¥–∞—á–∏, –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –≥–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å (7 –∑–∞–ø—Ä–æ—Å–æ–≤)")
                block3_results = await self._execute_block_queries(
                    block_name="block3_goals",
                    queries=all_queries['block3'],
                    websearch_client=websearch_router,  # Router –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞!
                    allowed_domains=[
                        'rosstat.gov.ru',
                        'government.ru',
                        'nationalprojects.ru',
                        'asi.ru'
                    ],
                    placeholders=placeholders
                )

                logger.info(f"‚úÖ –ë–ª–æ–∫ 3 –∑–∞–≤–µ—Ä—à—ë–Ω: {block3_results['total_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

                # üíæ –°–û–•–†–ê–ù–ò–¢–¨ –î–ê–ù–ù–´–ï –ë–õ–û–ö–ê 3 –°–†–ê–ó–£!
                await self._save_block_results(research_id, 'block3_goals', block3_results)

                # –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–µ—Å–ª–∏ –º–µ—Ç–æ–¥ –¥–æ—Å—Ç—É–ø–µ–Ω)
                client_stats = {}
                if hasattr(websearch_router, 'get_statistics'):
                    try:
                        client_stats = await websearch_router.get_statistics()
                    except:
                        pass

            # 7. –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            processing_time = time.time() - start_time

            research_results = {
                'block1_problem': block1_results,
                'block2_geography': block2_results,
                'block3_goals': block3_results,
                'metadata': {
                    'total_queries': 27,
                    'sources_count': (
                        block1_results['total_sources'] +
                        block2_results['total_sources'] +
                        block3_results['total_sources']
                    ),
                    'blocks': {
                        'block1': {
                            'queries': len(all_queries['block1']),
                            'sources': block1_results['total_sources'],
                            'processing_time': block1_results['processing_time']
                        },
                        'block2': {
                            'queries': len(all_queries['block2']),
                            'sources': block2_results['total_sources'],
                            'processing_time': block2_results['processing_time']
                        },
                        'block3': {
                            'queries': len(all_queries['block3']),
                            'sources': block3_results['total_sources'],
                            'processing_time': block3_results['processing_time']
                        }
                    },
                    'total_processing_time': int(processing_time),
                    'websearch_provider': self.websearch_provider,  # –ß–∏—Ç–∞–µ—Ç—Å—è –∏–∑ –ë–î!
                    'websearch_fallback': self.websearch_fallback,  # Fallback provider
                    'websearch_stats': client_stats
                }
            }

            # 8. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î
            await self._update_research_results(
                research_id=research_id,
                status='completed',
                research_results=research_results,
                completed_at=datetime.now()
            )

            logger.info(f"‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            logger.info(f"   - Research ID: {research_id}")
            logger.info(f"   - –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: 27")
            logger.info(f"   - –í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {research_results['metadata']['sources_count']}")
            logger.info(f"   - –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}s")

            # üìÑ –û–¢–ü–†–ê–í–ö–ê PDF –í –ê–î–ú–ò–ù–°–ö–ò–ô –ß–ê–¢
            try:
                await self._send_research_pdf_to_admin(
                    research_id=research_id,
                    anketa_id=anketa_id,
                    research_results=research_results,
                    queries=all_queries
                )
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ PDF –≤ –∞–¥–º–∏–Ω—Å–∫–∏–π —á–∞—Ç: {e}")
                # –ù–µ –ø–∞–¥–∞–µ–º –µ—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å - —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ

            return {
                'research_id': research_id,
                'status': 'completed',
                'research_results': research_results
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}", exc_info=True)

            # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ 'error'
            if 'research_id' in locals():
                await self._update_research_status(
                    research_id,
                    'error',
                    error_message=str(e)
                )

            return {
                'research_id': locals().get('research_id'),
                'status': 'error',
                'error': str(e)
            }

    async def _get_anketa(self, anketa_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∫–µ—Ç—É –∏–∑ –ë–î"""
        try:
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∫–µ—Ç—ã
            anketa = self.db.get_session_by_anketa_id(anketa_id)

            if not anketa:
                # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π SQL –∑–∞–ø—Ä–æ—Å
                with self.db.connect() as conn:
                    cursor = conn.cursor()
                    cursor.execute("SELECT * FROM sessions WHERE anketa_id = %s LIMIT 1", (anketa_id,))
                    row = cursor.fetchone()
                    if row:
                        anketa = self.db._dict_row(cursor, row)
                    cursor.close()

            return anketa

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∫–µ—Ç—ã {anketa_id}: {e}")
            return None

    async def _load_queries_from_db_or_fallback(self, placeholders: Dict) -> Dict[str, List[str]]:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å 27 –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –ë–î –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback –Ω–∞ PromptLoader

        Args:
            placeholders: –°–ª–æ–≤–∞—Ä—å —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏

        Returns:
            {'block1': [...], 'block2': [...], 'block3': [...]}
        """
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –ë–î —á–µ—Ä–µ–∑ DatabasePromptManager
        if self.prompt_manager:
            try:
                logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –ë–î...")

                # –ü–æ–ª—É—á–∏—Ç—å —à–∞–±–ª–æ–Ω—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
                block1_templates = self.prompt_manager.get_researcher_queries(1)
                block2_templates = self.prompt_manager.get_researcher_queries(2)
                block3_templates = self.prompt_manager.get_researcher_queries(3)

                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –ë–î: {len(block1_templates)} + {len(block2_templates)} + {len(block3_templates)} = {len(block1_templates) + len(block2_templates) + len(block3_templates)} –∑–∞–ø—Ä–æ—Å–æ–≤")

                # –ü—Ä–∏–º–µ–Ω–∏—Ç—å placeholders –∫ —à–∞–±–ª–æ–Ω–∞–º
                block1_queries = [template.format(**placeholders) for template in block1_templates]
                block2_queries = [template.format(**placeholders) for template in block2_templates]
                block3_queries = [template.format(**placeholders) for template in block3_templates]

                return {
                    'block1': block1_queries,
                    'block2': block2_queries,
                    'block3': block3_queries
                }

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –ë–î: {e}")
                logger.info("Fallback –Ω–∞ ResearcherPromptLoader...")

        # Fallback –Ω–∞ PromptLoader (hardcoded queries)
        logger.info("üì• –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ResearcherPromptLoader (fallback)...")
        loader = ResearcherPromptLoader()
        all_queries = loader.get_all_queries(placeholders)

        return all_queries

    async def _create_research_record(self, anketa_id: str, anketa: Dict) -> str:
        """–°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –ë–î —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–æ–π"""
        # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†–ê: anketa_id-RS-001
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º research_id —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ –ë–î (–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞: #AN-DATE-username-NNN-RS-NNN)
        # –ü—Ä–∏–º–µ—Ä—ã: #AN-20251008-ekaterina_maksimova-001-RS-001

        user_id = anketa.get('user_id', anketa.get('telegram_id', 0))
        session_id = anketa.get('id', anketa.get('session_id'))

        research_data = {
            # –ù–ï –ø–µ—Ä–µ–¥–∞—ë–º research_id - db.save_research_results —Å–∞–º —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ generate_research_id()
            'anketa_id': anketa_id,
            'user_id': user_id,
            'session_id': session_id,
            'research_type': 'expert_websearch_27_queries',
            'llm_provider': self.websearch_provider,  # –ß–∏—Ç–∞–µ—Ç—Å—è –∏–∑ –ë–î!
            'model': 'router',  # WebSearchRouter –≤–º–µ—Å—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
            'status': 'pending',
            'created_at': datetime.now(),
            'research_results': {}
        }

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥ –ë–î
        saved_id = self.db.save_research_results(research_data)

        # –í–ê–ñ–ù–û: –í–æ–∑–≤—Ä–∞—â–∞–µ–º ID –∏–∑ –ë–î, –∞ –Ω–µ –ª–æ–∫–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é!
        return saved_id

    async def _update_research_status(
        self,
        research_id: str,
        status: str,
        error_message: Optional[str] = None
    ):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        try:
            with self.db.connect() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    UPDATE researcher_research
                    SET status = %s
                    WHERE research_id = %s
                    """,
                    (status, research_id)
                )
                conn.commit()
                cursor.close()

            logger.info(f"üìù –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª—ë–Ω: {research_id} ‚Üí {status}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")

    async def _update_research_results(
        self,
        research_id: str,
        status: str,
        research_results: Dict,
        completed_at: datetime
    ):
        """–û–±–Ω–æ–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        try:
            # PostgreSQL: JSONB
            results_json = json.dumps(research_results, ensure_ascii=False)

            with self.db.connect() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    UPDATE researcher_research
                    SET status = %s,
                        research_results = %s::jsonb,
                        completed_at = %s
                    WHERE research_id = %s
                    """,
                    (status, results_json, completed_at, research_id)
                )
                conn.commit()
                cursor.close()

            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {research_id}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

    async def _save_block_results(
        self,
        research_id: str,
        block_name: str,
        block_results: Dict
    ):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–æ–∫–∞ –°–†–ê–ó–£ –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ - –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –±–ª–æ–∫ –≤ JSONB
        –¢–∞–∫ –¥–∞–∂–µ –µ—Å–ª–∏ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –æ—à–∏–±–∫–∞, –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –±–ª–æ–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è
        """
        try:
            # –ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            with self.db.connect() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT research_results
                    FROM researcher_research
                    WHERE research_id = %s
                    """,
                    (research_id,)
                )
                row = cursor.fetchone()

                if row and row[0]:
                    current_results = row[0]
                else:
                    current_results = {}

                # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –±–ª–æ–∫
                current_results[block_name] = block_results

                # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
                results_json = json.dumps(current_results, ensure_ascii=False)
                cursor.execute(
                    """
                    UPDATE researcher_research
                    SET research_results = %s::jsonb
                    WHERE research_id = %s
                    """,
                    (results_json, research_id)
                )
                conn.commit()
                cursor.close()

            logger.info(f"üíæ –ë–ª–æ–∫ {block_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {block_results['total_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–ª–æ–∫–∞ {block_name}: {e}")

    async def _execute_block_queries(
        self,
        block_name: str,
        queries: List[str],
        websearch_client: WebSearchRouter,  # Router –≤–º–µ—Å—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞!
        allowed_domains: List[str],
        placeholders: Dict
    ) -> Dict:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞

        Args:
            block_name: –ù–∞–∑–≤–∞–Ω–∏–µ –±–ª–æ–∫–∞ (block1_problem, block2_geography, block3_goals)
            queries: –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
            websearch_client: WebSearchRouter –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            allowed_domains: –†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –¥–æ–º–µ–Ω—ã
            placeholders: Placeholders –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            {
                'summary': '–†–µ–∑—é–º–µ –±–ª–æ–∫–∞',
                'key_facts': [...],
                'sources': [...],
                'queries_used': [...],
                'total_sources': 15,
                'processing_time': 120
            }
        """
        start_time = time.time()

        logger.info(f"   –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ {len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –±–ª–æ–∫–∞ {block_name}...")

        # –í—ã–ø–æ–ª–Ω–∏—Ç—å batch WebSearch
        batch_results = await websearch_client.batch_websearch(
            queries=queries,
            allowed_domains=allowed_domains,
            max_results=5,
            max_concurrent=3
        )

        # –ò–∑–≤–ª–µ—á—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results = []
        all_sources = []

        # WebSearchRouter –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä—è–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –Ω–µ –æ–±–µ—Ä–Ω—É—Ç—ã–µ –≤ {'result': ...}
        for result in batch_results:
            all_results.append(result)

            # –°–æ–±—Ä–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            if result.get('sources'):
                all_sources.extend(result['sources'])

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        unique_sources = list(set(all_sources))

        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–æ–∫–∞
        block_results = await self._aggregate_block_results(
            block_name=block_name,
            query_results=all_results,
            queries_used=queries,
            placeholders=placeholders
        )

        block_results['sources'] = unique_sources
        block_results['total_sources'] = len(unique_sources)
        block_results['processing_time'] = int(time.time() - start_time)

        logger.info(f"   ‚úÖ –ë–ª–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω: {len(unique_sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞ {block_results['processing_time']}s")

        return block_results

    async def _aggregate_block_results(
        self,
        block_name: str,
        query_results: List[Dict],
        queries_used: List[str],
        placeholders: Dict
    ) -> Dict:
        """
        –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–ª–æ–∫–∞

        TODO: –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å LLM –≤—ã–∑–æ–≤ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        """
        # –ò–∑–≤–ª–µ—á—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
        all_text = ""
        for result in query_results:
            for item in result.get('results', []):
                all_text += f"{item.get('title', '')} {item.get('snippet', '')} "

        # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        key_facts = []
        for result in query_results:
            for item in result.get('results', []):
                if item.get('snippet'):
                    key_facts.append({
                        'fact': item['snippet'][:200],
                        'source': item.get('source', 'unknown'),
                        'url': item.get('url', ''),
                        'title': item.get('title', '')
                    })

        return {
            'summary': all_text[:500] if all_text else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö',
            'key_facts': key_facts[:10],  # –¢–æ–ø 10 —Ñ–∞–∫—Ç–æ–≤
            'queries_used': queries_used,
            'raw_results': query_results  # –î–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        }

    def _generate_research_report_md(
        self,
        research_id: str,
        anketa_id: str,
        research_results: Dict,
        queries: Dict[str, List[str]],
        user_info: Dict
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è MD –æ—Ç—á–µ—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

        Args:
            research_id: ID –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            anketa_id: ID –∞–Ω–∫–µ—Ç—ã
            research_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            queries: –í—Å–µ 27 –∑–∞–ø—Ä–æ—Å–æ–≤ (dict —Å block1, block2, block3)
            user_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ

        Returns:
            str: MD –æ—Ç—á–µ—Ç
        """
        md_lines = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        md_lines.append("# –û—Ç—á—ë—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏")
        md_lines.append("")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        full_name = f"{user_info.get('first_name', '')} {user_info.get('last_name', '')}".strip() or user_info.get('username', 'Unknown')
        md_lines.append("## –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
        md_lines.append("")
        md_lines.append(f"- **ID –ê–Ω–∫–µ—Ç—ã**: {anketa_id}")
        md_lines.append(f"- **ID –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è**: {research_id}")
        md_lines.append(f"- **–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å**: {full_name} (@{user_info.get('username', 'unknown')})")
        md_lines.append(f"- **Telegram ID**: {user_info.get('telegram_id', 'unknown')}")
        md_lines.append(f"- **–î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md_lines.append(f"- **–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤**: 27")
        md_lines.append(f"- **–í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: {research_results['metadata']['sources_count']}")
        md_lines.append(f"- **–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {research_results['metadata']['total_processing_time']}s")
        md_lines.append(f"- **WebSearch –ø—Ä–æ–≤–∞–π–¥–µ—Ä**: {research_results['metadata']['websearch_provider']}")
        md_lines.append("")

        # –ë–ª–æ–∫ 1: –ü—Ä–æ–±–ª–µ–º–∞ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (10 –∑–∞–ø—Ä–æ—Å–æ–≤)
        md_lines.append("## –ë–ª–æ–∫ 1: –ü—Ä–æ–±–ª–µ–º–∞ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å")
        md_lines.append("")
        md_lines.append(f"**–ó–∞–ø—Ä–æ—Å–æ–≤**: {len(queries['block1'])}")
        md_lines.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: {research_results['block1_problem']['total_sources']}")
        md_lines.append(f"**–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {research_results['block1_problem']['processing_time']}s")
        md_lines.append("")

        block1_results = research_results.get('block1_problem', {})
        raw_results = block1_results.get('raw_results', [])

        for i, query in enumerate(queries['block1'], 1):
            md_lines.append(f"### üîç –ó–∞–ø—Ä–æ—Å {i}")
            md_lines.append("")
            md_lines.append(f"**‚ùì –í–æ–ø—Ä–æ—Å:**")
            md_lines.append("")
            md_lines.append(f"> {query}")
            md_lines.append("")

            query_result = raw_results[i-1] if i-1 < len(raw_results) else {}

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ 'content' (–Ω–µ snippet!)
            full_answer = query_result.get('content', '')

            if full_answer:
                md_lines.append(f"**üí¨ –û—Ç–≤–µ—Ç:**")
                md_lines.append("")
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                paragraphs = full_answer.split('\n\n')
                for para in paragraphs:
                    if para.strip():
                        md_lines.append(para.strip())
                        md_lines.append("")

                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ 'results' (—Ç–æ–ø 5 –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                if query_result.get('results'):
                    sources = [r.get('url', '') for r in query_result['results'] if r.get('url')][:5]
                    if sources:
                        md_lines.append(f"**üîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(sources)}):**")
                        md_lines.append("")
                        for idx, source in enumerate(sources, 1):
                            md_lines.append(f"{idx}. {source}")
                        md_lines.append("")
            else:
                md_lines.append("**üí¨ –û—Ç–≤–µ—Ç:** –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                md_lines.append("")

            # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            md_lines.append("---")
            md_lines.append("")

        # –ë–ª–æ–∫ 2: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è (10 –∑–∞–ø—Ä–æ—Å–æ–≤)
        md_lines.append("## –ë–ª–æ–∫ 2: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è")
        md_lines.append("")
        md_lines.append(f"**–ó–∞–ø—Ä–æ—Å–æ–≤**: {len(queries['block2'])}")
        md_lines.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: {research_results['block2_geography']['total_sources']}")
        md_lines.append(f"**–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {research_results['block2_geography']['processing_time']}s")
        md_lines.append("")

        block2_results = research_results.get('block2_geography', {})
        raw_results = block2_results.get('raw_results', [])

        for i, query in enumerate(queries['block2'], 1):
            md_lines.append(f"### üîç –ó–∞–ø—Ä–æ—Å {i + 10}")
            md_lines.append("")
            md_lines.append(f"**‚ùì –í–æ–ø—Ä–æ—Å:**")
            md_lines.append("")
            md_lines.append(f"> {query}")
            md_lines.append("")

            query_result = raw_results[i-1] if i-1 < len(raw_results) else {}

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ 'content' (–Ω–µ snippet!)
            full_answer = query_result.get('content', '')

            if full_answer:
                md_lines.append(f"**üí¨ –û—Ç–≤–µ—Ç:**")
                md_lines.append("")
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                paragraphs = full_answer.split('\n\n')
                for para in paragraphs:
                    if para.strip():
                        md_lines.append(para.strip())
                        md_lines.append("")

                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ 'results' (—Ç–æ–ø 5 –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                if query_result.get('results'):
                    sources = [r.get('url', '') for r in query_result['results'] if r.get('url')][:5]
                    if sources:
                        md_lines.append(f"**üîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(sources)}):**")
                        md_lines.append("")
                        for idx, source in enumerate(sources, 1):
                            md_lines.append(f"{idx}. {source}")
                        md_lines.append("")
            else:
                md_lines.append("**üí¨ –û—Ç–≤–µ—Ç:** –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                md_lines.append("")

            # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            md_lines.append("---")
            md_lines.append("")

        # –ë–ª–æ–∫ 3: –ó–∞–¥–∞—á–∏, –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –≥–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å (7 –∑–∞–ø—Ä–æ—Å–æ–≤)
        md_lines.append("## –ë–ª–æ–∫ 3: –ó–∞–¥–∞—á–∏, –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏ –≥–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å")
        md_lines.append("")
        md_lines.append(f"**–ó–∞–ø—Ä–æ—Å–æ–≤**: {len(queries['block3'])}")
        md_lines.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: {research_results['block3_goals']['total_sources']}")
        md_lines.append(f"**–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {research_results['block3_goals']['processing_time']}s")
        md_lines.append("")

        block3_results = research_results.get('block3_goals', {})
        raw_results = block3_results.get('raw_results', [])

        for i, query in enumerate(queries['block3'], 1):
            md_lines.append(f"### üîç –ó–∞–ø—Ä–æ—Å {i + 20}")
            md_lines.append("")
            md_lines.append(f"**‚ùì –í–æ–ø—Ä–æ—Å:**")
            md_lines.append("")
            md_lines.append(f"> {query}")
            md_lines.append("")

            query_result = raw_results[i-1] if i-1 < len(raw_results) else {}

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ 'content' (–Ω–µ snippet!)
            full_answer = query_result.get('content', '')

            if full_answer:
                md_lines.append(f"**üí¨ –û—Ç–≤–µ—Ç:**")
                md_lines.append("")
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                paragraphs = full_answer.split('\n\n')
                for para in paragraphs:
                    if para.strip():
                        md_lines.append(para.strip())
                        md_lines.append("")

                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ 'results' (—Ç–æ–ø 5 –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                if query_result.get('results'):
                    sources = [r.get('url', '') for r in query_result['results'] if r.get('url')][:5]
                    if sources:
                        md_lines.append(f"**üîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(sources)}):**")
                        md_lines.append("")
                        for idx, source in enumerate(sources, 1):
                            md_lines.append(f"{idx}. {source}")
                        md_lines.append("")
            else:
                md_lines.append("**üí¨ –û—Ç–≤–µ—Ç:** –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                md_lines.append("")

            # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            md_lines.append("---")
            md_lines.append("")

        # –ò—Ç–æ–≥–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        md_lines.append("---")
        md_lines.append("")
        md_lines.append("## –ò—Ç–æ–≥–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
        md_lines.append("")
        md_lines.append(f"- **–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ**: 27")
        md_lines.append(f"- **–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: {research_results['metadata']['sources_count']}")
        md_lines.append(f"- **–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {research_results['metadata']['total_processing_time']}s")
        md_lines.append(f"- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä**: {research_results['metadata']['websearch_provider']}")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append(f"*–û—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏*  ")
        md_lines.append(f"*–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*  ")
        md_lines.append(f"*ID –æ—Ç—á—ë—Ç–∞: {research_id}*")

        return "\n".join(md_lines)

    async def _send_research_pdf_to_admin(
        self,
        research_id: str,
        anketa_id: str,
        research_results: Dict,
        queries: Dict[str, List[str]]
    ):
        """
        –û—Ç–ø—Ä–∞–≤–∏—Ç—å PDF –æ—Ç—á–µ—Ç –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –∞–¥–º–∏–Ω—Å–∫–∏–π —á–∞—Ç

        Args:
            research_id: ID –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            anketa_id: ID –∞–Ω–∫–µ—Ç—ã
            research_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            queries: –í—Å–µ 27 –∑–∞–ø—Ä–æ—Å–æ–≤ (dict —Å block1, block2, block3)
        """
        try:
            logger.info(f"üìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ (MD + PDF) –¥–ª—è research_id={research_id}")

            # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ –ë–î
            user_info = {'username': 'Unknown', 'first_name': '', 'last_name': '', 'telegram_id': 0}
            with self.db.connect() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT u.telegram_id, u.username, u.first_name, u.last_name
                    FROM users u
                    JOIN sessions s ON s.telegram_id = u.telegram_id
                    WHERE s.anketa_id = %s
                    LIMIT 1
                """, (anketa_id,))
                user_row = cursor.fetchone()

                if user_row:
                    if isinstance(user_row, tuple):
                        user_info = {
                            'telegram_id': user_row[0],
                            'username': user_row[1] or 'unknown',
                            'first_name': (user_row[2] or '').strip(),
                            'last_name': (user_row[3] or '').strip()
                        }
                    elif hasattr(user_row, '_asdict'):
                        user_dict = user_row._asdict()
                        user_info = {
                            'telegram_id': user_dict.get('telegram_id', 0),
                            'username': user_dict.get('username', 'unknown'),
                            'first_name': (user_dict.get('first_name', '') or '').strip(),
                            'last_name': (user_dict.get('last_name', '') or '').strip()
                        }

                cursor.close()

            logger.info(f"‚úÖ User info –ø–æ–ª—É—á–µ–Ω–∞: {user_info['username']}")

            # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è MD –æ—Ç—á–µ—Ç–∞
            md_report = self._generate_research_report_md(
                research_id=research_id,
                anketa_id=anketa_id,
                research_results=research_results,
                queries=queries,
                user_info=user_info
            )

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å MD —Ñ–∞–π–ª
            md_filename = f"{research_id.replace('#', '')}.md"
            md_filepath = os.path.join(current_dir, 'reports', md_filename)
            os.makedirs(os.path.dirname(md_filepath), exist_ok=True)

            with open(md_filepath, 'w', encoding='utf-8') as f:
                f.write(md_report)

            logger.info(f"‚úÖ MD –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {md_filepath}")

            # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF –æ—Ç—á–µ—Ç–∞

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è PDF
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è PDF –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
            queries_list = []
            query_id = 1

            # –ë–ª–æ–∫ 1
            for i, query in enumerate(queries['block1']):
                block1_results = research_results.get('block1_problem', {})
                raw_results = block1_results.get('raw_results', [])
                query_result = raw_results[i] if i < len(raw_results) else {}

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ü–û–õ–ù–´–ô –æ—Ç–≤–µ—Ç –∏–∑ 'content' (–Ω–µ snippet!)
                answer = query_result.get('content', '') or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (—Ç–æ–ø 5 –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                sources = []
                if query_result.get('results'):
                    sources = [r.get('url', '') for r in query_result['results'] if r.get('url')][:5]

                queries_list.append({
                    'query_id': query_id,
                    'question': query,
                    'answer': answer,
                    'sources': sources
                })
                query_id += 1

            # –ë–ª–æ–∫ 2
            for i, query in enumerate(queries['block2']):
                block2_results = research_results.get('block2_geography', {})
                raw_results = block2_results.get('raw_results', [])
                query_result = raw_results[i] if i < len(raw_results) else {}

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ü–û–õ–ù–´–ô –æ—Ç–≤–µ—Ç –∏–∑ 'content' (–Ω–µ snippet!)
                answer = query_result.get('content', '') or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (—Ç–æ–ø 5 –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                sources = []
                if query_result.get('results'):
                    sources = [r.get('url', '') for r in query_result['results'] if r.get('url')][:5]

                queries_list.append({
                    'query_id': query_id,
                    'question': query,
                    'answer': answer,
                    'sources': sources
                })
                query_id += 1

            # –ë–ª–æ–∫ 3
            for i, query in enumerate(queries['block3']):
                block3_results = research_results.get('block3_goals', {})
                raw_results = block3_results.get('raw_results', [])
                query_result = raw_results[i] if i < len(raw_results) else {}

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ü–û–õ–ù–´–ô –æ—Ç–≤–µ—Ç –∏–∑ 'content' (–Ω–µ snippet!)
                answer = query_result.get('content', '') or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (—Ç–æ–ø 5 –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã)
                sources = []
                if query_result.get('results'):
                    sources = [r.get('url', '') for r in query_result['results'] if r.get('url')][:5]

                queries_list.append({
                    'query_id': query_id,
                    'question': query,
                    'answer': answer,
                    'sources': sources
                })
                query_id += 1

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è PDF
            research_data = {
                'anketa_id': anketa_id,
                'research_id': research_id,
                'queries': queries_list,
                'summary': f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: 27. –í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {research_results['metadata']['sources_count']}",
                'key_findings': f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {research_results['metadata']['total_processing_time']}s. –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {research_results['metadata']['websearch_provider']}",
                'completed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä PDF —á–µ—Ä–µ–∑ importlib (–Ω–∞–¥–µ–∂–Ω–µ–µ)
            import importlib.util
            pdf_gen_path = os.path.join(current_dir, 'telegram-bot', 'utils', 'stage_report_generator.py')
            spec_pdf = importlib.util.spec_from_file_location("stage_report_generator", pdf_gen_path)
            pdf_gen_module = importlib.util.module_from_spec(spec_pdf)
            spec_pdf.loader.exec_module(pdf_gen_module)
            generate_stage_pdf = pdf_gen_module.generate_stage_pdf

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF
            pdf_bytes = generate_stage_pdf('research', research_data)
            logger.info(f"‚úÖ PDF —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(pdf_bytes)} –±–∞–π—Ç")

            # 3. –û—Ç–ø—Ä–∞–≤–∫–∞ PDF –≤ –∞–¥–º–∏–Ω—Å–∫–∏–π —á–∞—Ç —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π caption
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AdminNotifier —á–µ—Ä–µ–∑ importlib
            admin_notif_path = os.path.join(current_dir, 'telegram-bot', 'utils', 'admin_notifications.py')
            spec_admin = importlib.util.spec_from_file_location("admin_notifications", admin_notif_path)
            admin_module = importlib.util.module_from_spec(spec_admin)
            spec_admin.loader.exec_module(admin_module)
            AdminNotifier = admin_module.AdminNotifier

            bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
            if not bot_token:
                logger.warning("‚ö†Ô∏è TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω, PDF –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
                return

            # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç caption (–∫–∞–∫ –≤ Interview –∏ Audit)
            full_name = f"{user_info['first_name']} {user_info['last_name']}".strip() or user_info['username']
            sources_count = research_results['metadata']['sources_count']
            provider = research_results['metadata']['websearch_provider']
            completed_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            caption = f"""üìä –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û

üìã –ê–Ω–∫–µ—Ç–∞: {anketa_id}
üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {full_name} (@{user_info['username']})
üÜî Telegram ID: {user_info['telegram_id']}
üìÖ –î–∞—Ç–∞: {completed_at}
üîç –ó–∞–ø—Ä–æ—Å–æ–≤: 27
üåê –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {sources_count}
‚öôÔ∏è –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider}

PDF –¥–æ–∫—É–º–µ–Ω—Ç —Å –ø–æ–ª–Ω—ã–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω

#research #completed"""

            notifier = AdminNotifier(bot_token)
            success = await notifier.send_stage_completion_pdf(
                stage='research',
                pdf_bytes=pdf_bytes,
                filename=f"{research_id.replace('#', '')}.pdf",  # FIXED: Nomenclature
                caption=caption,
                anketa_id=anketa_id
            )

            if success:
                logger.info(f"‚úÖ PDF –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –∞–¥–º–∏–Ω—Å–∫–∏–π —á–∞—Ç: {research_id}")
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å PDF –≤ –∞–¥–º–∏–Ω—Å–∫–∏–π —á–∞—Ç")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ PDF: {e}", exc_info=True)
            # –ù–µ –±—Ä–æ—Å–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ - –æ—Ç–ø—Ä–∞–≤–∫–∞ PDF –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞

    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞)"""
        anketa_id = data.get('anketa_id')

        if not anketa_id:
            return {
                'status': 'error',
                'message': 'anketa_id –Ω–µ —É–∫–∞–∑–∞–Ω'
            }

        # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
        return asyncio.run(self.research_with_expert_prompts(anketa_id))


# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
ResearcherAgent = ResearcherAgentV2
