#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π E2E Test –¥–ª—è Sber500 Bootcamp —Å GigaChat-Max
"""

import sys
import os
import asyncio
import json
import time
from datetime import datetime
from pathlib import Path

# PYTHONPATH —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ wrapper —Å–∫—Ä–∏–ø—Ç–µ
from data.database.models import GrantServiceDatabase
from agents.researcher_agent_v2 import ResearcherAgentV2
from agents.writer_agent_v2 import WriterAgentV2

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
ANKETA_ID = "#AN-20251012-Natalia_bruzzzz-001"
GIGACHAT_MODEL = "GigaChat-Max"
LLM_PROVIDER = "gigachat"

# –ú–µ—Ç—Ä–∏–∫–∏
metrics = {
    "start_time": None,
    "end_time": None,
    "anketa_id": ANKETA_ID,
    "model": GIGACHAT_MODEL,
    "stages": {}
}

def log(message: str, emoji: str = "üìå"):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"{emoji} [{timestamp}] {message}")

async def run_researcher(db, anketa_id: str):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å Researcher Agent"""
    log("–ó–∞–ø—É—Å–∫ Researcher Agent", "üîç")
    start = time.time()

    try:
        researcher = ResearcherAgentV2(
            db=db,
            llm_provider="claude_code",
            websearch_provider="perplexity"
        )

        result = await researcher.run_research(anketa_id)
        elapsed = time.time() - start

        metrics["stages"]["researcher"] = {
            "status": "success" if result else "failed",
            "duration_seconds": round(elapsed, 2),
            "queries": 27
        }

        log(f"Researcher –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {elapsed:.1f}s", "‚úÖ")
        return result

    except Exception as e:
        elapsed = time.time() - start
        log(f"–û–®–ò–ë–ö–ê Researcher: {e}", "‚ùå")
        metrics["stages"]["researcher"] = {
            "status": "error",
            "duration_seconds": round(elapsed, 2),
            "error": str(e)
        }
        return None

async def run_writer(db, anketa_id: str):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å Writer Agent —Å GigaChat-Max"""
    log(f"–ó–∞–ø—É—Å–∫ Writer Agent —Å {GIGACHAT_MODEL}", "‚úçÔ∏è")
    start = time.time()

    try:
        writer = WriterAgentV2(db=db, llm_provider=LLM_PROVIDER)

        # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å
        if hasattr(writer, 'llm_client') and writer.llm_client:
            writer.llm_client.model = GIGACHAT_MODEL
            log(f"–ú–æ–¥–µ–ª—å: {GIGACHAT_MODEL}", "üéØ")

        result = await writer.write_grant_application(anketa_id)
        elapsed = time.time() - start

        if result and 'application_text' in result:
            text_length = len(result['application_text'])
            estimated_tokens = int(text_length * 1.3)
        else:
            text_length = 0
            estimated_tokens = 0

        metrics["stages"]["writer"] = {
            "status": "success" if result else "failed",
            "duration_seconds": round(elapsed, 2),
            "estimated_tokens": estimated_tokens,
            "model": GIGACHAT_MODEL
        }

        log(f"Writer –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {elapsed:.1f}s", "‚úÖ")
        log(f"–¢–æ–∫–µ–Ω—ã: ~{estimated_tokens:,}", "üí∞")
        return result

    except Exception as e:
        elapsed = time.time() - start
        log(f"–û–®–ò–ë–ö–ê Writer: {e}", "‚ùå")
        metrics["stages"]["writer"] = {
            "status": "error",
            "duration_seconds": round(elapsed, 2),
            "error": str(e)
        }
        return None

async def main():
    log("="*80, "")
    log("E2E TEST - Sber500 Bootcamp", "üöÄ")
    log("="*80, "")

    metrics["start_time"] = datetime.now().isoformat()

    # –ë–î
    log("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î...", "üîå")
    try:
        db = GrantServiceDatabase()
        log("–ë–î –ø–æ–¥–∫–ª—é—á–µ–Ω–∞", "‚úÖ")
    except Exception as e:
        log(f"–û–®–ò–ë–ö–ê –ë–î: {e}", "‚ùå")
        return

    log(f"–ê–Ω–∫–µ—Ç–∞: {ANKETA_ID}", "üìã")
    log(f"–ú–æ–¥–µ–ª—å: {GIGACHAT_MODEL}", "üî•")
    log("")

    # Research
    log("--- RESEARCH ---", "üîç")
    research_result = await run_researcher(db, ANKETA_ID)
    if not research_result:
        log("Research failed", "‚ùå")
        return
    log("")

    # Write
    log("--- WRITE ---", "‚úçÔ∏è")
    write_result = await run_writer(db, ANKETA_ID)
    log("")

    # Metrics
    metrics["end_time"] = datetime.now().isoformat()
    metrics["total_duration"] = sum(
        s.get("duration_seconds", 0) for s in metrics["stages"].values()
    )

    # Save
    output_dir = Path("/var/GrantService/test_results")
    output_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    metrics_file = output_dir / f"e2e_metrics_{timestamp}.json"

    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)

    log("="*80, "")
    log("–û–¢–ß–ï–¢", "üìä")
    log("="*80, "")
    log(f"–ú–æ–¥–µ–ª—å: {GIGACHAT_MODEL}", "üéØ")

    if "researcher" in metrics["stages"]:
        r = metrics["stages"]["researcher"]
        log(f"Researcher: {r['status']} ({r['duration_seconds']}s)", "üîç")

    if "writer" in metrics["stages"]:
        w = metrics["stages"]["writer"]
        log(f"Writer: {w['status']} ({w['duration_seconds']}s)", "‚úçÔ∏è")
        if 'estimated_tokens' in w:
            log(f"–¢–æ–∫–µ–Ω—ã: ~{w['estimated_tokens']:,}", "üí∞")

    log(f"–í—Ä–µ–º—è: {metrics['total_duration']:.1f}s", "‚è±Ô∏è")
    log(f"–ú–µ—Ç—Ä–∏–∫–∏: {metrics_file}", "üíæ")
    log("="*80, "")

if __name__ == "__main__":
    asyncio.run(main())
