#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Semantic Search –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ GrantService
–ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–∞—Ä–æ–ª–µ–π, API keys, –∫–æ–º–∞–Ω–¥
"""

import sys
from pathlib import Path

# –ü—É—Ç–∏
project_root = Path(__file__).parent.parent.parent.parent.parent / "GrantService"
sys.path.insert(0, str(project_root))

from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

def search_tech_docs(query: str, limit: int = 3, show_full: bool = False):
    """–ü–æ–∏—Å–∫ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""

    # Connect
    client = QdrantClient(host="5.35.88.251", port=6333)
    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

    # Search
    query_vector = model.encode(query).tolist()
    results = client.search(
        collection_name="grantservice_tech_docs",
        query_vector=query_vector,
        limit=limit
    )

    # Display
    print(f"\nüîç –ü–æ–∏—Å–∫: '{query}'")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n")

    for i, hit in enumerate(results, 1):
        score = hit.score
        payload = hit.payload

        importance_emoji = {
            "critical": "üî•",
            "high": "‚ö°",
            "medium": "üìå",
            "low": "üìÑ"
        }.get(payload.get("importance", "medium"), "üìÑ")

        print(f"{i}. {importance_emoji} {payload.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
        print(f"   Score: {score:.3f} | Category: {payload.get('category', 'unknown')}")

        if 'tags' in payload:
            print(f"   Tags: {', '.join(payload['tags'])}")

        print()

        # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—Å—Ç
        if show_full:
            print("   " + "‚îÄ" * 70)
            print(payload.get('text', '').strip())
            print("   " + "‚îÄ" * 70)
            print()
        else:
            # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤
            text = payload.get('text', '').strip()
            preview = text[:300] + "..." if len(text) > 300 else text
            print(f"   {preview}")
            print()

    print("-" * 80)

def main():
    """Main function"""
    import argparse

    parser = argparse.ArgumentParser(description="–ü–æ–∏—Å–∫ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ GrantService")
    parser.add_argument("query", nargs="?", help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    parser.add_argument("-l", "--limit", type=int, default=3, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("-f", "--full", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç")

    args = parser.parse_args()

    if args.query:
        # Single search
        search_tech_docs(args.query, limit=args.limit, show_full=args.full)
    else:
        # Interactive mode
        print("="*80)
        print("üîç Semantic Search - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è GrantService")
        print("="*80)
        print("\n–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:")
        print("  ‚Ä¢ –ø–∞—Ä–æ–ª—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        print("  ‚Ä¢ api key gigachat")
        print("  ‚Ä¢ –∫–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞")
        print("  ‚Ä¢ postgresql –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")
        print("  ‚Ä¢ –∫–æ–º–∞–Ω–¥—ã ssh")
        print("\n–í–≤–µ–¥–∏—Ç–µ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞\n")

        while True:
            try:
                query = input("üîç Search: ").strip()

                if not query:
                    continue

                if query.lower() in ['exit', 'quit', 'q']:
                    print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break

                search_tech_docs(query, limit=args.limit, show_full=args.full)

            except KeyboardInterrupt:
                print("\n\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}\n")

if __name__ == "__main__":
    main()
