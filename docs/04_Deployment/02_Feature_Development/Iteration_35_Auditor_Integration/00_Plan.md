# Iteration 35: Auditor Integration in Grant Generation Workflow

**Created:** 2025-10-25
**Type:** Feature Enhancement
**Priority:** P0 - CRITICAL (Quality Control)
**Estimated Time:** 2-3 hours

---

## ðŸŽ¯ ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ

### Ð¢ÐµÐºÑƒÑ‰Ð°Ñ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ñ:

**ÐÐ½ÐºÐµÑ‚Ð° #AN-20251007-theperipherals-005:**
```json
{
    "links": "Ñ„Ñ‹Ð²Ð°Ñ„Ñ‹Ð²Ð°",
    "tasks": "Ñ„Ñ‹Ð²Ð°Ñ„Ñ‹Ð²Ð°",
    "budget": "Ñ„Ñ‹Ð²Ð°Ñ„Ñ‹Ð²Ð°",
    "events": "Ñ„Ñ‹Ð²Ð°Ñ„Ñ‹Ð²Ð°",
    ...Ð²ÑÐµ Ð¿Ð¾Ð»Ñ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ñ‹ Ð¼ÑƒÑÐ¾Ñ€Ð¾Ð¼
}
```

**ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹:**
1. âŒ ÐÐµÑ‚ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð°Ð½ÐºÐµÑ‚Ñ‹ Ð¿ÐµÑ€ÐµÐ´ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÐµÐ¹
2. âŒ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð³Ñ€Ð°Ð½Ñ‚Ð° Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… = waste of resources
3. âŒ User Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½ÐµÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½ÑƒÑŽ Ð·Ð°ÑÐ²ÐºÑƒ
4. âŒ ÐÐµÑ‚ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸ Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ

### Ð¡ÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð°Ñ Ð¸Ð½Ñ„Ñ€Ð°ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°:

âœ… **Auditor Agent ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚:**
- `agents/auditor_agent.py` - Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€
- `agents/auditor_agent_claude.py` - Claude version
- Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° `auditor_results` Ð² Ð‘Ð”

âœ… **Auditor Result Schema:**
```sql
auditor_results:
- completeness_score (1-10)
- clarity_score (1-10)
- feasibility_score (1-10)
- innovation_score (1-10)
- quality_score (1-10)
- average_score (numeric)
- approval_status (pending/approved/needs_revision/rejected)
- recommendations (jsonb)
```

âœ… **Approval Status Logic (trigger):**
- average_score >= 7.0 â†’ "approved"
- average_score >= 5.0 â†’ "needs_revision"
- average_score < 5.0 â†’ "rejected"

---

## ðŸŽ¯ Ð Ð•Ð¨Ð•ÐÐ˜Ð•

### New Workflow:

```
User: /generate_grant
   â†“
1. Get anketa_id
   â†“
2. Check: audit exists?
   â”œâ”€ NO â†’ Run AuditorAgent.audit(anketa_data)
   â”‚          â†“
   â”‚       Save to auditor_results
   â”‚
   â””â”€ YES â†’ Get audit result
   â†“
3. Check approval_status:
   â”œâ”€ "approved" â†’ Continue to generation âœ…
   â”‚
   â”œâ”€ "needs_revision" â†’ Show recommendations âš ï¸
   â”‚   Message: "ÐÐ½ÐºÐµÑ‚Ð° Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð¾Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"
   â”‚   Display: recommendations
   â”‚   Action: User must improve anketa
   â”‚
   â””â”€ "rejected" â†’ Block generation âŒ
       Message: "ÐÐ½ÐºÐµÑ‚Ð° Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸"
       Display: reasons
       Action: User must re-do anketa
   â†“
4. IF approved â†’ Generate grant with ProductionWriter
```

---

## ðŸ“ IMPLEMENTATION PLAN

### Step 1: Add audit check method (30 min)

**File:** `telegram-bot/handlers/grant_handler.py`

**Add method:**
```python
async def _check_or_run_audit(self, session_id: int, anketa_id: str, anketa_data: dict, user_id: int) -> dict:
    """
    Check if audit exists, run if needed
    Returns: {'approved': bool, 'score': float, 'recommendations': list, 'status': str}
    """
    # 1. Check existing audit
    existing_audit = self.db.get_audit_by_session_id(session_id)

    if existing_audit:
        logger.info(f"[AUDIT] Found existing audit for session {session_id}, score: {existing_audit['average_score']}")
        return {
            'approved': existing_audit['approval_status'] == 'approved',
            'score': existing_audit['average_score'],
            'recommendations': existing_audit.get('recommendations', []),
            'status': existing_audit['approval_status']
        }

    # 2. Run new audit
    logger.info(f"[AUDIT] No audit found, running AuditorAgent for session {session_id}")

    # Import AuditorAgent
    from agents.auditor_agent import AuditorAgent

    # Get LLM preference
    llm_provider = self.db.get_user_llm_preference(user_id)

    # Create auditor
    auditor = AuditorAgent(self.db, llm_provider=llm_provider)

    # Run audit
    audit_result = await asyncio.to_thread(
        auditor.audit,
        anketa_data=anketa_data,
        session_id=session_id
    )

    # Return result
    return {
        'approved': audit_result['approval_status'] == 'approved',
        'score': audit_result['average_score'],
        'recommendations': audit_result.get('recommendations', []),
        'status': audit_result['approval_status']
    }
```

**Add DB method:**
```python
# In data/database/models.py

def get_audit_by_session_id(self, session_id: int) -> Optional[Dict]:
    """Get audit result for session"""
    try:
        with self.connect() as conn:
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM auditor_results
                WHERE session_id = %s
                ORDER BY created_at DESC
                LIMIT 1
            """, (session_id,))

            row = cursor.fetchone()
            cursor.close()

            return self._dict_row(cursor, row) if row else None

    except Exception as e:
        logger.error(f"Error getting audit: {e}")
        return None
```

---

### Step 2: Integrate audit into generate_grant (45 min)

**File:** `telegram-bot/handlers/grant_handler.py`

**Modify generate_grant method:**

```python
async def generate_grant(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Generate grant application with AUDIT CHECK"""

    # ... existing code Ð´Ð¾ ProductionWriter ...

    # Get session_id
    session = self.db.get_session_by_anketa_id(anketa_id)
    if not session:
        await update.message.reply_text("âŒ Ð¡ÐµÑÑÐ¸Ñ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
        return

    session_id = session['id']

    # ===== NEW: RUN AUDIT CHECK =====
    await update.message.reply_text(
        "ðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÑŽ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°Ð½ÐºÐµÑ‚Ñ‹...\n"
        "Ð­Ñ‚Ð¾ Ð·Ð°Ð¹Ð¼ÐµÑ‚ ~30 ÑÐµÐºÑƒÐ½Ð´"
    )

    audit_result = await self._check_or_run_audit(
        session_id=session_id,
        anketa_id=anketa_id,
        anketa_data=anketa_data,
        user_id=user_id
    )

    # Check approval status
    if not audit_result['approved']:
        # Not approved - show recommendations
        status = audit_result['status']
        score = audit_result['score']
        recommendations = audit_result.get('recommendations', [])

        if status == 'needs_revision':
            message = f"âš ï¸ **ÐÐ½ÐºÐµÑ‚Ð° Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð¾Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸**\n\n"
            message += f"ðŸ“Š ÐžÑ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°: {score}/10\n\n"
            message += "**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸:**\n"

            for i, rec in enumerate(recommendations[:5], 1):
                message += f"{i}. {rec}\n"

            message += "\nðŸ’¡ ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚Ðµ Ð°Ð½ÐºÐµÑ‚Ñƒ Ð¸ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°"

        elif status == 'rejected':
            message = f"âŒ **ÐÐ½ÐºÐµÑ‚Ð° Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸**\n\n"
            message += f"ðŸ“Š ÐžÑ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°: {score}/10 (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 5.0)\n\n"
            message += "**ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹:**\n"

            for i, rec in enumerate(recommendations[:5], 1):
                message += f"{i}. {rec}\n"

            message += "\nðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼ Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð°Ð½ÐºÐµÑ‚Ñƒ Ð·Ð°Ð½Ð¾Ð²Ð¾"

        else:
            message = f"â³ ÐÐ½ÐºÐµÑ‚Ð° Ð½Ð° Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¸Ð¸ (ÑÑ‚Ð°Ñ‚ÑƒÑ: {status})"

        await update.message.reply_text(message)
        logger.warning(f"[GRANT] Audit blocked generation: {status}, score: {score}")
        return

    # Approved - continue generation
    logger.info(f"[GRANT] Audit approved (score: {audit_result['score']}), proceeding with generation")

    await update.message.reply_text(
        f"âœ… ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð°Ð½ÐºÐµÑ‚Ñ‹: {audit_result['score']}/10 - Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾!\n"
        f"ðŸš€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð³Ñ€Ð°Ð½Ñ‚Ð¾Ð²Ð¾Ð¹ Ð·Ð°ÑÐ²ÐºÐ¸..."
    )

    # ... existing ProductionWriter code ...
```

---

### Step 3: Add database method (15 min)

**File:** `data/database/models.py`

Add `get_audit_by_session_id()` method (see above)

---

### Step 4: Testing (30 min)

**Test Scenario 1: No audit exists**
1. User runs `/generate_grant`
2. System checks audit â†’ Not found
3. System runs AuditorAgent
4. System saves audit result
5. IF approved â†’ Generate grant
6. IF not approved â†’ Show recommendations

**Test Scenario 2: Audit exists - Approved**
1. User runs `/generate_grant`
2. System checks audit â†’ Found, status: approved
3. System proceeds with generation

**Test Scenario 3: Audit exists - Needs Revision**
1. User runs `/generate_grant`
2. System checks audit â†’ Found, status: needs_revision
3. System shows recommendations
4. System blocks generation

**Test Scenario 4: Audit exists - Rejected**
1. User runs `/generate_grant`
2. System checks audit â†’ Found, status: rejected
3. System shows problems
4. System blocks generation

---

## ðŸ“Š EXPECTED RESULTS

### Quality Control:

**Before:**
- âŒ Any anketa â†’ Grant generation
- âŒ Garbage data â†’ Garbage grant
- âŒ No feedback to user

**After:**
- âœ… Quality check before generation
- âœ… Only approved anketas â†’ Grant generation
- âœ… Recommendations for improvement
- âœ… User gets feedback

### Metrics:

**Quality:**
- Grant quality improves (only approved anketas)
- User satisfaction improves (better guidance)
- Less wasted resources (no generation on garbage)

**Performance:**
- First generation: +30s (audit time)
- Subsequent generations: +0.1s (cache check)
- Net: Positive (better quality > slight delay)

---

## ðŸ› EDGE CASES

### Edge Case 1: Audit fails
**Scenario:** AuditorAgent crashes
**Solution:** Try/except, fallback to warning + continue generation

### Edge Case 2: Audit in progress
**Scenario:** User clicks /generate_grant while audit is running
**Solution:** Check audit status, show "â³ Audit in progress"

### Edge Case 3: Multiple audits
**Scenario:** Anketa modified after audit
**Solution:** Get latest audit (ORDER BY created_at DESC LIMIT 1)

### Edge Case 4: Audit takes too long
**Scenario:** Audit takes > 60 seconds
**Solution:** Run in background, notify user when done

---

## ðŸ”§ CONFIGURATION

### Audit Score Thresholds (configurable):

```python
AUDIT_THRESHOLDS = {
    'approved': 7.0,        # >= 7.0 â†’ approved
    'needs_revision': 5.0,  # >= 5.0 â†’ needs_revision
    'rejected': 0.0         # < 5.0 â†’ rejected
}
```

### Audit Timeout:
```python
AUDIT_TIMEOUT = 60  # seconds
```

---

## ðŸ“ SUCCESS CRITERIA

- [ ] Audit runs automatically before grant generation
- [ ] Approved anketas proceed to generation
- [ ] Non-approved anketas show recommendations
- [ ] User receives clear feedback about quality
- [ ] Audit result cached (no re-run on same anketa)
- [ ] All tests pass
- [ ] Deployed to production
- [ ] User tested successfully

---

## ðŸ”„ ROLLBACK PLAN

If audit integration causes problems:

1. Comment out audit check in grant_handler.py
2. Restore original behavior (generate without audit)
3. Deploy hotfix
4. Debug audit offline
5. Re-deploy when fixed

**Rollback time:** < 5 minutes

---

## ðŸ“ž NEXT ACTIONS

### Immediate:
1. Create `get_audit_by_session_id()` method
2. Create `_check_or_run_audit()` method
3. Integrate into `generate_grant()`
4. Test locally

### Deploy:
1. Apply Pre-Deploy Checklist
2. Commit to git
3. Deploy to production
4. Test with real user

### After Deploy:
1. Monitor audit results
2. Adjust thresholds if needed
3. Collect user feedback
4. Document learnings

---

**Status:** READY TO IMPLEMENT
**Estimated Total Time:** 2-3 hours
**Impact:** HIGH (Quality Control)
**Risk:** LOW (Can rollback easily)

---

ðŸŽ¯ **Goal: Zero garbage grants, 100% quality control!**
