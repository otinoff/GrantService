# Iteration 1001: RAG Full Integration (FUTURE PLAN)

**Status:** üìÖ PLANNED (not started)
**Priority:** MEDIUM
**Prerequisites:** Iteration 51 complete ‚úÖ
**Estimated Time:** 4-6 hours
**Assigned To:** TBD

---

## üéØ Goal

Extend RAG (Retrieval Augmented Generation) to **all 10 sections** of WriterAgent, validate quality improvement through A/B testing.

**Current State (from Iteration 51):**
- ‚úÖ RAG integrated for **problem section** only (proof of concept)
- ‚úÖ RAG retriever module complete (3 retrieval methods)
- ‚úÖ 60 high-quality vectors (42 grants + 18 requirements)

**Target State:**
- ‚úÖ RAG integrated for **all 10 sections**
- ‚úÖ A/B tested (10 projects with/without RAG)
- ‚úÖ Measured quality improvement (ReviewerAgent scores)
- ‚úÖ Production-ready persistent Qdrant

---

## üìä Scope

### In Scope ‚úÖ
1. Extend RAG to 9 remaining sections:
   - solution (—Ä–µ—à–µ–Ω–∏–µ) - use solution examples
   - implementation (–ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏) - use methodologies
   - budget (–±—é–¥–∂–µ—Ç) - use budget templates
   - timeline (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏) - use implementation plans
   - team (–∫–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞) - use team examples
   - impact (–æ–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç) - use KPI examples
   - sustainability (—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å) - use impact examples
   - summary (–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ) - use all context
   - title (–Ω–∞–∑–≤–∞–Ω–∏–µ) - use title examples

2. Setup persistent Qdrant (production-ready)
3. A/B testing framework
4. Quality measurement (ReviewerAgent integration)
5. Documentation + metrics

### Out of Scope ‚ùå
- New embeddings collections (use existing 60 vectors)
- RL training (deferred to Iteration 1003)
- UI changes
- Database schema changes

---

## üìã Tasks Breakdown

### Phase 1: Setup Persistent Qdrant (1 hour)
**Goal:** Switch from in-memory to persistent Qdrant

**Tasks:**
- [ ] Start Qdrant with Docker: `docker run -p 6333:6333 qdrant/qdrant`
- [ ] Update `writer_agent.py` to use `localhost:6333`
- [ ] Load collections: `load_fpg_to_qdrant.py` + `load_fpg_requirements_to_qdrant.py`
- [ ] Verify collections: 42 + 18 = 60 vectors
- [ ] Test semantic search (smoke test)

**Acceptance Criteria:**
- ‚úÖ Qdrant running on localhost:6333
- ‚úÖ Both collections loaded and searchable
- ‚úÖ WriterAgent connects successfully

---

### Phase 2: Extend RAG to Solution Section (30 min)
**Goal:** Add RAG retrieval for solution generation

**Implementation:**
```python
# In _generate_application_content_async(), after problem generation:

# Get solution examples
solution_examples = []
if self.rag_retriever:
    solution_examples = self.rag_retriever.retrieve_section_examples(
        section_name="solution",
        query_text=f"{project_name}: {content['problem'][:500]}",
        top_k=2
    )

# Enhance solution prompt
solution_prompt = f"""...
{format_section_examples_for_prompt("solution", solution_examples)}

–ù–∞–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –†–ï–®–ï–ù–ò–Ø...
–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã –≤—ã—à–µ –¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è, –Ω–æ —Å–æ–∑–¥–∞–π –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ï —Ä–µ—à–µ–Ω–∏–µ.
"""
```

**Acceptance Criteria:**
- ‚úÖ Solution generation uses RAG examples
- ‚úÖ Prompt includes 2 solution examples
- ‚úÖ Quality improves (manual check)

---

### Phase 3: Extend RAG to Implementation Section (30 min)
**Goal:** Add RAG retrieval for implementation (use methodologies)

**Implementation:**
```python
# Get methodology recommendations
methodologies = []
if self.rag_retriever:
    methodologies = self.rag_retriever.retrieve_requirements(
        requirement_type="methodology",
        query_text=f"–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞: {project_name}",
        top_k=2
    )

# Enhance implementation prompt with methodologies
```

**Acceptance Criteria:**
- ‚úÖ Implementation uses methodologies (SMART, Logic Model)
- ‚úÖ Prompt structured with research methods

---

### Phase 4: Extend RAG to Budget Section (30 min)
**Goal:** Add RAG retrieval for budget (use templates)

**Implementation:**
```python
# Get budget templates
budget_templates = []
if self.rag_retriever:
    budget_templates = self.rag_retriever.retrieve_requirements(
        requirement_type="budget",
        query_text=f"–ë—é–¥–∂–µ—Ç –ø—Ä–æ–µ–∫—Ç–∞: {budget_amount}",
        top_k=2
    )

# Enhance budget prompt with standard FPG categories
```

**Acceptance Criteria:**
- ‚úÖ Budget follows FPG structure
- ‚úÖ All standard categories included

---

### Phase 5: Extend RAG to Impact Section (30 min)
**Goal:** Add RAG retrieval for impact (use KPI examples)

**Implementation:**
```python
# Get KPI examples
kpi_examples = []
if self.rag_retriever:
    kpi_examples = self.rag_retriever.retrieve_section_examples(
        section_name="kpi",
        query_text=f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞: {project_name}",
        top_k=2
    )

# Enhance impact prompt with measurable KPIs
```

**Acceptance Criteria:**
- ‚úÖ Impact includes SMART KPIs
- ‚úÖ Measurable results specified

---

### Phase 6: Extend RAG to Remaining 5 Sections (1 hour)
**Goal:** Add RAG to timeline, team, sustainability, summary, title

**Tasks:**
- [ ] Timeline - use implementation examples
- [ ] Team - use team structure examples
- [ ] Sustainability - use impact examples
- [ ] Summary - use all grant context
- [ ] Title - use title examples

**Acceptance Criteria:**
- ‚úÖ All 10 sections use RAG
- ‚úÖ No section left without examples

---

### Phase 7: A/B Testing Framework (1 hour)
**Goal:** Create framework to test with/without RAG

**Test Projects (10):**
1. –ú–æ–ª–æ–¥–µ–∂–Ω–æ–µ –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å—Ç–≤–æ
2. –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤
3. –ö—É–ª—å—Ç—É—Ä–Ω—ã–π —Ü–µ–Ω—Ç—Ä –¥–ª—è –º–∞–ª—ã—Ö –≥–æ—Ä–æ–¥–æ–≤
4. –°–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
5. –≠–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–µ–∫—Ç (–æ–∑–µ–ª–µ–Ω–µ–Ω–∏–µ)
6. –°–æ—Ü–∏–∞–ª—å–Ω–∞—è –ø–æ–º–æ—â—å –ø–æ–∂–∏–ª—ã–º
7. IT-–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–π
8. –ú—É–∑–µ–π–Ω–∞—è –≤—ã—Å—Ç–∞–≤–∫–∞
9. –ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–≤–æ—Ä–æ–≤
10. –í–æ–ª–æ–Ω—Ç–µ—Ä—Å–∫–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞

**Implementation:**
```python
# scripts/test_rag_ab.py

async def test_with_rag(project):
    agent = WriterAgent(db, rag_enabled=True)
    return await agent.write_application_async(project)

async def test_without_rag(project):
    agent = WriterAgent(db, rag_enabled=False)
    return await agent.write_application_async(project)

# Run A/B test for 10 projects
results = []
for project in test_projects:
    with_rag = await test_with_rag(project)
    without_rag = await test_without_rag(project)
    results.append({
        "project": project["name"],
        "with_rag": with_rag,
        "without_rag": without_rag
    })
```

**Acceptance Criteria:**
- ‚úÖ 10 projects tested
- ‚úÖ 20 applications generated (10 with RAG + 10 without)
- ‚úÖ Results saved for analysis

---

### Phase 8: Quality Measurement (1 hour)
**Goal:** Measure quality improvement using ReviewerAgent

**Metrics:**
1. **ReviewerAgent Score** (0-10)
2. **Problem Detail** (char count)
3. **Solution Specificity** (manual review)
4. **Budget Structure** (FPG alignment %)
5. **KPI Measurability** (SMART criteria %)

**Implementation:**
```python
from agents.reviewer_agent import ReviewerAgent

reviewer = ReviewerAgent(db)

for result in results:
    # Score with RAG
    score_with = await reviewer.review_application_async(
        result["with_rag"]["application_content"]
    )

    # Score without RAG
    score_without = await reviewer.review_application_async(
        result["without_rag"]["application_content"]
    )

    result["scores"] = {
        "with_rag": score_with["score"],
        "without_rag": score_without["score"],
        "improvement": score_with["score"] - score_without["score"]
    }
```

**Acceptance Criteria:**
- ‚úÖ All 20 applications scored
- ‚úÖ Average improvement calculated
- ‚úÖ Statistical significance checked (if sample size allows)

---

### Phase 9: Documentation (30 min)
**Goal:** Document results and production deployment

**Documents:**
- [ ] A/B Testing Results (`AB_TEST_RESULTS.md`)
- [ ] Quality Metrics Report (`QUALITY_METRICS.md`)
- [ ] Production Deployment Guide (update)
- [ ] Iteration 1001 Summary

**Acceptance Criteria:**
- ‚úÖ All results documented
- ‚úÖ Improvement % calculated
- ‚úÖ Recommendations provided

---

## üìä Success Metrics

| Metric | Target | How to Measure |
|--------|--------|----------------|
| **Quality Improvement** | +15% | ReviewerAgent score diff |
| **Problem Detail** | +20% chars | Character count comparison |
| **Solution Specificity** | 80% concrete | Manual review (5-point scale) |
| **Budget Alignment** | 85% FPG-like | Template matching |
| **KPI Measurability** | 80% SMART | SMART criteria checklist |
| **Generation Time** | <90s | Latency measurement |

**Minimum Viable Success:** +10% quality improvement (ReviewerAgent score)

---

## üöÄ Deployment Plan

### Prerequisites
- ‚úÖ Iteration 51 complete
- ‚úÖ Docker installed (for Qdrant)
- ‚úÖ GigaChat API access
- ‚úÖ PostgreSQL running

### Steps
1. Start persistent Qdrant
2. Load collections (one-time)
3. Deploy updated WriterAgent
4. Monitor RAG retrieval logs
5. Collect metrics for 1 week

### Rollback Plan
- Keep old WriterAgent code as backup
- Flag to disable RAG: `rag_enabled=False`
- Revert to Iteration 51 state if quality degrades

---

## üêõ Risks & Mitigation

| Risk | Impact | Mitigation |
|------|--------|------------|
| Quality doesn't improve | HIGH | Keep RAG optional, A/B test first |
| Latency increases | MEDIUM | Cache retrieved examples |
| Qdrant downtime | MEDIUM | Graceful degradation (works without RAG) |
| Token costs increase | LOW | RAG uses minimal tokens (retrieval only) |

---

## üìù Notes

- **Why not Phase 5 (RL)?** RL requires more time (8-10 hours) and should be separate iteration
- **Why 10 test projects?** Statistically significant sample (minimum 10 for t-test)
- **Why persistent Qdrant?** In-memory requires reload, not production-ready
- **Why all sections?** Proof of concept validated, time to go full integration

---

## üîó Related Iterations

- **Iteration 51:** AI Enhancement (RAG proof of concept) ‚úÖ COMPLETE
- **Iteration 1003:** RL Training (optional, future)
- **Iteration 1002:** E2E Tests Complete (higher priority)

---

## ‚úÖ Definition of Done

- [ ] RAG integrated for all 10 sections
- [ ] Persistent Qdrant setup and running
- [ ] 10 projects A/B tested
- [ ] Quality improvement measured (+10% minimum)
- [ ] Results documented
- [ ] Production deployed
- [ ] Metrics tracked for 1 week
- [ ] Code reviewed
- [ ] Git committed

---

**When to Start:** After Iteration 1002 (E2E Tests) or when WriterAgent quality is priority

**Owner:** TBD
**Status:** üìÖ PLANNED
