#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
StandaloneResearcher - Researcher Agent wrapper –¥–ª—è standalone testing

–¶–ï–õ–¨: –û—Ç–¥–µ–ª–∏—Ç—å Researcher –æ—Ç Telegram Bot –∏ database dependency

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê (Iteration 30):
- –ü—Ä–∏–Ω–∏–º–∞–µ—Ç project_data (Dict) –≤–º–µ—Å—Ç–æ anketa_id
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç WebSearchRouter –¥–ª—è Perplexity API
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç research_results (Dict)
- –ë–ï–ó —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ê–≤—Ç–æ—Ä: Claude Code (Iteration 30)
–î–∞—Ç–∞: 2025-10-24
–í–µ—Ä—Å–∏—è: 1.0
"""

import sys
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
import logging
import asyncio
import time
from datetime import datetime
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
project_root = Path(r"C:\SnowWhiteAI\GrantService")
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "shared"))
sys.path.insert(0, str(project_root / "agents"))

from shared.llm.websearch_router import WebSearchRouter
from agents.prompt_loader import ResearcherPromptLoader

logger = logging.getLogger(__name__)


class StandaloneResearcher:
    """
    Standalone Researcher - —Ä–∞–±–æ—Ç–∞–µ—Ç –ë–ï–ó –ë–î –∏ Telegram Bot

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - ResearcherPromptLoader –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    - WebSearchRouter –¥–ª—è Perplexity API
    - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç structured research_results Dict

    Example:
        researcher = StandaloneResearcher(websearch_provider='perplexity')

        project_data = {
            "project_name": "–°—Ç—Ä–µ–ª—å–±–∞ –∏–∑ –ª—É–∫–∞",
            "problem": "–û–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–π...",
            "target_audience": "–¥–µ—Ç–∏ 7-17 –ª–µ—Ç",
            "geography": "–ö–µ–º–µ—Ä–æ–≤–æ",
            "goals": ["–†–∞–∑–≤–∏—Ç–∏–µ —Å–ø–æ—Ä—Ç–∞", "–ü–∞—Ç—Ä–∏–æ—Ç–∏–∑–º"]
        }

        research_results = await researcher.research(project_data)
    """

    def __init__(
        self,
        websearch_provider: str = 'perplexity',
        websearch_fallback: str = 'claude_code',
        db=None  # Optional –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    ):
        """
        Args:
            websearch_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è WebSearch (default: perplexity)
            websearch_fallback: Fallback –ø—Ä–æ–≤–∞–π–¥–µ—Ä (default: claude_code)
            db: Database instance (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
        """
        self.websearch_provider = websearch_provider
        self.websearch_fallback = websearch_fallback
        self.db = db

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º PromptLoader –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.prompt_loader = ResearcherPromptLoader()

        logger.info(f"[StandaloneResearcher] Initialized with {websearch_provider}")

    def _convert_project_data_to_anketa(self, project_data: Dict) -> Dict:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å project_data –≤ —Ñ–æ—Ä–º–∞—Ç anketa –¥–ª—è PromptLoader

        Args:
            project_data: {
                "project_name": "...",
                "problem": "...",
                "target_audience": "...",
                "geography": "...",
                "goals": [...]
            }

        Returns:
            anketa: Dict –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è extract_placeholders()
        """
        # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–Ω–∫–µ—Ç—ã –∏–∑ project_data
        anketa = {
            "interview_data": {
                "project_essence": project_data.get("project_name", ""),
                "problem_and_significance": project_data.get("problem", ""),
                "target_group": project_data.get("target_audience", ""),
                "geography": project_data.get("geography", ""),
                "main_goal": ", ".join(project_data.get("goals", [])) if isinstance(project_data.get("goals"), list) else project_data.get("goals", "")
            }
        }

        return anketa

    def _generate_queries(self, project_data: Dict) -> Dict[str, List[str]]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ project_data

        Args:
            project_data: –î–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞

        Returns:
            {
                'block1': [...],  # 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ –ø—Ä–æ–±–ª–µ–º—É
                'block2': [...],  # 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ –≥–µ–æ–≥—Ä–∞—Ñ–∏—é
                'block3': [...]   # 7 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ —Ü–µ–ª–∏
            }
        """
        logger.info(f"üîç –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è: {project_data.get('project_name', 'Unknown')}")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç anketa
        anketa = self._convert_project_data_to_anketa(project_data)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º placeholders —á–µ—Ä–µ–∑ PromptLoader
        placeholders = self.prompt_loader.extract_placeholders(anketa)

        logger.info(f"üìã Placeholders:")
        logger.info(f"   - –ü–†–û–ë–õ–ï–ú–ê: {placeholders['–ü–†–û–ë–õ–ï–ú–ê'][:50]}...")
        logger.info(f"   - –†–ï–ì–ò–û–ù: {placeholders['–†–ï–ì–ò–û–ù']}")
        logger.info(f"   - –°–§–ï–†–ê: {placeholders['–°–§–ï–†–ê']}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —à–∞–±–ª–æ–Ω—ã –∑–∞–ø—Ä–æ—Å–æ–≤ (—É–∂–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ placeholders!)
        all_queries = {
            'block1': self.prompt_loader.get_block1_queries(placeholders),
            'block2': self.prompt_loader.get_block2_queries(placeholders),
            'block3': self.prompt_loader.get_block3_queries(placeholders)
        }

        logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        logger.info(f"   - –ë–ª–æ–∫ 1: {len(all_queries['block1'])} –∑–∞–ø—Ä–æ—Å–æ–≤")
        logger.info(f"   - –ë–ª–æ–∫ 2: {len(all_queries['block2'])} –∑–∞–ø—Ä–æ—Å–æ–≤")
        logger.info(f"   - –ë–ª–æ–∫ 3: {len(all_queries['block3'])} –∑–∞–ø—Ä–æ—Å–æ–≤")

        return all_queries

    async def _execute_websearch(
        self,
        queries: List[str],
        websearch_router: WebSearchRouter,
        allowed_domains: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å WebSearch –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ Perplexity (batch)

        Args:
            queries: –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
            websearch_router: WebSearchRouter instance
            allowed_domains: –†–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –¥–æ–º–µ–Ω—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            List[Dict]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
        """
        try:
            logger.info(f"   Executing {len(queries)} queries via batch_websearch...")

            # –í—ã–ø–æ–ª–Ω—è–µ–º batch WebSearch
            batch_results = await websearch_router.batch_websearch(
                queries=queries,
                allowed_domains=allowed_domains,
                max_results=5
            )

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ expected format
            results = []
            for i, query in enumerate(queries):
                if i < len(batch_results):
                    result = batch_results[i]
                    results.append({
                        'query': query,
                        'result': result,
                        'status': 'success' if result else 'failed'
                    })
                else:
                    results.append({
                        'query': query,
                        'error': 'No result returned',
                        'status': 'failed'
                    })

            return results

        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Batch search error: {e}")
            # Return all as failed
            return [{
                'query': q,
                'error': str(e),
                'status': 'failed'
            } for q in queries]

    def _structure_results(
        self,
        block1_results: List[Dict],
        block2_results: List[Dict],
        block3_results: List[Dict],
        project_data: Dict
    ) -> Dict[str, Any]:
        """
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç

        Args:
            block1_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–æ–∫–∞ 1 (–ø—Ä–æ–±–ª–µ–º–∞)
            block2_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–æ–∫–∞ 2 (–≥–µ–æ–≥—Ä–∞—Ñ–∏—è)
            block3_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–æ–∫–∞ 3 (—Ü–µ–ª–∏)
            project_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞

        Returns:
            research_results: Structured dict
        """
        def extract_key_facts(results: List[Dict]) -> List[str]:
            """–ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
            facts = []
            for r in results:
                if r.get('status') == 'success' and r.get('result'):
                    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    text = r['result'][:200] if isinstance(r['result'], str) else str(r['result'])[:200]
                    facts.append(text)
            return facts

        research_results = {
            "block1_problem": {
                "summary": f"–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã: {project_data.get('problem', '')[:100]}...",
                "key_facts": extract_key_facts(block1_results),
                "total_sources": len([r for r in block1_results if r.get('status') == 'success']),
                "queries_executed": len(block1_results)
            },
            "block2_geography": {
                "summary": f"–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏: {project_data.get('geography', '')}",
                "key_facts": extract_key_facts(block2_results),
                "total_sources": len([r for r in block2_results if r.get('status') == 'success']),
                "queries_executed": len(block2_results)
            },
            "block3_goals": {
                "summary": f"–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞",
                "key_facts": extract_key_facts(block3_results),
                "total_sources": len([r for r in block3_results if r.get('status') == 'success']),
                "queries_executed": len(block3_results)
            },
            "metadata": {
                "total_queries": len(block1_results) + len(block2_results) + len(block3_results),
                "websearch_provider": self.websearch_provider,
                "timestamp": datetime.now().isoformat(),
                "project_name": project_data.get("project_name", "Unknown")
            }
        }

        return research_results

    async def research(self, project_data: Dict) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ë–ï–ó –ë–î –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

        Args:
            project_data: {
                "project_name": "–°—Ç—Ä–µ–ª—å–±–∞ –∏–∑ –ª—É–∫–∞",
                "problem": "–û–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–π...",
                "target_audience": "–¥–µ—Ç–∏ 7-17 –ª–µ—Ç",
                "geography": "–ö–µ–º–µ—Ä–æ–≤–æ",
                "goals": ["–†–∞–∑–≤–∏—Ç–∏–µ —Å–ø–æ—Ä—Ç–∞", "–ü–∞—Ç—Ä–∏–æ—Ç–∏–∑–º"]
            }

        Returns:
            research_results: {
                "block1_problem": {...},
                "block2_geography": {...},
                "block3_goals": {...},
                "metadata": {
                    "total_queries": 27,
                    "websearch_provider": "perplexity"
                }
            }
        """
        start_time = time.time()

        logger.info("=" * 80)
        logger.info("üîç STANDALONE RESEARCHER - STARTING")
        logger.info("=" * 80)
        logger.info(f"Project: {project_data.get('project_name', 'Unknown')}")
        logger.info(f"Provider: {self.websearch_provider}")
        logger.info("")

        try:
            # 1. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 27 –∑–∞–ø—Ä–æ—Å–æ–≤
            all_queries = self._generate_queries(project_data)

            # 2. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ WebSearchRouter
            async with WebSearchRouter(self.db) as websearch_router:

                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ API
                healthy = await websearch_router.check_health()
                if not healthy:
                    logger.warning(f"‚ö†Ô∏è WebSearch provider {self.websearch_provider} not responding")

                # –ë–õ–û–ö 1: –ü—Ä–æ–±–ª–µ–º–∞ (10 –∑–∞–ø—Ä–æ—Å–æ–≤)
                logger.info("üîç –ë–õ–û–ö 1: –ü—Ä–æ–±–ª–µ–º–∞ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (10 –∑–∞–ø—Ä–æ—Å–æ–≤)")
                block1_results = await self._execute_websearch(
                    queries=all_queries['block1'],
                    websearch_router=websearch_router,
                    allowed_domains=[
                        'rosstat.gov.ru',
                        'fedstat.ru',
                        'government.ru',
                        'nationalprojects.ru'
                    ]
                )
                logger.info(f"‚úÖ –ë–ª–æ–∫ 1 –∑–∞–≤–µ—Ä—à—ë–Ω: {len(block1_results)} –∑–∞–ø—Ä–æ—Å–æ–≤")

                # –ë–õ–û–ö 2: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è (10 –∑–∞–ø—Ä–æ—Å–æ–≤)
                logger.info("üåç –ë–õ–û–ö 2: –ì–µ–æ–≥—Ä–∞—Ñ–∏—è –∏ —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è (10 –∑–∞–ø—Ä–æ—Å–æ–≤)")
                block2_results = await self._execute_websearch(
                    queries=all_queries['block2'],
                    websearch_router=websearch_router
                )
                logger.info(f"‚úÖ –ë–ª–æ–∫ 2 –∑–∞–≤–µ—Ä—à—ë–Ω: {len(block2_results)} –∑–∞–ø—Ä–æ—Å–æ–≤")

                # –ë–õ–û–ö 3: –¶–µ–ª–∏ (7 –∑–∞–ø—Ä–æ—Å–æ–≤)
                logger.info("üéØ –ë–õ–û–ö 3: –¶–µ–ª–∏ –∏ –∑–∞–¥–∞—á–∏ –ø—Ä–æ–µ–∫—Ç–∞ (7 –∑–∞–ø—Ä–æ—Å–æ–≤)")
                block3_results = await self._execute_websearch(
                    queries=all_queries['block3'],
                    websearch_router=websearch_router
                )
                logger.info(f"‚úÖ –ë–ª–æ–∫ 3 –∑–∞–≤–µ—Ä—à—ë–Ω: {len(block3_results)} –∑–∞–ø—Ä–æ—Å–æ–≤")

            # 3. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            research_results = self._structure_results(
                block1_results=block1_results,
                block2_results=block2_results,
                block3_results=block3_results,
                project_data=project_data
            )

            duration = time.time() - start_time

            logger.info("")
            logger.info("=" * 80)
            logger.info("‚úÖ STANDALONE RESEARCHER - COMPLETED")
            logger.info("=" * 80)
            logger.info(f"Duration: {duration:.1f}s")
            logger.info(f"Total queries: {research_results['metadata']['total_queries']}")
            logger.info(f"Block 1 sources: {research_results['block1_problem']['total_sources']}")
            logger.info(f"Block 2 sources: {research_results['block2_geography']['total_sources']}")
            logger.info(f"Block 3 sources: {research_results['block3_goals']['total_sources']}")
            logger.info("")

            return research_results

        except Exception as e:
            logger.error(f"‚ùå Research failed: {e}")
            import traceback
            traceback.print_exc()
            raise


if __name__ == "__main__":
    """
    Quick test of StandaloneResearcher
    """
    import sys
    if sys.platform == 'win32':
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Test project data
    test_project_data = {
        "project_name": "–°—Ç—Ä–µ–ª—å–±–∞ –∏–∑ –ª—É–∫–∞ - —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ-–ø–∞—Ç—Ä–∏–æ—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å–ø–∏—Ç–∞–Ω–∏–µ",
        "problem": "–£—Ä–æ–∫–∏ —Ñ–∏–∑–∫—É–ª—å—Ç—É—Ä—ã –Ω–µ –º–æ–≥—É—Ç –≤ –ø–æ–ª–Ω–æ–π –º–µ—Ä–µ –ø—Ä–∏–≤–ª–µ—á—å –¥–µ—Ç–µ–π –∫ —Å–ø–æ—Ä—Ç—É",
        "target_audience": "–î–µ—Ç–∏ –∏ –º–æ–ª–æ–¥—ë–∂—å 10-21 –ª–µ—Ç",
        "geography": "–≥. –ö–µ–º–µ—Ä–æ–≤–æ",
        "goals": ["–°–ø–æ—Ä—Ç–∏–≤–Ω–æ-–ø–∞—Ç—Ä–∏–æ—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å–ø–∏—Ç–∞–Ω–∏–µ", "–ü—Ä–æ–ø–∞–≥–∞–Ω–¥–∞ –ó–û–ñ", "–û–±—É—á–µ–Ω–∏–µ —Å—Ç—Ä–µ–ª—å–±–µ"]
    }

    async def main():
        researcher = StandaloneResearcher(websearch_provider='perplexity')
        research_results = await researcher.research(test_project_data)

        print("\nüìä RESEARCH RESULTS:")
        print(json.dumps(research_results, indent=2, ensure_ascii=False))

    asyncio.run(main())
