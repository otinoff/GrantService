# Local Testing Plan: Iteration 38

**Date:** 2025-10-25
**Status:** ‚è≥ READY TO START
**Iteration:** 38 - Synthetic Corpus Generator

---

## üéØ OBJECTIVE

–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å Iteration 38 –ª–æ–∫–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥ git commit –∏ production deployment.

**–¶–µ–ª—å:** –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, —Ç–æ–∫–µ–Ω—ã —Ç—Ä–∞—Ç—è—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è.

---

## üìã PREREQUISITES

### 1. Environment Check

```bash
# Verify we're in correct directory
cd C:\SnowWhiteAI\GrantService

# Check Python environment
python --version  # Should be Python 3.10+

# Check database is running
psql -h localhost -p 5432 -U postgres -d grantservice -c "SELECT 1"
```

### 2. Bot Running

```bash
# Make sure telegram bot is running
# Check process or restart if needed
python telegram-bot/main.py
```

### 3. User Setup

**Test User:** andrew_otinoff (or current Telegram user)

**Prerequisites:**
- [ ] User has at least 1 completed anketa (for template)
- [ ] User is authorized (has access token)
- [ ] User has GigaChat API access

---

## üß™ TEST PLAN

### Phase 1: Basic Functionality Tests

#### Test 1.1: Generate 1 Synthetic Anketa

**Command:**
```
/generate_synthetic_anketa 1 medium
```

**Expected Result:**
```
üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é 1 —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∞–Ω–∫–µ—Ç...
üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: GIGACHAT-LITE
üìä –ö–∞—á–µ—Å—Ç–≤–æ: medium
‚è±Ô∏è –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~15 —Å–µ–∫—É–Ω–¥

‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∞–Ω–∫–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã!

üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
‚Ä¢ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: 1 –∞–Ω–∫–µ—Ç
‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î: 1 –∞–Ω–∫–µ—Ç
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~1,500 (GigaChat Lite)

–ö–∞—á–µ—Å—Ç–≤–æ:
‚Ä¢ Low: 0 –∞–Ω–∫–µ—Ç
‚Ä¢ Medium: 1 –∞–Ω–∫–µ—Ç
‚Ä¢ High: 0 –∞–Ω–∫–µ—Ç

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /corpus_stats –¥–ª—è –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
```

**Verification:**
```sql
-- Check in database
SELECT anketa_id, status, completed_at
FROM sessions
WHERE telegram_id = <USER_ID>
ORDER BY completed_at DESC
LIMIT 1;

-- Check interview_data contains synthetic flag
SELECT interview_data->>'synthetic' as is_synthetic,
       interview_data->>'quality_target' as quality,
       interview_data->>'project_name' as project
FROM sessions
WHERE telegram_id = <USER_ID>
  AND interview_data->>'synthetic' = 'true'
ORDER BY completed_at DESC
LIMIT 1;
```

**Pass Criteria:**
- [x] Bot responds within 30 seconds
- [x] No errors in bot logs
- [x] Anketa saved to database
- [x] `synthetic: true` flag present
- [x] `quality_target: 'medium'` present
- [x] Token usage shown (~1,500 Lite)

---

#### Test 1.2: Generate 5 Synthetic Anketas (Mixed Quality)

**Command:**
```
/generate_synthetic_anketa 5
```

**Expected Result:**
```
üìä –ö–∞—á–µ—Å—Ç–≤–æ: mixed (20% low, 50% medium, 30% high)

‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∞–Ω–∫–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã!

üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
‚Ä¢ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: 5 –∞–Ω–∫–µ—Ç
‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î: 5 –∞–Ω–∫–µ—Ç
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: ~7,500 (GigaChat Lite)

–ö–∞—á–µ—Å—Ç–≤–æ:
‚Ä¢ Low: 1 –∞–Ω–∫–µ—Ç
‚Ä¢ Medium: 3 –∞–Ω–∫–µ—Ç  (50% of 5 = 2.5 ‚âà 3)
‚Ä¢ High: 1 –∞–Ω–∫–µ—Ç   (30% of 5 = 1.5 ‚âà 1)
```

**Verification:**
```sql
-- Count synthetic anketas by quality
SELECT
    interview_data->>'quality_target' as quality,
    COUNT(*) as count
FROM sessions
WHERE telegram_id = <USER_ID>
  AND interview_data->>'synthetic' = 'true'
GROUP BY quality;
```

**Pass Criteria:**
- [x] 5 anketas generated
- [x] Distribution approximately matches (20/50/30)
- [x] All have different project names
- [x] Token usage ~7,500 Lite

---

#### Test 1.3: Batch Audit 5 Anketas

**Command:**
```
/batch_audit_anketas 5
```

**Expected Result:**
```
üîÑ –ó–∞–ø—É—Å–∫–∞—é batch –∞—É–¥–∏—Ç 5 –∞–Ω–∫–µ—Ç...
üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: GigaChat Max (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è Sber500!)
üìä –û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: ~10,000 Max tokens
‚è±Ô∏è –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~150 —Å–µ–∫—É–Ω–¥

‚úÖ Batch –∞—É–¥–∏—Ç –∑–∞–≤–µ—Ä—à—ë–Ω!

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
‚Ä¢ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: 5 –∞–Ω–∫–µ—Ç
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: 6.8/10  (depends on quality)

–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:
‚Ä¢ ‚úÖ –û–¥–æ–±—Ä–µ–Ω–æ (‚â•7.0): 2-3
‚Ä¢ ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏ (5.0-6.9): 2-3
‚Ä¢ ‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–æ (<5.0): 0-1

–¢–æ–∫–µ–Ω—ã:
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: ~10,000 Max tokens
‚Ä¢ –°—Ç–æ–∏–º–æ—Å—Ç—å: ~10 —Ä—É–± (–∏–∑ 1,987,948 –¥–æ—Å—Ç—É–ø–Ω—ã—Ö)

üí° –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ Sber500!
```

**Verification:**
```sql
-- Check audit results
SELECT
    s.anketa_id,
    ar.average_score,
    ar.approval_status,
    s.interview_data->>'quality_target' as target_quality
FROM sessions s
JOIN auditor_results ar ON s.id = ar.session_id
WHERE s.telegram_id = <USER_ID>
  AND s.interview_data->>'synthetic' = 'true'
ORDER BY ar.created_at DESC
LIMIT 5;
```

**Pass Criteria:**
- [x] 5 anketas audited
- [x] All have `average_score` in database
- [x] All have `approval_status` set
- [x] Scores correlate with quality targets:
  - Low: ~4-6/10
  - Medium: ~6-8/10
  - High: ~7-9/10
- [x] Token usage ~10,000 Max

---

#### Test 1.4: Corpus Statistics

**Command:**
```
/corpus_stats
```

**Expected Result:**
```
üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä–ø—É—Å–∞ –∞–Ω–∫–µ—Ç

–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: 7  (1 real + 6 synthetic)
‚Ä¢ –†–µ–∞–ª—å–Ω—ã–µ: 1
‚Ä¢ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ: 6

–ê—É–¥–∏—Ç:
‚Ä¢ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: 5
‚Ä¢ –ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: 2  (1 synthetic + 1 real if not audited)
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: 6.8/10

–ö–∞—á–µ—Å—Ç–≤–æ (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ):
‚Ä¢ ‚úÖ –û–¥–æ–±—Ä–µ–Ω–æ: 2-3
‚Ä¢ ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏: 2-3
‚Ä¢ ‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: 0-1

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤:
‚Ä¢ GigaChat Lite: ~9,000
‚Ä¢ GigaChat Max: ~10,000

üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:
‚Ä¢ /generate_synthetic_anketa [N] - —Å–æ–∑–¥–∞—Ç—å –µ—â—ë
‚Ä¢ /batch_audit_anketas [N] - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ
```

**Pass Criteria:**
- [x] Correct count of anketas
- [x] Correct synthetic vs real split
- [x] Correct audit statistics
- [x] Token estimates reasonable

---

### Phase 2: Edge Cases & Error Handling

#### Test 2.1: Invalid Parameters

**Commands:**
```
/generate_synthetic_anketa 0
/generate_synthetic_anketa 101
/generate_synthetic_anketa abc
/generate_synthetic_anketa 10 invalid_quality
/batch_audit_anketas -1
/batch_audit_anketas 501
```

**Expected Results:**
- Error messages for each invalid input
- No anketas generated
- No database writes

---

#### Test 2.2: No Template Anketas Available

**Scenario:** New user with no completed anketas

**Command:**
```
/generate_synthetic_anketa 1
```

**Expected Result:**
```
‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –∞–Ω–∫–µ—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∫ —à–∞–±–ª–æ–Ω—ã.

–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –∞–Ω–∫–µ—Ç—É —á–µ—Ä–µ–∑ /start
```

---

#### Test 2.3: No Unaudited Anketas

**Scenario:** All anketas already audited

**Command:**
```
/batch_audit_anketas 10
```

**Expected Result:**
```
‚ùå –ù–µ—Ç –∞–Ω–∫–µ—Ç –¥–ª—è –∞—É–¥–∏—Ç–∞.

–í—Å–µ –≤–∞—à–∏ –∞–Ω–∫–µ—Ç—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã.
```

---

### Phase 3: Performance & Load Tests

#### Test 3.1: Generate 10 Anketas (Stress Test)

**Command:**
```
/generate_synthetic_anketa 10
```

**Expected Behavior:**
- Progress updates every 10 anketas (won't see for 10, but code tested)
- ~150 seconds total time (15 sec/anketa)
- ~15,000 Lite tokens used
- All 10 saved successfully

---

#### Test 3.2: Batch Audit 20 Anketas

**Command:**
```
/batch_audit_anketas 20
```

**Expected Behavior:**
- Progress update at 10/20
- ~10 minutes total time (30 sec/anketa)
- ~40,000 Max tokens used
- All 20 audited successfully

---

### Phase 4: Integration Tests

#### Test 4.1: Full Workflow

**Steps:**
1. `/generate_synthetic_anketa 10 medium`
2. `/corpus_stats` (verify 10 synthetic, 0 audited)
3. `/batch_audit_anketas 10`
4. `/corpus_stats` (verify 10 synthetic, 10 audited)
5. `/my_anketas` (verify list shows synthetic anketas)

**Expected:**
- Full pipeline works end-to-end
- Database consistent
- Token counts accurate

---

#### Test 4.2: Existing Commands Still Work

**Verify no regressions:**

```
/my_anketas          # Should still work
/audit_anketa        # Should still work on real anketas
/delete_anketa       # Should work on synthetic anketas
/generate_grant      # Should work with synthetic anketa
```

---

## üìä SUCCESS CRITERIA

### Must Pass:

- [x] All basic functionality tests (1.1-1.4) pass
- [x] No Python exceptions in bot logs
- [x] Database integrity maintained
- [x] Token usage within expected ranges (¬±20%)
- [x] Response times acceptable (<30s for single, <5min for batch)

### Nice to Have:

- [x] All edge case tests (2.1-2.3) pass
- [x] Performance tests (3.1-3.2) complete without errors
- [x] Integration tests (4.1-4.2) pass
- [x] No regressions in existing commands

---

## üêõ KNOWN ISSUES TO WATCH

### Potential Issues:

1. **GigaChat API Rate Limiting:**
   - If generating 100+ anketas, may hit rate limits
   - Solution: Add exponential backoff retry logic

2. **Database Connection Pooling:**
   - Batch operations may exhaust connection pool
   - Solution: Ensure connections are closed properly

3. **Memory Usage:**
   - Generating 100 embeddings in memory might be heavy
   - Solution: Process in smaller batches

4. **JSON Parsing from GigaChat:**
   - Already fixed in AnketaSyntheticGenerator (lines 262-311)
   - But watch for new edge cases

---

## üìù TEST EXECUTION LOG

### Test Session: 2025-10-25

| Test | Command | Status | Notes |
|------|---------|--------|-------|
| 1.1 | `/generate_synthetic_anketa 1 medium` | ‚è≥ | |
| 1.2 | `/generate_synthetic_anketa 5` | ‚è≥ | |
| 1.3 | `/batch_audit_anketas 5` | ‚è≥ | |
| 1.4 | `/corpus_stats` | ‚è≥ | |
| 2.1 | Invalid params | ‚è≥ | |
| 2.2 | No templates | ‚è≥ | |
| 2.3 | No unaudited | ‚è≥ | |
| 3.1 | Generate 10 | ‚è≥ | |
| 3.2 | Audit 20 | ‚è≥ | |
| 4.1 | Full workflow | ‚è≥ | |
| 4.2 | Regression | ‚è≥ | |

---

## üöÄ NEXT STEPS AFTER TESTING

### If All Tests Pass:

1. **Document Results:**
   - Update test log with results
   - Note any issues found and fixes applied
   - Calculate actual token usage

2. **Git Commit:**
   ```bash
   git add .
   git commit -m "Iteration 38: Synthetic Corpus Generator

   Features:
   - /generate_synthetic_anketa: Generate 1-100 synthetic anketas (GigaChat Lite)
   - /batch_audit_anketas: Batch audit using GigaChat Max
   - /corpus_stats: Show corpus statistics

   Testing:
   - All tests passed locally
   - Token usage verified (~350K per 100 anketas)
   - Database integration working

   Files:
   - agents/anketa_synthetic_generator.py (NEW)
   - telegram-bot/handlers/anketa_management_handler.py (+442 lines)
   - telegram-bot/main.py (+20 lines)
   - data/database/models.py (+97 lines)

   Iteration: 38
   Status: TESTED LOCALLY, READY FOR PRODUCTION"
   ```

3. **Prepare for Production:**
   - Test on production server (optional)
   - Monitor first production run
   - Document token usage

4. **Run Production Batch:**
   - Generate 100 synthetic anketas
   - Audit 100 anketas
   - Spend ~350K tokens
   - Demonstrate to Sber500

---

### If Tests Fail:

1. **Debug Issues:**
   - Check bot logs for exceptions
   - Verify database queries
   - Test LLM API responses

2. **Fix and Retest:**
   - Apply fixes
   - Re-run failed tests
   - Verify no regressions

3. **Document Issues:**
   - Note issues found
   - Document fixes applied
   - Update testing plan if needed

---

## üìÑ FILES TO MONITOR

### Log Files:

```bash
# Bot logs
telegram-bot/logs/*.log

# Database logs
/var/log/postgresql/*.log  (on server)

# GigaChat API logs
Check bot output for API errors
```

### Database Tables:

```sql
-- Sessions (anketas)
SELECT COUNT(*) FROM sessions WHERE interview_data->>'synthetic' = 'true';

-- Audits
SELECT COUNT(*) FROM auditor_results;

-- Check for orphaned records
SELECT COUNT(*) FROM sessions s
LEFT JOIN auditor_results ar ON s.id = ar.session_id
WHERE ar.id IS NULL AND s.status = 'completed';
```

---

**Created:** 2025-10-25
**Purpose:** Local testing plan for Iteration 38
**Status:** READY TO EXECUTE ‚úÖ
**Next Step:** Start Test 1.1
