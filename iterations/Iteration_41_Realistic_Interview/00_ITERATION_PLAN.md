# Iteration 41: Realistic Interactive Interview Simulation

**Date:** 2025-10-25
**Status:** üöÄ PLANNED
**Iteration:** 41 - Realistic Interview Simulation

---

## üéØ OBJECTIVE

**Goal:** –°–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å 100 —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é –≥–¥–µ InteractiveInterviewer –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã, SyntheticUserSimulator –æ—Ç–≤–µ—á–∞–µ—Ç, –∏ AnketaValidator –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ.

**Success Criteria:**
- ‚úÖ 100 realistic interviews completed (20 low, 50 medium, 30 high quality)
- ‚úÖ All interviews saved to database
- ‚úÖ All 100 anketas audited by AnketaValidator
- ‚úÖ Quality correlation verified: low/medium/high ‚Üí audit score
- ‚úÖ Database linking works: sessions ‚Üî auditor_results
- ‚úÖ Ready for RL Optimization (state/action/reward data collected)

---

## üèóÔ∏è ARCHITECTURE

### **3-Agent System:**

```
InteractiveInterviewer ‚Üí SyntheticUserSimulator ‚Üí AnketaValidator
     (–≤–æ–ø—Ä–æ—Å—ã)              (–æ—Ç–≤–µ—Ç—ã)                (–∞—É–¥–∏—Ç)
```

### **Component 1: InteractiveInterviewer**
**Status:** ‚úÖ Already exists

**Role:** –ó–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç—ã

**Methods:**
```python
class InteractiveInterviewer:
    async def ask_question(self, field_name: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—è"""

    async def validate_answer(self, field_name: str, answer: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞"""
```

---

### **Component 2: SyntheticUserSimulator**
**Status:** üÜï NEW - Create in this iteration

**Role:** –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã

**Implementation:**
```python
class SyntheticUserSimulator:
    """–°–∏–º—É–ª–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –≥—Ä–∞–Ω—Ç–æ–∑–∞—è–≤–∏—Ç–µ–ª—è"""

    def __init__(self, quality_level: str, context: dict):
        """
        Args:
            quality_level: 'low', 'medium', 'high'
            context: {
                'region': '–ú–æ—Å–∫–≤–∞',
                'topic': '–º–æ–ª–æ–¥—ë–∂—å',
                'organization': '–ê–ù–û "–ú–æ–ª–æ–¥–µ–∂–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã"'
            }
        """
        self.quality_level = quality_level
        self.context = context
        self.llm = UnifiedLLMClient(provider='gigachat', model='GigaChat')

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –∫–∞—á–µ—Å—Ç–≤–∞
        self.quality_params = {
            'low': {
                'temperature': 0.9,
                'max_tokens': 500,
                'detail_instruction': '–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø—Ä–æ—Å—Ç–æ (100-200 —Å–ª–æ–≤). –ò—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏.'
            },
            'medium': {
                'temperature': 0.7,
                'max_tokens': 1500,
                'detail_instruction': '–û—Ç–≤–µ—Ç—å —Å–æ —Å—Ä–µ–¥–Ω–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π (200-400 —Å–ª–æ–≤). –í–∫–ª—é—á–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏ 1-2 –ø—Ä–∏–º–µ—Ä–∞.'
            },
            'high': {
                'temperature': 0.5,
                'max_tokens': 3000,
                'detail_instruction': '–û—Ç–≤–µ—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏, —Ü–∏—Ñ—Ä–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—è–º–∏ (400-800 —Å–ª–æ–≤).'
            }
        }

    async def answer_question(self, question: str, field_name: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        params = self.quality_params[self.quality_level]

        prompt = f"""–¢—ã - –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ù–ö–û, –ø–æ–¥–∞—ë—à—å –∑–∞—è–≤–∫—É –Ω–∞ –≥—Ä–∞–Ω—Ç.

–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–≤–æ–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞:
- –†–µ–≥–∏–æ–Ω: {self.context['region']}
- –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è: {self.context['organization']}
- –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {self.context['topic']}

–í–æ–ø—Ä–æ—Å –æ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –≥—Ä–∞–Ω—Ç–æ–≤–æ–≥–æ —Ñ–æ–Ω–¥–∞:
"{question}"

{params['detail_instruction']}

–û—Ç–≤–µ—á–∞–π –∫–∞–∫ —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞—è–≤–∏—Ç–µ–ª—å –≥—Ä–∞–Ω—Ç–∞ - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ.
–ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–µ—Ü–∏—Ñ–∏–∫—É —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –ù–ö–û –∏ –≥—Ä–∞–Ω—Ç–æ–≤—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º.

–¢–≤–æ–π –æ—Ç–≤–µ—Ç:"""

        response = await self.llm.generate_text(
            prompt=prompt,
            max_tokens=params['max_tokens']
        )

        return response.strip()
```

---

### **Component 3: AnketaValidator**
**Status:** ‚úÖ Already exists

**Role:** –ê—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –∞–Ω–∫–µ—Ç—ã

**Methods:**
```python
validator = AnketaValidator(llm_provider='gigachat', db=db)
result = await validator.validate(interview_data, user_id)

# Returns:
{
    'score': 7.5,  # 0-10
    'approval_status': 'approved',  # or 'needs_revision', 'rejected'
    'individual_scores': {
        'relevance': 8,
        'clarity': 7,
        'feasibility': 8,
        'impact': 7,
        'budget': 7
    }
}
```

---

## üìã WORKFLOW

### **Single Interview Flow:**

```python
async def conduct_realistic_interview(quality_level: str) -> dict:
    """–ü—Ä–æ–≤–æ–¥–∏—Ç –æ–¥–Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é"""

    # 1. –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞
    context = {
        'region': random.choice(REGIONS),
        'topic': random.choice(TOPICS),
        'organization': generate_org_name()
    }

    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤
    interviewer = InteractiveInterviewer(db=db)
    user_simulator = SyntheticUserSimulator(
        quality_level=quality_level,
        context=context
    )

    # 3. –ü—Ä–æ–≤–æ–¥–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é (15 –≤–æ–ø—Ä–æ—Å–æ–≤)
    interview_data = {}
    conversation_log = []

    for field_name in REQUIRED_FIELDS:
        # –í–æ–ø—Ä–æ—Å –æ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞
        question = await interviewer.ask_question(field_name)
        conversation_log.append({'role': 'interviewer', 'text': question})

        # –û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        answer = await user_simulator.answer_question(question, field_name)
        conversation_log.append({'role': 'user', 'text': answer})

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª–∏–Ω—ã
        is_valid = await interviewer.validate_answer(field_name, answer)
        if not is_valid:
            # (–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å retry –ª–æ–≥–∏–∫—É)
            pass

        interview_data[field_name] = answer

    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∫–µ—Ç—É
    anketa_id = db.save_anketa({
        'interview_data': interview_data,
        'metadata': {
            'quality_target': quality_level,
            'context': context,
            'conversation_log': conversation_log
        }
    })

    # 5. –ê—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞
    validator = AnketaValidator(llm_provider='gigachat', db=db)
    audit_result = await validator.validate(interview_data, user_id)

    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞—É–¥–∏—Ç–∞
    db.save_audit_result(anketa_id, audit_result)

    return {
        'anketa_id': anketa_id,
        'quality_target': quality_level,
        'audit_score': audit_result['score'],
        'approval_status': audit_result['approval_status'],
        'context': context
    }
```

---

## üé¨ TEST PLAN

### **Test 1: Low Quality Interviews (20 anketas)**

**Parameters:**
- quality_level = 'low'
- temperature = 0.9
- max_tokens = 500
- Detail level: minimal

**Expected Results:**
```python
{
    'count': 20,
    'avg_score': 4.0-6.0,
    'approval_distribution': {
        'approved': 2 (10%),
        'needs_revision': 8 (40%),
        'rejected': 10 (50%)
    }
}
```

---

### **Test 2: Medium Quality Interviews (50 anketas)**

**Parameters:**
- quality_level = 'medium'
- temperature = 0.7
- max_tokens = 1500
- Detail level: normal

**Expected Results:**
```python
{
    'count': 50,
    'avg_score': 6.5-7.5,
    'approval_distribution': {
        'approved': 30 (60%),
        'needs_revision': 15 (30%),
        'rejected': 5 (10%)
    }
}
```

---

### **Test 3: High Quality Interviews (30 anketas)**

**Parameters:**
- quality_level = 'high'
- temperature = 0.5
- max_tokens = 3000
- Detail level: detailed

**Expected Results:**
```python
{
    'count': 30,
    'avg_score': 8.0-9.5,
    'approval_distribution': {
        'approved': 27 (90%),
        'needs_revision': 3 (10%),
        'rejected': 0 (0%)
    }
}
```

---

## üìä DATABASE SCHEMA

### **After Iteration 41:**

```sql
-- sessions table (100 new rows):
sessions (
    id SERIAL PRIMARY KEY,
    anketa_id VARCHAR UNIQUE,  -- #AN-20251025-iter41_user-001, ..., -100
    telegram_id BIGINT,        -- 999999997 (new test user for Iteration 41)
    status VARCHAR,             -- 'completed'
    interview_data JSONB,       -- {...15 fields...}
    metadata JSONB,             -- {quality_target, context, conversation_log}
    created_at TIMESTAMP
)

-- auditor_results table (100 new rows):
auditor_results (
    id SERIAL PRIMARY KEY,
    session_id INTEGER,         -- FK ‚Üí sessions.id
    average_score NUMERIC,      -- 0-10
    approval_status VARCHAR,    -- 'approved', 'needs_revision', 'rejected'
    individual_scores JSONB,    -- {relevance, clarity, feasibility, impact, budget}
    created_at TIMESTAMP
)
```

### **Linking Query:**

```sql
SELECT
    s.anketa_id,
    s.metadata->>'quality_target' as quality,
    s.metadata->'context'->>'region' as region,
    s.metadata->'context'->>'topic' as topic,
    ar.average_score,
    ar.approval_status
FROM sessions s
JOIN auditor_results ar ON s.id = ar.session_id
WHERE s.telegram_id = 999999997  -- Iteration 41 test user
ORDER BY s.created_at;
```

---

## üìà TOKEN BUDGET

### **Per Interview:**

```
1 interview = 15 questions √ó 2 LLM calls per question
15 √ó (User Answer: ~500 tokens + Optional Retry: ~200 tokens) = ~10,500 tokens per interview

Audit: ~2,000 tokens

Total per interview: ~12,500 tokens
```

### **Total for 100 Interviews:**

```
100 interviews √ó 12,500 tokens = 1,250,000 tokens

Distribution:
- Low (20): 20 √ó 12,500 = 250,000 tokens
- Medium (50): 50 √ó 12,500 = 625,000 tokens
- High (30): 30 √ó 12,500 = 375,000 tokens

Model: GigaChat (user answers + audit)
Cost: ~$125 rubles (~1.25M tokens)
```

**Note:** –≠—Ç–æ –¥–æ—Ä–æ–≥–æ, –Ω–æ –º—ã –ø–æ–ª—É—á–∞–µ–º:
- 100 realistic interviews
- 100 audit results
- Full conversation logs
- RL-ready dataset (state/action/reward)

**Optimization:** –ú–æ–∂–µ–º –Ω–∞—á–∞—Ç—å —Å –º–µ–Ω—å—à–µ–≥–æ:
- **Phase 1:** 30 interviews (10+15+5) ‚Üí ~375K tokens (~$40)
- **Phase 2:** –ï—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Üí –æ—Å—Ç–∞–ª—å–Ω—ã–µ 70

---

## üî¨ RL READINESS

### **State:**
```python
state = {
    'quality_target': 'medium',
    'region': '–ú–æ—Å–∫–≤–∞',
    'topic': '–º–æ–ª–æ–¥—ë–∂—å',
    'organization_type': '–ê–ù–û'
}
```

### **Action:**
```python
action = {
    'temperature': 0.7,
    'max_tokens': 1500,
    'detail_instruction': 'normal'
}
```

### **Reward:**
```python
reward = audit_score  # 0-10 from AnketaValidator
```

### **RL Model:**
```python
Q(state, action) ‚Üí expected_reward

# Grid search:
for quality in ['low', 'medium', 'high']:
    for temp in [0.3, 0.5, 0.7, 0.9]:
        for max_tokens in [500, 1000, 1500, 2000]:
            # Generate + Audit
            # Find optimal (temp, max_tokens) for each quality_level
```

---

## üìù FILES TO CREATE

1. **`00_ITERATION_PLAN.md`** ‚Üê THIS FILE
2. **`agents/synthetic_user_simulator.py`** - New SyntheticUserSimulator class
3. **`test_iteration_41_realistic_interview.py`** - Automated test script
4. **`01_INTERVIEW_RESULTS.md`** - Test execution log
5. **`02_AUDIT_STATISTICS.md`** - Audit score analysis
6. **`03_QUALITY_CORRELATION.md`** - quality_level ‚Üí score correlation
7. **`04_CONVERSATION_SAMPLES.md`** - Sample conversations
8. **`05_RL_DATASET.json`** - RL training data (state/action/reward)
9. **`06_SUMMARY.md`** - Final iteration summary

---

## üöÄ EXECUTION PLAN

### **Phase 1: Implementation (30 minutes)**

1. Create `agents/synthetic_user_simulator.py`
2. Create `test_iteration_41_realistic_interview.py`
3. Test single interview (verify workflow)

### **Phase 2: Small Batch Test (30 minutes, ~$10)**

Run 30 interviews:
- 10 low quality
- 15 medium quality
- 5 high quality

Verify:
- ‚úÖ Conversation flow works
- ‚úÖ Answers are realistic
- ‚úÖ Audit scores correlate with quality_level
- ‚úÖ Database linking works

### **Phase 3: Full Run (90-120 minutes, ~$125)**

Run remaining 70 interviews:
- 10 more low
- 35 more medium
- 25 more high

Total: 100 interviews

### **Phase 4: Analysis (30 minutes)**

- Score distribution analysis
- Quality correlation
- Regional/topic patterns
- RL dataset preparation

---

## üéØ SUCCESS CRITERIA

### **Must Pass:**

1. ‚úÖ 100 interviews completed successfully
2. ‚úÖ All anketas saved to database
3. ‚úÖ All 100 audits completed
4. ‚úÖ Quality correlation verified:
   - low ‚Üí 4-6 avg score
   - medium ‚Üí 6.5-7.5 avg score
   - high ‚Üí 8-9.5 avg score
5. ‚úÖ Database linking works (sessions ‚Üî auditor_results)

### **Nice to Have:**

- [ ] Conversation logs saved for review
- [ ] Regional/topic patterns identified
- [ ] RL dataset exported to JSON
- [ ] Sample conversations documented

---

## üí° KEY INNOVATIONS

### **Why This is Better Than Iteration 39:**

1. **Avoids GigaChat Truncation:** Short prompts in dialog format
2. **Tests Real Workflow:** Full Interviewer ‚Üí User ‚Üí Validator cycle
3. **Realistic Data:** Natural conversation flow, not batch generation
4. **RL Ready:** Clean state/action/reward structure
5. **Quality Control:** Immediate audit feedback per interview

### **Comparison:**

| Iteration | Approach | Issues | RL Ready |
|-----------|----------|--------|----------|
| 38 | Batch generator | ‚ùå No diversity | ‚ùå No |
| 39 | Batch generator | ‚ùå GigaChat truncation | ‚ùå Failed |
| 40 | Hardcoded tests | ‚ùå Not realistic | ‚ùå No |
| **41** | **Realistic dialog** | ‚úÖ **All fixed** | ‚úÖ **YES** |

---

## üìå NEXT STEPS (After Iteration 41)

### **Iteration 42: RL Optimization**

Use Iteration 41 data to:
1. Analyze quality_level ‚Üí score correlation
2. Grid search for optimal temperature per quality
3. Test different prompt variants
4. Implement simple policy gradient

### **Iteration 43: Grant Writing**

Use approved anketas from Iteration 41 to:
1. Generate grant documents
2. Test GrantWriter agent
3. Verify full workflow: Interview ‚Üí Audit ‚Üí Grant

---

**Created:** 2025-10-25
**Status:** PLANNED
**Ready to Execute:** ‚úÖ YES

**LET'S CREATE 100 REALISTIC INTERVIEWS! üöÄ**
