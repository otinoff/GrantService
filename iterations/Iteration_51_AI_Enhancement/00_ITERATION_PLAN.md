# Iteration 51: AI Enhancement - Embeddings + RL

**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:** 2025-10-26
**–î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Phase 1:** 2025-10-26
**–°—Ç–∞—Ç—É—Å:** ‚úÖ PHASE 1 COMPLETE
**–¶–µ–ª—å:** –ü–æ—Ç—Ä–∞—Ç–∏—Ç—å 3 –º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤ GigaChat Embeddings –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ 3 –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π + –¥–æ–±–∞–≤–∏—Ç—å RL –¥–ª—è InterviewerAgent

---

## üéØ –ó–∞–¥–∞—á–∞

**–ë–∏–∑–Ω–µ—Å-—Ü–µ–ª—å:** –ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞ –æ—Ü–µ–Ω–∫–µ Sber500 —Å–µ—Ä—å—ë–∑–Ω—ã–π AI-–ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞ 2 –¥–Ω—è

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ü–µ–ª–∏:**
1. –°–æ–∑–¥–∞—Ç—å 3 –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å GigaChat Embeddings (1024-dim)
2. –ü–æ—Ç—Ä–∞—Ç–∏—Ç—å 3 –º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤ embeddings + 2 –º–ª–Ω —Ä–µ–∑–µ—Ä–≤ –Ω–∞ fine-tuning
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –†–ï–ê–õ–¨–ù–´–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–µ–±–∞ (Perplexity, Parallel AI)
4. –î–æ–±–∞–≤–∏—Ç—å –±–∞–∑–æ–≤—ã–π RL –¥–ª—è InterviewerAgent
5. –ò–∑–º–µ—Ä–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ (–¥–æ/–ø–æ—Å–ª–µ)

---

## üìä –ë—é–¥–∂–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ (5 –º–ª–Ω total)

| –ö–æ–ª–ª–µ–∫—Ü–∏—è | –ò—Å—Ç–æ—á–Ω–∏–∫ | Tokens | % –±—é–¥–∂–µ—Ç–∞ | Status |
|-----------|----------|--------|-----------|--------|
| **fpg_real_winners** | Web scraping (Perplexity/Parallel AI) | 1,200,000 | 24% | ‚úÖ DONE (1.6K used) |
| **fpg_requirements_gigachat** | –ë–î + Web (–∫—Ä–∏—Ç–µ—Ä–∏–∏ + –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ + –±—é–¥–∂–µ—Ç—ã) | 1,000,000 | 20% | üî• NEW |
| **user_grants_all** | PostgreSQL grant_applications (174 –≥—Ä–∞–Ω—Ç–∞) | 800,000 | 16% | üî• NEW |
| **–†–µ–∑–µ—Ä–≤ –Ω–∞ fine-tuning** | - | 2,000,000 | 40% | üíé RESERVED |
| **TOTAL** | - | **5,000,000** | **100%** | ‚úÖ |

**–ö–ª—é—á–µ–≤–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ:** user_grants_approved (–Ω–∞—à–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ 29 –≥—Ä–∞–Ω—Ç–æ–≤) –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è! –í–º–µ—Å—Ç–æ –Ω–∏—Ö - –†–ï–ê–õ–¨–ù–´–ï –ø–æ–±–µ–¥–∏—Ç–µ–ª–∏ –∏–∑ –≤–µ–±–∞ —á–µ—Ä–µ–∑ web search.

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π (3 –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö)

### 1. `fpg_real_winners` (1.2M tokens) üî• NEW

**–ò—Å—Ç–æ—á–Ω–∏–∫:** –†–ï–ê–õ–¨–ù–´–ï –ø–æ–±–µ–¥–∏—Ç–µ–ª–∏ –§–ü–ì 2020-2024 –∏–∑ –≤–µ–±–∞

**–ú–µ—Ç–æ–¥ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:**
1. **Perplexity AI –ø—Ä–æ–º—Ç—ã:**
   ```
   "–ù–∞–π–¥–∏ —Å–ø–∏—Å–æ–∫ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π –§–æ–Ω–¥–∞ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å–∫–∏—Ö –≥—Ä–∞–Ω—Ç–æ–≤ 2024 –≥–æ–¥–∞ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–°–æ—Ü–∏–∞–ª—å–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ'.
   –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ —É–∫–∞–∂–∏: –Ω–∞–∑–≤–∞–Ω–∏–µ, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, —Ä–µ–≥–∏–æ–Ω, —Å—É–º–º–∞ –≥—Ä–∞–Ω—Ç–∞, –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ."
   ```

2. **Parallel AI –ø—Ä–æ–º—Ç—ã:**
   ```
   "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–±–µ–¥–∏–≤—à–∏–µ –≥—Ä–∞–Ω—Ç–æ–≤—ã–µ –∑–∞—è–≤–∫–∏ –§–ü–ì –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ' –∑–∞ 2023 –≥–æ–¥.
   –ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è, —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å, –∏–∑–º–µ—Ä–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."
   ```

3. **–†—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑:** 50-100 —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞—è–≤–æ–∫ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π

**–ß—Ç–æ —Ö—Ä–∞–Ω–∏–º:**
- `title` - –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
- `organization` - –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è-–ø–æ–±–µ–¥–∏—Ç–µ–ª—å
- `problem` - –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (300-500 —Å–ª–æ–≤)
- `solution` - —Ä–µ—à–µ–Ω–∏–µ (500-1000 —Å–ª–æ–≤)
- `target_audience` - —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è
- `social_impact` - —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
- `kpi` - –∏–∑–º–µ—Ä–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- `budget` - –±—é–¥–∂–µ—Ç –∏ —Å—Ç–∞—Ç—å–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤
- `fund_name` - –§–ü–ì/–†–ù–§/–†–§–§–ò
- `year` - –≥–æ–¥ –ø–æ–±–µ–¥—ã
- `region` - —Ä–µ–≥–∏–æ–Ω
- `amount` - —Å—É–º–º–∞ –≥—Ä–∞–Ω—Ç–∞
- `category` - –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∫–æ–Ω–∫—É—Ä—Å–∞
- `rating_score` - —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)

**Embedding strategy:**
- –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –æ—Ç–¥–µ–ª—å–Ω–æ: problem, solution, kpi, budget
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ payload: fund, year, region, category, amount
- GigaChat Embeddings API (1024-dim)

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- **WriterAgent:** –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è
- **RL Training:** –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã (approved = +10 reward)
- **ReviewerAgent:** –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å winning patterns

**Token budget:** ~1,200,000 tokens (100 –≥—Ä–∞–Ω—Ç–æ–≤ √ó ~12,000 tokens/–≥—Ä–∞–Ω—Ç)

---

### 2. `fpg_requirements_gigachat` (1M tokens) üî• NEW

**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–Ø 3 —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö:
1. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ —Ñ–æ–Ω–¥–æ–≤ (grant_criteria)
2. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (research_methodologies)
3. –ë—é–¥–∂–µ—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã (budget_templates)

**–ú–µ—Ç–æ–¥ —Å–±–æ—Ä–∞:**
1. **–ò–∑ PostgreSQL:** 17 —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö knowledge_sections
2. **Web scraping:** –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∞–π—Ç—ã –§–ü–ì, –†–ù–§, –†–§–§–ò
3. **Perplexity/Parallel AI:** "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –≥—Ä–∞–Ω—Ç–æ–≤—ã—Ö –∑–∞—è–≤–æ–∫ –§–ü–ì 2024"

**–ß—Ç–æ —Ö—Ä–∞–Ω–∏–º:**

**A. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ (40%):**
- `fund_name` - –§–ü–ì/–†–ù–§/–†–§–§–ò
- `criterion_name` - –Ω–∞–∑–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏—è
- `criterion_description` - –æ–ø–∏—Å–∞–Ω–∏–µ
- `weight` - –≤–µ—Å –≤ –æ—Ü–µ–Ω–∫–µ (0-100%)
- `requirements` - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- `examples` - –ø—Ä–∏–º–µ—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è

**B. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ (30%):**
- `methodology_name` - SMART, Agile, Design Thinking
- `description` - –æ–ø–∏—Å–∞–Ω–∏–µ
- `application_area` - –æ–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
- `kpi_examples` - –ø—Ä–∏–º–µ—Ä—ã KPI
- `smart_goals_examples` - –ø—Ä–∏–º–µ—Ä—ã SMART-—Ü–µ–ª–µ–π

**C. –ë—é–¥–∂–µ—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã (30%):**
- `fund_name` - —Ñ–æ–Ω–¥
- `project_type` - —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞
- `budget_categories` - –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤
- `justification` - –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
- `total_amount` - –æ–±—â–∞—è —Å—É–º–º–∞
- `duration_months` - –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

**Embedding strategy:**
- –ö–∞–∂–¥—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö (–∫—Ä–∏—Ç–µ—Ä–∏–∏, –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏, –±—é–¥–∂–µ—Ç—ã) —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ metadata tags
- GigaChat Embeddings API (1024-dim)
- Hierarchical chunking: —Ä–∞–∑–¥–µ–ª ‚Üí –ø–æ–¥—Ä–∞–∑–¥–µ–ª ‚Üí –ø–∞—Ä–∞–≥—Ä–∞—Ñ

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- **ReviewerAgent:** –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–æ–Ω–¥
- **AuditorAgent:** –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
- **WriterAgent:** –†–∞–∑–¥–µ–ª "–ë—é–¥–∂–µ—Ç" + –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è

**Token budget:** ~1,000,000 tokens (200 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ √ó ~5,000 tokens/doc)

---

### 3. `user_grants_all` (800K tokens) üî• NEW

**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ì–æ—Ç–æ–≤—ã–µ –∑–∞—è–≤–∫–∏ –∏–∑ PostgreSQL grant_applications (174 –≥—Ä–∞–Ω—Ç–∞)

**–ú–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:**
```sql
-- –í—Å–µ –≥—Ä–∞–Ω—Ç—ã (draft + approved)
SELECT id, title, content_json, status, quality_score, created_at, updated_at
FROM grant_applications
WHERE content_json IS NOT NULL
ORDER BY created_at DESC;
```

**–ß—Ç–æ –≤–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º:**
- **174 –≥—Ä–∞–Ω—Ç–∞ total:**
  - 145 draft (—á–µ—Ä–Ω–æ–≤–∏–∫–∏)
  - 29 approved (–æ–¥–æ–±—Ä–µ–Ω–Ω—ã–µ)
- **10 —Ä–∞–∑–¥–µ–ª–æ–≤ –∫–∞–∂–¥–æ–π –∑–∞—è–≤–∫–∏:**
  - problem (–ø—Ä–æ–±–ª–µ–º–∞)
  - solution (—Ä–µ—à–µ–Ω–∏–µ)
  - target_audience (—Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è)
  - goals (—Ü–µ–ª–∏)
  - methodology (–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è)
  - timeline (–ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
  - budget (–±—é–¥–∂–µ—Ç)
  - team (–∫–æ–º–∞–Ω–¥–∞)
  - risks (—Ä–∏—Å–∫–∏)
  - impact (–æ–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)

**–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (payload):**
- `status` - draft/approved/submitted
- `quality_score` - –æ—Ü–µ–Ω–∫–∞ ReviewerAgent (0-10)
- `created_at` - –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è
- `user_id` - ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- `fund_target` - —Ü–µ–ª–µ–≤–æ–π —Ñ–æ–Ω–¥

**Embedding strategy:**
- –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –æ—Ç–¥–µ–ª—å–Ω–æ (10 vectors per grant √ó 174 grants = 1,740 vectors)
- GigaChat Embeddings API (1024-dim)
- Metadata-based filtering –¥–ª—è similarity search

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- **WriterAgent:** –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:** "–ü–æ—Ö–æ–∂–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –≤ –Ω–∞—à–µ–π –±–∞–∑–µ"
- **RL Training:**
  - approved grants (29) = –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã (+5 reward)
  - draft grants (145) = –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (neutral)
- **–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è:** –£—á–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

**Token budget:** ~800,000 tokens (174 grants √ó 10 sections √ó ~460 tokens/section)

**–û—Ç–ª–∏—á–∏–µ –æ—Ç fpg_real_winners:**
- `fpg_real_winners` = –†–ï–ê–õ–¨–ù–´–ï –ø–æ–±–µ–¥–∏—Ç–µ–ª–∏ –∏–∑ –≤–µ–±–∞ (—ç—Ç–∞–ª–æ–Ω –∫–∞—á–µ—Å—Ç–≤–∞)
- `user_grants_all` = –ù–ê–®–ò –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (–∏—Å—Ç–æ—Ä–∏—è —Å–∏—Å—Ç–µ–º—ã, –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è)

---

## ü§ñ RL Component

### –ó–∞–¥–∞—á–∞
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å InterviewerAgent: –≤—ã–±–∏—Ä–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –ª—É—á—à–∏–º –∑–∞—è–≤–∫–∞–º

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

**State (—Å–æ—Å—Ç–æ—è–Ω–∏–µ):**
- –¢–µ–∫—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- Embedding —Ç–µ–∫—É—â–µ–π –∞–Ω–∫–µ—Ç—ã
- –ò—Å—Ç–æ—Ä–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤

**Action (–¥–µ–π—Å—Ç–≤–∏–µ):**
- –í—ã–±–æ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ 50 –≤–æ–∑–º–æ–∂–Ω—ã—Ö

**Reward (–Ω–∞–≥—Ä–∞–¥–∞):**
- –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è: –∑–∞—è–≤–∫–∞ –æ–¥–æ–±—Ä–µ–Ω–∞ —Ñ–æ–Ω–¥–æ–º (+10)
- –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è: –∑–∞—è–≤–∫–∞ –ø–æ–¥–∞–Ω–∞ (+5)
- –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è: –∑–∞—è–≤–∫–∞ –Ω–µ –ø–æ–¥–∞–Ω–∞ (-5)
- –ë–æ–Ω—É—Å: –≤—ã—Å–æ–∫–∞—è –æ—Ü–µ–Ω–∫–∞ ReviewerAgent (+2 –∑–∞ –∫–∞–∂–¥—ã–π –±–∞–ª–ª >7)

**Algorithm:**
- Q-Learning (–ø—Ä–æ—Å—Ç–æ–π, —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
- Epsilon-greedy exploration (90% best, 10% random)

### Implementation

**–§–∞–π–ª:** `agents/rl_interviewer_agent.py`

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
```python
class RLInterviewerAgent:
    def __init__(self):
        self.q_table = {}  # state -> {question_id: q_value}
        self.epsilon = 0.1  # exploration rate
        self.alpha = 0.1    # learning rate
        self.gamma = 0.9    # discount factor

    def get_next_question(self, state):
        # Epsilon-greedy
        if random.random() < self.epsilon:
            return random_question()
        else:
            return best_question_from_q_table(state)

    def update_q_value(self, state, action, reward, next_state):
        # Q-learning update
        ...
```

**Storage:**
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Q-table –≤ PostgreSQL
- –¢–∞–±–ª–∏—Ü–∞: `rl_q_values (state_hash, question_id, q_value, updated_at)`

---

## üß™ Testing & Metrics - Following TESTING-METHODOLOGY.md

### Test Pyramid (70% Unit / 20% Integration / 10% E2E)

#### Unit Tests (70%) - `tests/unit/`

**test_fpg_parser.py**
```python
def test_parse_fpg_grant():
    """Parse single FPG grant page"""
    html = load_fixture("fpg_grant_sample.html")
    grant = parse_fpg_grant(html)
    assert grant['title']
    assert grant['problem']
    assert len(grant['problem']) > 100
```

**test_gigachat_embeddings_client.py**
```python
def test_create_embedding():
    """Test GigaChat API embedding creation"""
    client = GigaChatEmbeddingsClient()
    text = "–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"
    embedding = client.create_embedding(text)
    assert len(embedding) == 1024  # GigaChat embedding size
```

**test_rl_q_table.py**
```python
def test_q_value_update():
    """Test Q-learning update formula"""
    q_table = QTable()
    state = "answered_3_questions"
    action = "ask_question_5"
    reward = 10

    q_table.update(state, action, reward)
    assert q_table.get(state, action) > 0
```

#### Integration Tests (20%) - `tests/integration/`

**test_gigachat_embedding_integration.py**
```python
@pytest.mark.integration
@pytest.mark.gigachat
def test_create_collection_with_gigachat():
    """Integration: Create Qdrant collection with GigaChat embeddings"""
    # Load sample data
    grants = load_successful_grants(limit=5)

    # Create embeddings
    loader = GigaChatEmbeddingsLoader()
    collection = loader.create_collection("test_successful_grants")

    # Verify
    assert collection.points_count == 5
    assert collection.vectors_size == 1024
```

**test_writer_with_embeddings.py**
```python
@pytest.mark.integration
@pytest.mark.gigachat
def test_writer_uses_successful_grants():
    """WriterAgent queries successful_grants collection"""
    writer = WriterAgent(use_embeddings=True)

    # Generate grant with embeddings context
    result = writer.process({
        'user_answers': sample_anketa,
        'use_successful_grants': True
    })

    # Verify embeddings were used
    assert 'successful_grants_context' in result
    assert len(result['successful_grants_context']) > 0
```

#### E2E Tests (10%) - `tests/integration/`

**test_embeddings_quality_improvement.py**
```python
@pytest.mark.e2e
@pytest.mark.slow
def test_embeddings_improve_quality():
    """E2E: Compare grant quality before/after embeddings"""
    # BASELINE (Iteration 50)
    baseline_grant = generate_grant_without_embeddings()
    baseline_score = review_grant(baseline_grant)

    # WITH EMBEDDINGS (Iteration 51)
    enhanced_grant = generate_grant_with_embeddings()
    enhanced_score = review_grant(enhanced_grant)

    # Expect improvement
    assert enhanced_score > baseline_score
    assert enhanced_score - baseline_score >= 1.0  # +1 point minimum
```

---

### AI/LLM-Specific Testing (Section 10 of TESTING-METHODOLOGY)

**Semantic Validation:**
```python
def test_embeddings_semantic_similarity():
    """Verify similar texts have high cosine similarity"""
    text1 = "–†–∞–∑–≤–∏—Ç–∏–µ –Ω–∞—É–∫–∏ —Å—Ä–µ–¥–∏ –º–æ–ª–æ–¥–µ–∂–∏"
    text2 = "–ü–æ–ø—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤"

    emb1 = create_embedding(text1)
    emb2 = create_embedding(text2)

    similarity = cosine_similarity(emb1, emb2)
    assert similarity > 0.7  # High similarity expected
```

**Non-Determinism Handling:**
```python
@pytest.mark.repeat(3)  # Run 3 times
def test_rl_stability():
    """RL agent should converge to similar results"""
    results = []
    for _ in range(3):
        agent = RLInterviewerAgent()
        score = agent.train(episodes=100)
        results.append(score)

    # Results should be within 10% of each other
    assert max(results) - min(results) < 0.1 * mean(results)
```

---

### Production Parity Tests

**test_production_qdrant.py**
```python
def test_use_production_qdrant():
    """Verify tests use production Qdrant (5.35.88.251:6333)"""
    from expert_agent.expert_agent import ExpertAgent

    agent = ExpertAgent()
    assert agent.qdrant.host == "5.35.88.251"
    assert agent.qdrant.port == 6333
```

**test_gigachat_credentials.py**
```python
def test_use_production_gigachat():
    """Verify GigaChat uses production credentials"""
    from shared.llm.unified_llm_client import get_client

    client = get_client(provider="gigachat")
    # Should use config.py, not env vars
    assert client.auth_method == "oauth"
```

### –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ Sber500

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ (Iteration 50) | –ü–æ—Å–ª–µ (Iteration 51) | Œî |
|---------|-------------------|----------------------|---|
| Qdrant vectors | 53 | **5,053** | +5,000 ‚úÖ |
| Collections | 2 | **7** | +5 ‚úÖ |
| GigaChat tokens used | 0 | **5,000,000** | +5M ‚úÖ |
| WriterAgent quality | 3.25/10 | **5-6/10** | +2 üéØ |
| ReviewerAgent requirements | 11 | **30+** | +20 üéØ |
| InterviewerAgent questions | 50 fixed | **Adaptive (RL)** | Smart ‚úÖ |

---

## üìã Success Criteria

**Must Have (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ):**
1. ‚úÖ 5 –Ω–æ–≤—ã—Ö Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–π —Å–æ–∑–¥–∞–Ω—ã
2. ‚úÖ 5 –º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤ GigaChat Embeddings –ø–æ—Ç—Ä–∞—á–µ–Ω–æ
3. ‚úÖ user_projects –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã (–≤—Å–µ grant_applications –∏–∑ –ë–î)
4. ‚úÖ WriterAgent –∏—Å–ø–æ–ª—å–∑—É–µ—Ç successful_grants
5. ‚úÖ RL –¥–ª—è InterviewerAgent —Ä–∞–±–æ—Ç–∞–µ—Ç (Q-learning –±–∞–∑–æ–≤—ã–π)

**Should Have (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ):**
1. ‚úÖ ReviewerAgent –∏—Å–ø–æ–ª—å–∑—É–µ—Ç grant_criteria
2. ‚úÖ –¢–µ—Å—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–¥–æ/–ø–æ—Å–ª–µ) –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–ª—É—á—à–µ–Ω–∏–µ
3. ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π

**Nice to Have (–±–æ–Ω—É—Å):**
1. ‚≠ê Dashboard –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ embeddings (t-SNE/UMAP)
2. ‚≠ê A/B —Ç–µ—Å—Ç: RL vs Random question selection
3. ‚≠ê –≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏

---

## üóìÔ∏è Timeline (2 –¥–Ω—è) - Following PROJECT-EVOLUTION-METHODOLOGY

### –î–µ–Ω—å 1 (26 –æ–∫—Ç—è–±—Ä—è, —Å–µ–≥–æ–¥–Ω—è) - Data Collection

**Commit #1: Iteration plan + schemas (–°–ï–ô–ß–ê–°, 1 —á–∞—Å)**
```bash
git commit -m "feat(iteration-51): Plan + 3 collection schemas (3M tokens + 2M reserve)"
```
- ‚úÖ Update iteration plan (3 –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤–º–µ—Å—Ç–æ 5)
- Create Pydantic models –¥–ª—è 3 –∫–æ–ª–ª–µ–∫—Ü–∏–π
- Create Qdrant collection schemas (JSON)
- **Test:** Schema validation
- **CI:** Lint + type check
- **Lines:** ~150 lines

**Commit #2: Web search –ø—Ä–æ–º—Ç—ã + parsers (–¥–µ–Ω—å, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Perplexity/Parallel AI prompts + FPG parsers"
```
- **Perplexity AI –ø—Ä–æ–º—Ç—ã** –¥–ª—è fpg_real_winners:
  - "–ü–æ–±–µ–¥–∏—Ç–µ–ª–∏ –§–ü–ì 2024: –°–æ—Ü–∏–∞–ª—å–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"
  - "–ü–æ–±–µ–¥–∏—Ç–µ–ª–∏ –§–ü–ì 2023: –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"
  - "–ü–æ–±–µ–¥–∏—Ç–µ–ª–∏ –§–ü–ì 2024: –ö—É–ª—å—Ç—É—Ä–∞"
- **Parallel AI –ø—Ä–æ–º—Ç—ã** –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞—è–≤–æ–∫
- Create FPG web parser (BeautifulSoup)
- Unit tests: `test_web_parsers.py`
- **Test:** Mock HTML fixtures
- **CI:** All unit tests pass
- **Lines:** ~180 lines

**Commit #3: GigaChat embeddings loader (–≤–µ—á–µ—Ä, 2 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): GigaChat Embeddings API client + loader"
```
- Create `shared/llm/gigachat_embeddings.py`
- GigaChat Embeddings API client (1024-dim)
- Batch processing (100 texts per batch)
- Integration test: `test_gigachat_embeddings_client.py`
- **Test:** Create 10 test embeddings
- **Metrics:** Test token usage (~5K tokens)
- **Lines:** ~120 lines

**Commit #4: Load fpg_real_winners (–≤–µ—á–µ—Ä, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Load 100 real FPG winners (1.2M tokens)"
```
- Process Perplexity/Parallel AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- Parse 100 real grant applications
- Create Qdrant collection `fpg_real_winners`
- Load embeddings (1.2M tokens)
- **Test:** `test_fpg_real_winners_collection.py`
- **Metrics:** 1.2M / 3M tokens used (40%)
- **Lines:** ~150 lines

### –î–µ–Ω—å 2 (27 –æ–∫—Ç—è–±—Ä—è) - Vectorization + Integration

**Commit #5: Load fpg_requirements_gigachat (—É—Ç—Ä–æ, 2 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Consolidate criteria + methodologies + budgets (1M tokens)"
```
- Consolidate 3 —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö:
  - A. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ (40%)
  - B. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ (30%)
  - C. –ë—é–¥–∂–µ—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã (30%)
- Create Qdrant collection `fpg_requirements_gigachat`
- Load embeddings (1M tokens)
- **Test:** `test_fpg_requirements_collection.py`
- **Metrics:** 2.2M / 3M tokens used (73%)
- **Lines:** ~120 lines

**Commit #6: Load user_grants_all (–¥–µ–Ω—å, 2 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Vectorize 174 user grants (800K tokens)"
```
- Query PostgreSQL grant_applications (174 total)
- Vectorize 10 sections √ó 174 grants = 1,740 vectors
- Create Qdrant collection `user_grants_all`
- Load embeddings (800K tokens)
- **Test:** `test_user_grants_collection.py`
- **Metrics:** 3M / 3M tokens used (100%) + 2M reserve
- **Lines:** ~100 lines

**Commit #7: WriterAgent integration (–¥–µ–Ω—å, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Integrate fpg_real_winners + fpg_requirements in WriterAgent"
```
- Add semantic search –≤ WriterAgent:
  - Query `fpg_real_winners` –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
  - Query `fpg_requirements_gigachat` –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤/–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–π
  - Query `user_grants_all` –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
- Integration test: `test_writer_with_embeddings.py`
- **Test:** Compare quality (Iteration 50 baseline)
- **Expected:** +1 point minimum –≤ ReviewerAgent score
- **Lines:** ~150 lines

**Commit #8: RL for InterviewerAgent (–≤–µ—á–µ—Ä, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Q-learning for InterviewerAgent (optional)"
```
- Create `agents/rl_interviewer_agent.py`
- Q-table storage –≤ PostgreSQL (table: rl_q_values)
- Epsilon-greedy policy (Œµ=0.1)
- **Test:** `test_rl_q_learning.py` (unit test)
- **Metrics:** Q-table size, convergence
- **Lines:** ~120 lines
- **Note:** ‚ö†Ô∏è OPTIONAL - if time allows

**Commit #9: Documentation + SUMMARY (–≤–µ—á–µ—Ä, 2 —á–∞—Å–∞)**
```bash
git commit -m "docs(iteration-51): Summary + Sber500 presentation metrics"
```
- Create ITERATION_51_SUMMARY.md
- Export metrics:
  - Token usage: 3M / 5M (60%)
  - Collections created: 3
  - Vectors total: ~2,840 (100 + 200 + 1,740)
  - Quality improvement: baseline vs embeddings
- Final deliverable for Sber500
- **Lines:** ~200 lines (markdown)

---

## üîß Technical Implementation

### GigaChat Embeddings API

**Endpoint:**
```python
POST https://gigachat.devices.sberbank.ru/api/v1/embeddings

Headers:
  Authorization: Bearer <access_token>

Body:
{
  "model": "Embeddings",  # –∏–ª–∏ "EmbeddingsGigaR"
  "input": ["—Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"]
}

Response:
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [0.1, 0.2, ...],  # 1024-dim vector
      "index": 0
    }
  ],
  "model": "Embeddings"
}
```

**–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:** 1024 (vs 384 —É Sentence Transformers)

**–°–∫—Ä–∏–ø—Ç:**
```bash
python scripts/create_gigachat_embeddings.py \
  --collection successful_grants \
  --source data/fpg_winners_2020_2024.json \
  --batch-size 100
```

---

## üìä Data Sources

### 1. –§–ü–ì –ø–æ–±–µ–¥–∏—Ç–µ–ª–∏ (successful_grants)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- https://—Ñ–æ–Ω–¥–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å–∫–∏—Ö–≥—Ä–∞–Ω—Ç–æ–≤.—Ä—Ñ/competitions/results
- –ü–∞—Ä—Å–∏–Ω–≥: BeautifulSoup + Selenium
- –§–æ—Ä–º–∞—Ç: JSON [{title, problem, solution, ...}, ...]

### 2. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ (grant_criteria)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –§–ü–ì: https://—Ñ–æ–Ω–¥–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å–∫–∏—Ö–≥—Ä–∞–Ω—Ç–æ–≤.—Ä—Ñ/
- –†–ù–§: https://rscf.ru/
- –†–§–§–ò –∞—Ä—Ö–∏–≤
- –†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞

### 3. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ (research_methodologies)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ (Google Scholar)
- –ú–µ—Ç–æ–¥–∏—á–∫–∏ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤
- Best practices (Harvard Business Review, etc.)

### 4. –ë—é–¥–∂–µ—Ç—ã (budget_templates)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- –ü–æ–±–µ–¥–∏–≤—à–∏–µ –∑–∞—è–≤–∫–∏ (–ø—É–±–ª–∏—á–Ω—ã–µ)
- –®–∞–±–ª–æ–Ω—ã —Ñ–æ–Ω–¥–æ–≤
- –ù–∞—à –æ–ø—ã—Ç

### 5. –ü—Ä–æ–µ–∫—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (user_projects)
**–ò—Å—Ç–æ—á–Ω–∏–∫:**
- PostgreSQL: `grant_applications` table
- –§–∏–ª—å—Ç—Ä: –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å content_json IS NOT NULL

---

## üéì RL Theory (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è)

### Q-Learning –æ—Å–Ω–æ–≤—ã

**Q-value (–∫–∞—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏—è):**
```
Q(state, action) = –æ–∂–∏–¥–∞–µ–º–∞—è –Ω–∞–≥—Ä–∞–¥–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ action –≤ state
```

**Update rule:**
```
Q(s, a) ‚Üê Q(s, a) + Œ±[r + Œ≥¬∑max Q(s', a') - Q(s, a)]
```

–ì–¥–µ:
- Œ± (alpha) = learning rate (0.1) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- Œ≥ (gamma) = discount factor (0.9) - –≤–∞–∂–Ω–æ—Å—Ç—å –±—É–¥—É—â–∏—Ö –Ω–∞–≥—Ä–∞–¥
- r = immediate reward - –º–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞
- s' = next state - —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

### –ü—Ä–∏–º–µ—Ä –¥–ª—è InterviewerAgent

**State:**
```python
state = {
  'answered_questions': [1, 5, 12],
  'current_topic': 'team',
  'completeness': 0.3  # 30% –∑–∞–ø–æ–ª–Ω–µ–Ω–æ
}
```

**Action:**
```python
action = question_id  # ID —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ (1-50)
```

**Reward:**
```python
# –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é:
if grant_approved:
  reward = +10
elif grant_submitted:
  reward = +5
else:
  reward = -5

# –ë–æ–Ω—É—Å –æ—Ç ReviewerAgent:
reward += (readiness_score - 5) * 2  # +2 –∑–∞ –∫–∞–∂–¥—ã–π –±–∞–ª–ª >5
```

### Convergence (—Å—Ö–æ–¥–∏–º–æ—Å—Ç—å)

**–û–∂–∏–¥–∞–µ–º:**
- –ü–æ—Å–ª–µ 50-100 –∏–Ω—Ç–µ—Ä–≤—å—é: Q-values —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É—é—Ç—Å—è
- Epsilon decay: 0.1 ‚Üí 0.05 (–º–µ–Ω—å—à–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
- Avg questions per interview: 50 ‚Üí 35-40 (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)

---

## üöÄ Deployment Plan

**Staging (—Ç–µ—Å—Ç):**
1. –°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–∞ prod Qdrant (5.35.88.251:6333)
2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –ë–î
3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ–∫–µ–Ω—ã: –±–∞–ª–∞–Ω—Å –¥–æ/–ø–æ—Å–ª–µ

**Production (–±–æ–µ–≤–æ–π):**
1. –û–±–Ω–æ–≤–∏—Ç—å WriterAgent (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å successful_grants)
2. –û–±–Ω–æ–≤–∏—Ç—å ReviewerAgent (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å grant_criteria)
3. –î–µ–ø–ª–æ–π RL InterviewerAgent (—Å fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π)

**Rollback plan:**
- –°—Ç–∞—Ä—ã–µ –∞–≥–µ–Ω—Ç—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
- RL —Ç–æ–ª—å–∫–æ –¥–ª—è A/B —Ç–µ—Å—Ç–∞ (50% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)

---

## üìö References

- **GigaChat Embeddings:** https://developers.sber.ru/docs/ru/gigachat/guides/embeddings
- **Qdrant Collections:** http://5.35.88.251:6333/dashboard
- **RL Theory:** Sutton & Barto "Reinforcement Learning: An Introduction"
- **Q-Learning:** https://en.wikipedia.org/wiki/Q-learning

---

## ‚úÖ Checklist

**Planning:**
- [x] Create iteration plan
- [ ] Collect data sources
- [ ] Design collection schemas
- [ ] Estimate token usage

**Execution:**
- [ ] Create 5 Qdrant collections
- [ ] Load successful_grants (500K)
- [ ] Load grant_criteria (500K)
- [ ] Load research_methodologies (600K)
- [ ] Load budget_templates (600K)
- [ ] Vectorize user_projects (2.5M)
- [ ] Implement RL for InterviewerAgent
- [ ] Integration tests

**Validation:**
- [ ] Test WriterAgent improvement
- [ ] Test ReviewerAgent accuracy
- [ ] Test RL convergence
- [ ] Measure token usage (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å ~5M)

**Documentation:**
- [ ] Update ITERATION_51_SUMMARY.md
- [ ] Create metrics dashboard
- [ ] Git commit

---

**Status:** üöÄ READY TO START
**Estimated time:** 2 days (20 hours total)
**Tokens budget:** 5,000,000
**Key deliverable:** 5 –Ω–æ–≤—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π + RL –¥–ª—è InterviewerAgent + –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è Sber500
