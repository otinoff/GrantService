# Iteration 51: AI Enhancement - Embeddings + RL

**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:** 2025-10-26
**–°—Ç–∞—Ç—É—Å:** üöÄ PLANNING
**–¶–µ–ª—å:** –ü–æ—Ç—Ä–∞—Ç–∏—Ç—å 5 –º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤ GigaChat Embeddings –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ 5 –∫–æ–ª–ª–µ–∫—Ü–∏–π + –¥–æ–±–∞–≤–∏—Ç—å RL –¥–ª—è InterviewerAgent

---

## üéØ –ó–∞–¥–∞—á–∞

**–ë–∏–∑–Ω–µ—Å-—Ü–µ–ª—å:** –ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞ –æ—Ü–µ–Ω–∫–µ Sber500 —Å–µ—Ä—å—ë–∑–Ω—ã–π AI-–ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞ 2 –¥–Ω—è

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ü–µ–ª–∏:**
1. –°–æ–∑–¥–∞—Ç—å 5 –Ω–æ–≤—ã—Ö Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–π —Å GigaChat Embeddings
2. –ü–æ—Ç—Ä–∞—Ç–∏—Ç—å ~5 –º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤ embeddings (–±–∞–ª–∞–Ω—Å –¥–æ 04.10.2026)
3. –î–æ–±–∞–≤–∏—Ç—å –±–∞–∑–æ–≤—ã–π RL –¥–ª—è InterviewerAgent
4. –ò–∑–º–µ—Ä–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ (–¥–æ/–ø–æ—Å–ª–µ)

---

## üìä –ë—é–¥–∂–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ (5 –º–ª–Ω total)

| –ö–æ–ª–ª–µ–∫—Ü–∏—è | –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ | Tokens/doc | Total tokens | % –±—é–¥–∂–µ—Ç–∞ |
|-----------|------------|------------|--------------|-----------|
| successful_grants | 50 | 10,000 | 500,000 | 10% |
| grant_criteria | 100 | 5,000 | 500,000 | 10% |
| research_methodologies | 200 | 3,000 | 600,000 | 12% |
| budget_templates | 150 | 4,000 | 600,000 | 12% |
| user_projects | 500 | 5,000 | 2,500,000 | 50% |
| **–†–µ–∑–µ—Ä–≤ (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)** | - | - | 300,000 | 6% |
| **TOTAL** | 1,000 | - | **5,000,000** | **100%** |

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π

### 1. `successful_grants` (500K tokens)
**–ò—Å—Ç–æ—á–Ω–∏–∫:** –û—Ç–∫—Ä—ã—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π –§–ü–ì 2020-2024

**–ß—Ç–æ —Ö—Ä–∞–Ω–∏–º:**
- title (–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞)
- problem (–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã)
- solution (—Ä–µ—à–µ–Ω–∏–µ)
- implementation (–ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
- budget (–±—é–¥–∂–µ—Ç)
- fund_name (–§–ü–ì/–†–ù–§/–†–§–§–ò)
- year (–≥–æ–¥ –ø–æ–±–µ–¥—ã)
- region (—Ä–µ–≥–∏–æ–Ω)
- amount (—Å—É–º–º–∞ –≥—Ä–∞–Ω—Ç–∞)

**Embedding strategy:**
- –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –æ—Ç–¥–µ–ª—å–Ω–æ (title, problem, solution, etc.)
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ payload –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- WriterAgent: –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —É—Å–ø–µ—à–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
- –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM: "–í–æ—Ç –∫–∞–∫ –ø–∏—Å–∞–ª–∏ –ø–æ–±–µ–¥–∏—Ç–µ–ª–∏"

---

### 2. `grant_criteria` (500K tokens)
**–ò—Å—Ç–æ—á–Ω–∏–∫:** –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è —Ñ–æ–Ω–¥–æ–≤ (–§–ü–ì, –†–ù–§, –†–§–§–ò, —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ)

**–ß—Ç–æ —Ö—Ä–∞–Ω–∏–º:**
- fund_name (–Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–æ–Ω–¥–∞)
- criterion_name (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏—è)
- criterion_description (–æ–ø–∏—Å–∞–Ω–∏–µ)
- weight (–≤–µ—Å –≤ –æ—Ü–µ–Ω–∫–µ, 0-100%)
- requirements (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
- examples (–ø—Ä–∏–º–µ—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è)

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- ReviewerAgent: –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–æ–Ω–¥
- AuditorAgent: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º

---

### 3. `research_methodologies` (600K tokens)
**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ù–∞—É—á–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞, –º–µ—Ç–æ–¥–∏—á–∫–∏, best practices

**–ß—Ç–æ —Ö—Ä–∞–Ω–∏–º:**
- methodology_name (SMART, Agile, Design Thinking, etc.)
- description (–æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏)
- application_area (–æ–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)
- kpi_examples (–ø—Ä–∏–º–µ—Ä—ã KPI)
- smart_goals_examples (–ø—Ä–∏–º–µ—Ä—ã SMART-—Ü–µ–ª–µ–π)
- metrics (–º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏)

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- WriterAgent: —Ä–∞–∑–¥–µ–ª "–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"
- InterviewerAgent: –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º

---

### 4. `budget_templates` (600K tokens)
**–ò—Å—Ç–æ—á–Ω–∏–∫:** –®–∞–±–ª–æ–Ω—ã —Å–º–µ—Ç –∏–∑ –ø–æ–±–µ–¥–∏–≤—à–∏—Ö –∑–∞—è–≤–æ–∫

**–ß—Ç–æ —Ö—Ä–∞–Ω–∏–º:**
- fund_name (—Ñ–æ–Ω–¥)
- project_type (—Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞)
- budget_categories (–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤)
- justification (–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ)
- total_amount (–æ–±—â–∞—è —Å—É–º–º–∞)
- duration_months (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- WriterAgent: —Ä–∞–∑–¥–µ–ª "–ë—é–¥–∂–µ—Ç"
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–π —Å—É–º–º—ã

---

### 5. `user_projects` (2.5M tokens) - **–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!**
**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ì–æ—Ç–æ–≤—ã–µ –∑–∞—è–≤–∫–∏ –∏–∑ –Ω–∞—à–µ–π –ë–î

**–ß—Ç–æ –≤–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º:**
- –í—Å–µ grant_applications (—Ç–∞–±–ª–∏—Ü–∞)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: 10 —Ä–∞–∑–¥–µ–ª–æ–≤ –∫–∞–∂–¥–æ–π –∑–∞—è–≤–∫–∏
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: status, quality_score, created_at

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: "–ü–æ—Ö–æ–∂–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –ø–æ–ª—É—á–∏–ª–∏ –≥—Ä–∞–Ω—Ç—ã"
- RL reward: —É—Å–ø–µ—à–Ω—ã–µ –∑–∞—è–≤–∫–∏ = –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π feedback

---

## ü§ñ RL Component

### –ó–∞–¥–∞—á–∞
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å InterviewerAgent: –≤—ã–±–∏—Ä–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –ª—É—á—à–∏–º –∑–∞—è–≤–∫–∞–º

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

**State (—Å–æ—Å—Ç–æ—è–Ω–∏–µ):**
- –¢–µ–∫—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- Embedding —Ç–µ–∫—É—â–µ–π –∞–Ω–∫–µ—Ç—ã
- –ò—Å—Ç–æ—Ä–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤

**Action (–¥–µ–π—Å—Ç–≤–∏–µ):**
- –í—ã–±–æ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ 50 –≤–æ–∑–º–æ–∂–Ω—ã—Ö

**Reward (–Ω–∞–≥—Ä–∞–¥–∞):**
- –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è: –∑–∞—è–≤–∫–∞ –æ–¥–æ–±—Ä–µ–Ω–∞ —Ñ–æ–Ω–¥–æ–º (+10)
- –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è: –∑–∞—è–≤–∫–∞ –ø–æ–¥–∞–Ω–∞ (+5)
- –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è: –∑–∞—è–≤–∫–∞ –Ω–µ –ø–æ–¥–∞–Ω–∞ (-5)
- –ë–æ–Ω—É—Å: –≤—ã—Å–æ–∫–∞—è –æ—Ü–µ–Ω–∫–∞ ReviewerAgent (+2 –∑–∞ –∫–∞–∂–¥—ã–π –±–∞–ª–ª >7)

**Algorithm:**
- Q-Learning (–ø—Ä–æ—Å—Ç–æ–π, —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
- Epsilon-greedy exploration (90% best, 10% random)

### Implementation

**–§–∞–π–ª:** `agents/rl_interviewer_agent.py`

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
```python
class RLInterviewerAgent:
    def __init__(self):
        self.q_table = {}  # state -> {question_id: q_value}
        self.epsilon = 0.1  # exploration rate
        self.alpha = 0.1    # learning rate
        self.gamma = 0.9    # discount factor

    def get_next_question(self, state):
        # Epsilon-greedy
        if random.random() < self.epsilon:
            return random_question()
        else:
            return best_question_from_q_table(state)

    def update_q_value(self, state, action, reward, next_state):
        # Q-learning update
        ...
```

**Storage:**
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Q-table –≤ PostgreSQL
- –¢–∞–±–ª–∏—Ü–∞: `rl_q_values (state_hash, question_id, q_value, updated_at)`

---

## üß™ Testing & Metrics - Following TESTING-METHODOLOGY.md

### Test Pyramid (70% Unit / 20% Integration / 10% E2E)

#### Unit Tests (70%) - `tests/unit/`

**test_fpg_parser.py**
```python
def test_parse_fpg_grant():
    """Parse single FPG grant page"""
    html = load_fixture("fpg_grant_sample.html")
    grant = parse_fpg_grant(html)
    assert grant['title']
    assert grant['problem']
    assert len(grant['problem']) > 100
```

**test_gigachat_embeddings_client.py**
```python
def test_create_embedding():
    """Test GigaChat API embedding creation"""
    client = GigaChatEmbeddingsClient()
    text = "–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"
    embedding = client.create_embedding(text)
    assert len(embedding) == 1024  # GigaChat embedding size
```

**test_rl_q_table.py**
```python
def test_q_value_update():
    """Test Q-learning update formula"""
    q_table = QTable()
    state = "answered_3_questions"
    action = "ask_question_5"
    reward = 10

    q_table.update(state, action, reward)
    assert q_table.get(state, action) > 0
```

#### Integration Tests (20%) - `tests/integration/`

**test_gigachat_embedding_integration.py**
```python
@pytest.mark.integration
@pytest.mark.gigachat
def test_create_collection_with_gigachat():
    """Integration: Create Qdrant collection with GigaChat embeddings"""
    # Load sample data
    grants = load_successful_grants(limit=5)

    # Create embeddings
    loader = GigaChatEmbeddingsLoader()
    collection = loader.create_collection("test_successful_grants")

    # Verify
    assert collection.points_count == 5
    assert collection.vectors_size == 1024
```

**test_writer_with_embeddings.py**
```python
@pytest.mark.integration
@pytest.mark.gigachat
def test_writer_uses_successful_grants():
    """WriterAgent queries successful_grants collection"""
    writer = WriterAgent(use_embeddings=True)

    # Generate grant with embeddings context
    result = writer.process({
        'user_answers': sample_anketa,
        'use_successful_grants': True
    })

    # Verify embeddings were used
    assert 'successful_grants_context' in result
    assert len(result['successful_grants_context']) > 0
```

#### E2E Tests (10%) - `tests/integration/`

**test_embeddings_quality_improvement.py**
```python
@pytest.mark.e2e
@pytest.mark.slow
def test_embeddings_improve_quality():
    """E2E: Compare grant quality before/after embeddings"""
    # BASELINE (Iteration 50)
    baseline_grant = generate_grant_without_embeddings()
    baseline_score = review_grant(baseline_grant)

    # WITH EMBEDDINGS (Iteration 51)
    enhanced_grant = generate_grant_with_embeddings()
    enhanced_score = review_grant(enhanced_grant)

    # Expect improvement
    assert enhanced_score > baseline_score
    assert enhanced_score - baseline_score >= 1.0  # +1 point minimum
```

---

### AI/LLM-Specific Testing (Section 10 of TESTING-METHODOLOGY)

**Semantic Validation:**
```python
def test_embeddings_semantic_similarity():
    """Verify similar texts have high cosine similarity"""
    text1 = "–†–∞–∑–≤–∏—Ç–∏–µ –Ω–∞—É–∫–∏ —Å—Ä–µ–¥–∏ –º–æ–ª–æ–¥–µ–∂–∏"
    text2 = "–ü–æ–ø—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤"

    emb1 = create_embedding(text1)
    emb2 = create_embedding(text2)

    similarity = cosine_similarity(emb1, emb2)
    assert similarity > 0.7  # High similarity expected
```

**Non-Determinism Handling:**
```python
@pytest.mark.repeat(3)  # Run 3 times
def test_rl_stability():
    """RL agent should converge to similar results"""
    results = []
    for _ in range(3):
        agent = RLInterviewerAgent()
        score = agent.train(episodes=100)
        results.append(score)

    # Results should be within 10% of each other
    assert max(results) - min(results) < 0.1 * mean(results)
```

---

### Production Parity Tests

**test_production_qdrant.py**
```python
def test_use_production_qdrant():
    """Verify tests use production Qdrant (5.35.88.251:6333)"""
    from expert_agent.expert_agent import ExpertAgent

    agent = ExpertAgent()
    assert agent.qdrant.host == "5.35.88.251"
    assert agent.qdrant.port == 6333
```

**test_gigachat_credentials.py**
```python
def test_use_production_gigachat():
    """Verify GigaChat uses production credentials"""
    from shared.llm.unified_llm_client import get_client

    client = get_client(provider="gigachat")
    # Should use config.py, not env vars
    assert client.auth_method == "oauth"
```

### –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ Sber500

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ (Iteration 50) | –ü–æ—Å–ª–µ (Iteration 51) | Œî |
|---------|-------------------|----------------------|---|
| Qdrant vectors | 53 | **5,053** | +5,000 ‚úÖ |
| Collections | 2 | **7** | +5 ‚úÖ |
| GigaChat tokens used | 0 | **5,000,000** | +5M ‚úÖ |
| WriterAgent quality | 3.25/10 | **5-6/10** | +2 üéØ |
| ReviewerAgent requirements | 11 | **30+** | +20 üéØ |
| InterviewerAgent questions | 50 fixed | **Adaptive (RL)** | Smart ‚úÖ |

---

## üìã Success Criteria

**Must Have (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ):**
1. ‚úÖ 5 –Ω–æ–≤—ã—Ö Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–π —Å–æ–∑–¥–∞–Ω—ã
2. ‚úÖ 5 –º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤ GigaChat Embeddings –ø–æ—Ç—Ä–∞—á–µ–Ω–æ
3. ‚úÖ user_projects –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã (–≤—Å–µ grant_applications –∏–∑ –ë–î)
4. ‚úÖ WriterAgent –∏—Å–ø–æ–ª—å–∑—É–µ—Ç successful_grants
5. ‚úÖ RL –¥–ª—è InterviewerAgent —Ä–∞–±–æ—Ç–∞–µ—Ç (Q-learning –±–∞–∑–æ–≤—ã–π)

**Should Have (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ):**
1. ‚úÖ ReviewerAgent –∏—Å–ø–æ–ª—å–∑—É–µ—Ç grant_criteria
2. ‚úÖ –¢–µ—Å—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–¥–æ/–ø–æ—Å–ª–µ) –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–ª—É—á—à–µ–Ω–∏–µ
3. ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π

**Nice to Have (–±–æ–Ω—É—Å):**
1. ‚≠ê Dashboard –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ embeddings (t-SNE/UMAP)
2. ‚≠ê A/B —Ç–µ—Å—Ç: RL vs Random question selection
3. ‚≠ê –≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏

---

## üóìÔ∏è Timeline (2 –¥–Ω—è) - Following PROJECT-EVOLUTION-METHODOLOGY

### –î–µ–Ω—å 1 (26 –æ–∫—Ç—è–±—Ä—è, —Å–µ–≥–æ–¥–Ω—è)

**Commit #1: Iteration plan + schemas (—É—Ç—Ä–æ, 2 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Plan + collection schemas"
```
- ‚úÖ Create iteration plan (—ç—Ç–æ—Ç —Ñ–∞–π–ª)
- Create Qdrant collection schemas (JSON)
- Create data models (Pydantic)
- **Test:** Schema validation
- **CI:** Lint + type check

**Commit #2: Data collection + Unit tests (–¥–µ–Ω—å, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Data parsers + unit tests"
```
- Scrape successful_grants (–§–ü–ì parser)
- Create grant_criteria dataset
- Unit tests –¥–ª—è –ø–∞—Ä—Å–µ—Ä–æ–≤ (70% coverage)
- **Test:** `test_fpg_parser.py`, `test_criteria_loader.py`
- **CI:** All unit tests pass

**Commit #3: Embeddings loader + Integration test (–≤–µ—á–µ—Ä, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): GigaChat embeddings loader"
```
- Create `scripts/gigachat_embeddings_loader.py`
- Load successful_grants (500K tokens)
- Integration test: `test_gigachat_embedding.py`
- **Test:** Verify collection created, vectors count
- **CI:** Integration tests pass

**Commit #4: Load 3 more collections (–≤–µ—á–µ—Ä, 2 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Load grant_criteria + research + budget"
```
- Load grant_criteria (500K)
- Load research_methodologies (600K)
- Load budget_templates (600K)
- **Test:** All collections green
- **Metrics:** 2.2M / 5M tokens used (44%)

### –î–µ–Ω—å 2 (27 –æ–∫—Ç—è–±—Ä—è)

**Commit #5: Vectorize user_projects (—É—Ç—Ä–æ, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Vectorize all user grant applications"
```
- Query all grant_applications from PostgreSQL
- Create embeddings (2.5M tokens)
- **Test:** `test_user_projects_vectorization.py`
- **Metrics:** 4.7M / 5M tokens used (94%)

**Commit #6: WriterAgent integration (–¥–µ–Ω—å, 2 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Integrate successful_grants in WriterAgent"
```
- Add semantic search to WriterAgent
- Query successful_grants before generation
- **Test:** Compare quality (Iteration 50 baseline)
- **Metrics:** Readiness score improvement

**Commit #7: RL for InterviewerAgent (–¥–µ–Ω—å, 3 —á–∞—Å–∞)**
```bash
git commit -m "feat(iteration-51): Q-learning for InterviewerAgent"
```
- Create `agents/rl_interviewer_agent.py`
- Q-table storage in PostgreSQL
- **Test:** `test_rl_convergence.py` (100 simulations)
- **Metrics:** Questions reduction (50 ‚Üí 40)

**Commit #8: Documentation + SUMMARY (–≤–µ—á–µ—Ä, 2 —á–∞—Å–∞)**
```bash
git commit -m "docs(iteration-51): Summary + metrics for Sber500"
```
- Create ITERATION_51_SUMMARY.md
- Export metrics dashboard
- Final token usage report
- **Deliverable:** Ready for presentation

---

## üîß Technical Implementation

### GigaChat Embeddings API

**Endpoint:**
```python
POST https://gigachat.devices.sberbank.ru/api/v1/embeddings

Headers:
  Authorization: Bearer <access_token>

Body:
{
  "model": "Embeddings",  # –∏–ª–∏ "EmbeddingsGigaR"
  "input": ["—Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"]
}

Response:
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [0.1, 0.2, ...],  # 1024-dim vector
      "index": 0
    }
  ],
  "model": "Embeddings"
}
```

**–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:** 1024 (vs 384 —É Sentence Transformers)

**–°–∫—Ä–∏–ø—Ç:**
```bash
python scripts/create_gigachat_embeddings.py \
  --collection successful_grants \
  --source data/fpg_winners_2020_2024.json \
  --batch-size 100
```

---

## üìä Data Sources

### 1. –§–ü–ì –ø–æ–±–µ–¥–∏—Ç–µ–ª–∏ (successful_grants)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- https://—Ñ–æ–Ω–¥–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å–∫–∏—Ö–≥—Ä–∞–Ω—Ç–æ–≤.—Ä—Ñ/competitions/results
- –ü–∞—Ä—Å–∏–Ω–≥: BeautifulSoup + Selenium
- –§–æ—Ä–º–∞—Ç: JSON [{title, problem, solution, ...}, ...]

### 2. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ (grant_criteria)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –§–ü–ì: https://—Ñ–æ–Ω–¥–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å–∫–∏—Ö–≥—Ä–∞–Ω—Ç–æ–≤.—Ä—Ñ/
- –†–ù–§: https://rscf.ru/
- –†–§–§–ò –∞—Ä—Ö–∏–≤
- –†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞

### 3. –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ (research_methodologies)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ (Google Scholar)
- –ú–µ—Ç–æ–¥–∏—á–∫–∏ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤
- Best practices (Harvard Business Review, etc.)

### 4. –ë—é–¥–∂–µ—Ç—ã (budget_templates)
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- –ü–æ–±–µ–¥–∏–≤—à–∏–µ –∑–∞—è–≤–∫–∏ (–ø—É–±–ª–∏—á–Ω—ã–µ)
- –®–∞–±–ª–æ–Ω—ã —Ñ–æ–Ω–¥–æ–≤
- –ù–∞—à –æ–ø—ã—Ç

### 5. –ü—Ä–æ–µ–∫—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (user_projects)
**–ò—Å—Ç–æ—á–Ω–∏–∫:**
- PostgreSQL: `grant_applications` table
- –§–∏–ª—å—Ç—Ä: –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å content_json IS NOT NULL

---

## üéì RL Theory (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è)

### Q-Learning –æ—Å–Ω–æ–≤—ã

**Q-value (–∫–∞—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏—è):**
```
Q(state, action) = –æ–∂–∏–¥–∞–µ–º–∞—è –Ω–∞–≥—Ä–∞–¥–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ action –≤ state
```

**Update rule:**
```
Q(s, a) ‚Üê Q(s, a) + Œ±[r + Œ≥¬∑max Q(s', a') - Q(s, a)]
```

–ì–¥–µ:
- Œ± (alpha) = learning rate (0.1) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- Œ≥ (gamma) = discount factor (0.9) - –≤–∞–∂–Ω–æ—Å—Ç—å –±—É–¥—É—â–∏—Ö –Ω–∞–≥—Ä–∞–¥
- r = immediate reward - –º–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞
- s' = next state - —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

### –ü—Ä–∏–º–µ—Ä –¥–ª—è InterviewerAgent

**State:**
```python
state = {
  'answered_questions': [1, 5, 12],
  'current_topic': 'team',
  'completeness': 0.3  # 30% –∑–∞–ø–æ–ª–Ω–µ–Ω–æ
}
```

**Action:**
```python
action = question_id  # ID —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ (1-50)
```

**Reward:**
```python
# –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é:
if grant_approved:
  reward = +10
elif grant_submitted:
  reward = +5
else:
  reward = -5

# –ë–æ–Ω—É—Å –æ—Ç ReviewerAgent:
reward += (readiness_score - 5) * 2  # +2 –∑–∞ –∫–∞–∂–¥—ã–π –±–∞–ª–ª >5
```

### Convergence (—Å—Ö–æ–¥–∏–º–æ—Å—Ç—å)

**–û–∂–∏–¥–∞–µ–º:**
- –ü–æ—Å–ª–µ 50-100 –∏–Ω—Ç–µ—Ä–≤—å—é: Q-values —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É—é—Ç—Å—è
- Epsilon decay: 0.1 ‚Üí 0.05 (–º–µ–Ω—å—à–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
- Avg questions per interview: 50 ‚Üí 35-40 (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)

---

## üöÄ Deployment Plan

**Staging (—Ç–µ—Å—Ç):**
1. –°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–∞ prod Qdrant (5.35.88.251:6333)
2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –ë–î
3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ–∫–µ–Ω—ã: –±–∞–ª–∞–Ω—Å –¥–æ/–ø–æ—Å–ª–µ

**Production (–±–æ–µ–≤–æ–π):**
1. –û–±–Ω–æ–≤–∏—Ç—å WriterAgent (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å successful_grants)
2. –û–±–Ω–æ–≤–∏—Ç—å ReviewerAgent (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å grant_criteria)
3. –î–µ–ø–ª–æ–π RL InterviewerAgent (—Å fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π)

**Rollback plan:**
- –°—Ç–∞—Ä—ã–µ –∞–≥–µ–Ω—Ç—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
- RL —Ç–æ–ª—å–∫–æ –¥–ª—è A/B —Ç–µ—Å—Ç–∞ (50% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)

---

## üìö References

- **GigaChat Embeddings:** https://developers.sber.ru/docs/ru/gigachat/guides/embeddings
- **Qdrant Collections:** http://5.35.88.251:6333/dashboard
- **RL Theory:** Sutton & Barto "Reinforcement Learning: An Introduction"
- **Q-Learning:** https://en.wikipedia.org/wiki/Q-learning

---

## ‚úÖ Checklist

**Planning:**
- [x] Create iteration plan
- [ ] Collect data sources
- [ ] Design collection schemas
- [ ] Estimate token usage

**Execution:**
- [ ] Create 5 Qdrant collections
- [ ] Load successful_grants (500K)
- [ ] Load grant_criteria (500K)
- [ ] Load research_methodologies (600K)
- [ ] Load budget_templates (600K)
- [ ] Vectorize user_projects (2.5M)
- [ ] Implement RL for InterviewerAgent
- [ ] Integration tests

**Validation:**
- [ ] Test WriterAgent improvement
- [ ] Test ReviewerAgent accuracy
- [ ] Test RL convergence
- [ ] Measure token usage (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å ~5M)

**Documentation:**
- [ ] Update ITERATION_51_SUMMARY.md
- [ ] Create metrics dashboard
- [ ] Git commit

---

**Status:** üöÄ READY TO START
**Estimated time:** 2 days (20 hours total)
**Tokens budget:** 5,000,000
**Key deliverable:** 5 –Ω–æ–≤—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π + RL –¥–ª—è InterviewerAgent + –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è Sber500
