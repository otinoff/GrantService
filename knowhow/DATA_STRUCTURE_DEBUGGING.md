# Debugging Data Structures - Nested Dicts

**–î–∞—Ç–∞:** 2025-10-29
**–ò—Å—Ç–æ—á–Ω–∏–∫:** Iteration 62 - N/A Bug Fix
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤ production

---

## üêõ –ü—Ä–æ–±–ª–µ–º–∞: N/A –≤–º–µ—Å—Ç–æ –¥–∞–Ω–Ω—ã—Ö

### –°–∏–º–ø—Ç–æ–º

–§–∞–π–ª `research_*.txt` –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
```
=== –ó–ê–ü–†–û–° 1 ===

–í–æ–ø—Ä–æ—Å: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞...

–û—Ç–≤–µ—Ç:
N/A

------------------------------------------------------------
```

–í–º–µ—Å—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ:
```
–û—Ç–≤–µ—Ç:
–†–ï–ó–Æ–ú–ï: –ü–æ –¥–∞–Ω–Ω—ã–º –†–æ—Å—Å—Ç–∞—Ç–∞ –∑–∞ 2022-2024 –≥–æ–¥—ã...
[200-300 —Å–ª–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞]
```

### Root Cause

**Mismatch –º–µ–∂–¥—É —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –¥–∞–Ω–Ω—ã—Ö:**

**–ß—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç API** (`researcher_agent.py:_websearch_simple()`):
```python
{
    'query': '–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞...',
    'result': {                    # ‚Üê Nested structure
        'summary': '[Real answer]',
        'raw_response': '[Full text]'
    }
}
```

**–ß—Ç–æ –∏—Å–∫–∞–ª –ø–∞—Ä—Å–µ—Ä** (`file_generators.py:generate_research_txt()`):
```python
answer = query_data.get('answer', 'N/A')  # ‚Üê Wrong key!
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ö–ª—é—á `'answer'` –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è default `'N/A'`

---

## üîç –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è Debugging

### –®–∞–≥ 1: –ù–∞–π—Ç–∏ –≥–¥–µ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ

**–í–æ–ø—Ä–æ—Å:** –û—Ç–∫—É–¥–∞ –±–µ—Ä—É—Ç—Å—è research results?

**–ü–æ–∏—Å–∫:**
```bash
grep -r "websearch_simple" agents/
grep -r "research_anketa" agents/
```

**–ù–∞–π–¥–µ–Ω–æ:**
- `agents/researcher_agent.py` - –º–µ—Ç–æ–¥ `research_anketa()` –∏ `_websearch_simple()`

### –®–∞–≥ 2: –ü—Ä–æ—á–∏—Ç–∞—Ç—å –∫–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

**File:** `agents/researcher_agent.py:393-469`

```python
def _websearch_simple(self, query: str, ...) -> Dict:
    """
    Perform WebSearch using Claude Code
    Returns: {
        'query': str,
        'result': {
            'summary': str,    # ‚Üê Actual answer here!
            'raw_response': str
        }
    }
    """
    # ... WebSearch call ...
    return {
        'query': query,
        'result': {
            'summary': claude_response,
            'raw_response': claude_response
        }
    }
```

**–í—ã–≤–æ–¥:** –î–∞–Ω–Ω—ã–µ –í–õ–û–ñ–ï–ù–´ –≤ `result.summary`, –∞ –Ω–µ –≤ –ø–ª–æ—Å–∫–æ–º `answer`

### –®–∞–≥ 3: –ù–∞–π—Ç–∏ –≥–¥–µ —á–∏—Ç–∞—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ

**–í–æ–ø—Ä–æ—Å:** –ì–¥–µ —Ñ–∞–π–ª –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è?

**–ü–æ–∏—Å–∫:**
```bash
grep -r "generate_research_txt" shared/
grep -r "research_.*\.txt" telegram-bot/
```

**–ù–∞–π–¥–µ–Ω–æ:**
- `shared/telegram_utils/file_generators.py:generate_research_txt()`

### –®–∞–≥ 4: –°—Ä–∞–≤–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**–û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (parser):**
```python
# file_generators.py:462
answer = query_data.get('answer', 'N/A')
```

**–†–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (API):**
```python
# researcher_agent.py:469
return {'query': '...', 'result': {'summary': '...'}}
```

**Mismatch –Ω–∞–π–¥–µ–Ω!** ‚ùå

### –®–∞–≥ 5: –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–∫—Å

**BEFORE:**
```python
answer = query_data.get('answer', 'N/A')
```

**AFTER:**
```python
result = query_data.get('result', {})
answer = result.get('summary', 'N/A')
```

---

## üõ†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω—ã Extraction

### –ü–∞—Ç—Ç–µ—Ä–Ω 1: Flat Dict (–ø—Ä–æ—Å—Ç–æ–π)

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```python
data = {'name': 'John', 'age': 30}
```

**Extraction:**
```python
name = data.get('name', 'Unknown')
```

### –ü–∞—Ç—Ç–µ—Ä–Ω 2: Nested Dict (–≤–ª–æ–∂–µ–Ω–Ω—ã–π)

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```python
data = {
    'user': {
        'name': 'John',
        'profile': {
            'email': 'john@example.com'
        }
    }
}
```

**Extraction (–ü–†–ê–í–ò–õ–¨–ù–û):**
```python
user = data.get('user', {})
name = user.get('name', 'Unknown')

profile = user.get('profile', {})
email = profile.get('email', 'N/A')
```

**Extraction (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–û):**
```python
# ‚ùå KeyError –µ—Å–ª–∏ 'user' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
name = data['user']['name']

# ‚ùå –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å
name = data.get('name', 'Unknown')  # –í—Å–µ–≥–¥–∞ 'Unknown'!
```

### –ü–∞—Ç—Ç–µ—Ä–Ω 3: List of Dicts

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```python
data = {
    'queries': [
        {'query': 'Q1', 'result': {'summary': 'A1'}},
        {'query': 'Q2', 'result': {'summary': 'A2'}}
    ]
}
```

**Extraction:**
```python
queries = data.get('queries', [])
for query_data in queries:
    query_text = query_data.get('query', 'N/A')

    # –ò–∑–≤–ª–µ—á—å –≤–ª–æ–∂–µ–Ω–Ω—ã–π result
    result = query_data.get('result', {})
    answer = result.get('summary', 'N/A')
```

---

## üìã Debugging Checklist

**–ö–æ–≥–¥–∞ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç N/A, None, default):**

1. **[ ] –ù–∞–π—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö**
   - –ì–¥–µ –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è? (API, database, agent)
   - –ö–∞–∫–æ–π –º–µ—Ç–æ–¥ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ?

2. **[ ] –ü—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö**
   - –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π
   - –ù–∞–π—Ç–∏ `return` statement
   - –ó–∞–ø–∏—Å–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞ –±—É–º–∞–≥–µ

3. **[ ] –ù–∞–π—Ç–∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è –¥–∞–Ω–Ω—ã—Ö**
   - –ì–¥–µ –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è?
   - –ö–∞–∫–∏–µ –∫–ª—é—á–∏ –∏—â–µ—Ç –∫–æ–¥?

4. **[ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã**
   - –°–æ–≤–ø–∞–¥–∞—é—Ç –ª–∏ –∫–ª—é—á–∏?
   - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–∏ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å?
   - –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–∞—é—Ç?

5. **[ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–∫—Å**
   - –ò–∑–º–µ–Ω–∏—Ç—å extraction –∫–æ–¥
   - –î–æ–±–∞–≤–∏—Ç—å `.get()` –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å defaults (`'N/A'`, `{}`, `[]`)

6. **[ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å**
   - –õ–æ–∫–∞–ª—å–Ω–æ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
   - –ù–∞ production —Å real user flow
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å edge cases (–ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ, None)

---

## üéØ Best Practices

### 1. –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π `.get()` –¥–ª—è dict

```python
# ‚ùå BAD - –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å KeyError
value = data['key']

# ‚úÖ GOOD - –±–µ–∑–æ–ø–∞—Å–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default
value = data.get('key', 'default')
```

### 2. –ü—Ä–æ–≤–µ—Ä—è–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–¥ –¥–æ—Å—Ç—É–ø–æ–º

```python
# ‚ùå BAD - KeyError –µ—Å–ª–∏ 'result' –Ω–µ—Ç
answer = data['result']['summary']

# ‚úÖ GOOD - –±–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç
result = data.get('result', {})
answer = result.get('summary', 'N/A')
```

### 3. –ò—Å–ø–æ–ª—å–∑—É–π meaningful defaults

```python
# ‚ùå BAD - default None —Å–∫—Ä—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É
answer = data.get('answer', None)

# ‚úÖ GOOD - default –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç
answer = data.get('answer', 'N/A')
count = data.get('count', 0)
items = data.get('items', [])
```

### 4. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö

```python
def process_research(research_data: Dict[str, Any]) -> str:
    """
    Process research results

    Expected structure:
    {
        'queries': [
            {
                'query': str,
                'result': {
                    'summary': str,
                    'raw_response': str
                }
            }
        ]
    }
    """
    queries = research_data.get('queries', [])
    # ...
```

### 5. –î–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏

```python
# Extract answer from nested 'result.summary'
result = query_data.get('result', {})
answer = result.get('summary', 'N/A')
```

---

## üîç Debugging Tools

### 1. Print —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö

```python
import json
print(json.dumps(data, indent=2, ensure_ascii=False))
```

### 2. –ü—Ä–æ–≤–µ—Ä—å —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö

```python
print(f"Type: {type(data)}")
print(f"Keys: {data.keys() if isinstance(data, dict) else 'Not a dict'}")
```

### 3. Trace data flow

```python
# –í –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏
logger.info(f"Input data: {data}")

# –ü–æ—Å–ª–µ extraction
logger.info(f"Extracted answer: {answer}")
```

### 4. Unit test —Å —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π

```python
def test_extract_nested_answer():
    # –ö–æ–ø–∏—Ä—É–µ–º –†–ï–ê–õ–¨–ù–£–Æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ API
    query_data = {
        'query': 'test query',
        'result': {
            'summary': 'test answer',
            'raw_response': 'full text'
        }
    }

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º extraction
    result = query_data.get('result', {})
    answer = result.get('summary', 'N/A')

    assert answer == 'test answer'
```

---

## üß™ –ü—Ä–∏–º–µ—Ä –∏–∑ Iteration 62

### –†–µ–∞–ª—å–Ω—ã–π –∫–æ–¥ –î–û —Ñ–∏–∫—Å–∞

**File:** `shared/telegram_utils/file_generators.py:460-467`

```python
for i, query_data in enumerate(queries, 1):
    query_text = query_data.get('query', 'N/A')
    answer = query_data.get('answer', 'N/A')  # ‚Üê WRONG!
    sources = query_data.get('sources', [])

    lines.append(f"=== –ó–ê–ü–†–û–° {i} ===")
    lines.append(f"–í–æ–ø—Ä–æ—Å: {query_text}")
    lines.append(f"–û—Ç–≤–µ—Ç:\n{answer}")  # –í—Å–µ–≥–¥–∞ N/A!
```

### –†–µ–∞–ª—å–Ω—ã–π –∫–æ–¥ –ü–û–°–õ–ï —Ñ–∏–∫—Å–∞

```python
for i, query_data in enumerate(queries, 1):
    query_text = query_data.get('query', 'N/A')

    # ITERATION 62 FIX: Extract answer from nested 'result.summary'
    result = query_data.get('result', {})
    answer = result.get('summary', 'N/A')

    sources = query_data.get('sources', [])

    lines.append(f"=== –ó–ê–ü–†–û–° {i} ===")
    lines.append(f"–í–æ–ø—Ä–æ—Å: {query_text}")
    lines.append(f"–û—Ç–≤–µ—Ç:\n{answer}")  # –¢–µ–ø–µ—Ä—å —Ä–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç!
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç

**BEFORE:**
```
–û—Ç–≤–µ—Ç:
N/A
```

**AFTER:**
```
–û—Ç–≤–µ—Ç:
–†–ï–ó–Æ–ú–ï: –ü–æ –¥–∞–Ω–Ω—ã–º –†–æ—Å—Å—Ç–∞—Ç–∞ –∑–∞ 2022-2024 –≥–æ–¥—ã, –≤ –†–æ—Å—Å–∏–∏ –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è...
[200-300 —Å–ª–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞]
–ò–°–¢–û–ß–ù–ò–ö–ò: rosstat.gov.ru, mintrud.gov.ru
```

---

## üí° Lessons Learned

### –ß—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫:

1. **–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö** –≤–º–µ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–π
2. **–ù–µ –¥–æ–±–∞–≤–∏–ª–∏ integration test** –º–µ–∂–¥—É researcher_agent –∏ file_generators
3. **–ù–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏** expected data structure –≤ docstrings

### –ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å –≤ –±—É–¥—É—â–µ–º:

1. ‚úÖ **–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ä–µ–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É** –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ API/agent
2. ‚úÖ **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É** –≤ docstrings —Ñ—É–Ω–∫—Ü–∏–π
3. ‚úÖ **–ü–∏—Å–∞—Ç—å integration tests** –¥–ª—è data flow –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏
4. ‚úÖ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å type hints** –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è mismatches
5. ‚úÖ **–î–æ–±–∞–≤–ª—è—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏** –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–∑ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä

### –£–ª—É—á—à–µ–Ω–∏—è –¥–ª—è –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã:

```python
# –î–æ–±–∞–≤–∏—Ç—å type hint –¥–ª—è research results
from typing import TypedDict

class ResearchResult(TypedDict):
    query: str
    result: dict[str, str]  # {'summary': str, 'raw_response': str}

def _websearch_simple(self, query: str) -> ResearchResult:
    """Returns structured research result"""
    return {
        'query': query,
        'result': {
            'summary': answer,
            'raw_response': full_text
        }
    }
```

---

## üîó Related Knowhow

- `knowhow/DEPLOYMENT_SSH_PRACTICES.md` - SSH deployment workflow
- `knowhow/TESTING_BEST_PRACTICES.md` - Integration testing patterns
- `iterations/Iteration_62_Fix_Research_Results_Parsing/` - –ü–æ–ª–Ω—ã–π example

---

**–ê–≤—Ç–æ—Ä:** Claude Code
**–î–∞—Ç–∞:** 2025-10-29
**Iteration:** 62
**Impact:** Critical bug fix (blocked research data flow)
**Status:** ‚úÖ Production-tested

---

# Production Database Schema & Credentials

**–î–∞—Ç–∞:** 2025-10-29
**–ò—Å—Ç–æ—á–Ω–∏–∫:** Iteration 64 - Full E2E Pipeline
**–°—Ç–∞—Ç—É—Å:** ‚úÖ Tested in production

---

## üêõ –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ credentials –∏ table names

### –°–∏–º–ø—Ç–æ–º 1: Authentication Failed

```
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1),
port 5434 failed: FATAL: password authentication failed for user "postgres"
```

### –°–∏–º–ø—Ç–æ–º 2: Table Does Not Exist

```
psycopg2.errors.UndefinedTable: relation "audits" does not exist
LINE 2: INSERT INTO audits (session_id, audit_data...)
```

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ

### Production Database Credentials

```bash
# ‚ùå WRONG (Local dev)
PGUSER=postgres
PGPASSWORD=root
PGPORT=5432

# ‚úÖ CORRECT (Production - 5.35.88.251)
export PGHOST=localhost
export PGPORT=5434
export PGDATABASE=grantservice
export PGUSER=grantservice
export PGPASSWORD='jPsGn%Nt%q#THnUB&&cqo*1Q'
```

### Production Table Names

| Dev/Test Name | Production Name | Status |
|---------------|-----------------|--------|
| `audits` | `auditor_results` | ‚úÖ EXISTS |
| `researcher_research` | `researcher_research` | ‚úÖ EXISTS |
| `grants` | `grants` | ‚úÖ EXISTS |
| `reviews` | N/A | ‚ùå DOES NOT EXIST |

**Key Tables:**
- `auditor_results` - Audit data from AuditorAgentClaude
- `researcher_research` - Research results from ResearcherAgent
- `grants` - Grant applications from WriterAgent
- `sessions` - Session data with JSONB answers_data
- `users` - User accounts

---

## üìã –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ SQL Queries

### Step 2 (Audit)

```python
# ‚ùå WRONG
INSERT INTO audits (session_id, audit_data, created_at)
VALUES (%s, %s, %s)

# ‚úÖ CORRECT
INSERT INTO auditor_results (session_id, audit_data, created_at)
VALUES (%s, %s, %s)
```

### Step 5 (Review)

```python
# ‚ùå WRONG - Table doesn't exist
INSERT INTO reviews (session_id, review_data, created_at)

# ‚úÖ CORRECT - Skip DB save, file-only
logger.info("‚ö†Ô∏è Skipping database save (reviews table not found)")
# Just generate review_*.txt file
```

---

## üîç How to Check Schema

```bash
# Connect to production DB
PGPASSWORD='jPsGn%Nt%q#THnUB&&cqo*1Q' psql \
  -h localhost \
  -p 5434 \
  -U grantservice \
  -d grantservice \
  -c '\dt'

# Check specific tables
PGPASSWORD='...' psql -h localhost -p 5434 -U grantservice -d grantservice \
  -c "SELECT table_name FROM information_schema.tables
      WHERE table_schema='public'
      AND table_name ~ 'audit|research|grant|review';"
```

---

## üö® Common Mistakes

### 1. Wrong Port (5432 instead of 5434)

```bash
# ‚ùå WRONG - Default PostgreSQL port
psql -h localhost -U grantservice -d grantservice
# Fails: password authentication failed

# ‚úÖ CORRECT - Custom port 5434
psql -h localhost -p 5434 -U grantservice -d grantservice
```

### 2. Wrong User (postgres instead of grantservice)

```bash
# ‚ùå WRONG
PGUSER=postgres

# ‚úÖ CORRECT
PGUSER=grantservice
```

### 3. Wrong Table Names

```python
# ‚ùå WRONG
self.db.execute("INSERT INTO audits ...")

# ‚úÖ CORRECT
self.db.execute("INSERT INTO auditor_results ...")
```

---

## üìö Related Code

**Files using DB:**
- `scripts/e2e_synthetic_workflow.py` - E2E pipeline
- `data/database/models.py` - Database connection class
- `agents/*_agent.py` - Agent implementations

**Environment Setup:**
```python
# agents/base_agent.py or scripts
import os
os.environ['PGHOST'] = 'localhost'
os.environ['PGPORT'] = '5434'
os.environ['PGDATABASE'] = 'grantservice'
os.environ['PGUSER'] = 'grantservice'
os.environ['PGPASSWORD'] = 'jPsGn%Nt%q#THnUB&&cqo*1Q'

db = GrantServiceDatabase()  # Will use env vars
```

---

**–ê–≤—Ç–æ—Ä:** Claude Code
**–î–∞—Ç–∞:** 2025-10-29
**Iteration:** 64
**Impact:** Critical - Production deployment blocker
**Status:** ‚úÖ Documented and fixed

---

## üìä Production Table Schemas (Complete)

### grants Table

**Full Schema** (queried via `\d grants` on production):

```sql
Column            | Type                        | Constraints
------------------+-----------------------------+----------------------------------
grant_id          | varchar(50)                 | not null, unique
anketa_id         | varchar(50)                 | not null, FK ‚Üí sessions.anketa_id
research_id       | varchar(100)                | FK ‚Üí researcher_research.research_id
user_id           | bigint                      | not null, FK ‚Üí users.telegram_id
grant_title       | varchar(200)                |
grant_content     | text                        |
grant_sections    | jsonb                       |
metadata          | jsonb                       |
llm_provider      | varchar(50)                 | not null
model             | varchar(50)                 |
status            | varchar(30)                 | default 'draft'
created_at        | timestamp                   | default CURRENT_TIMESTAMP
updated_at        | timestamp                   | default CURRENT_TIMESTAMP

Indexes:
  "grants_pkey" PRIMARY KEY, btree (grant_id)
  "grants_anketa_id_key" UNIQUE CONSTRAINT, btree (anketa_id)
  "grants_grant_id_key" UNIQUE CONSTRAINT, btree (grant_id)

Foreign Key Constraints:
  "grants_anketa_id_fkey" FOREIGN KEY (anketa_id) ‚Üí sessions(anketa_id)
  "grants_research_id_fkey" FOREIGN KEY (research_id) ‚Üí researcher_research(research_id)
  "grants_user_id_fkey" FOREIGN KEY (user_id) ‚Üí users(telegram_id)
```

**Correct INSERT Query:**

```python
# ITERATION 64 FIX: Use correct grants table schema
timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
grant_id = f"{anketa_id}-GR-{timestamp}"

# Extract title (first line or default)
grant_title = grant_text.split('\n')[0][:200] if grant_text else "–ì—Ä–∞–Ω—Ç–æ–≤–∞—è –∑–∞—è–≤–∫–∞"

with self.db.connect() as conn:
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO grants (
            grant_id, anketa_id, research_id, user_id,
            grant_title, grant_content, grant_sections, metadata,
            llm_provider, model, status, created_at
        )
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """, (
        grant_id,           # varchar(50) - Primary key
        anketa_id,          # varchar(50) - FK to sessions
        research_id,        # varchar(100) - FK to researcher_research
        telegram_id,        # bigint - FK to users
        grant_title,        # varchar(200)
        grant_text,         # text - Full grant content
        json.dumps({}),     # jsonb - Empty sections structure
        json.dumps({'generated_by': 'e2e_workflow'}),  # jsonb - Metadata
        'gigachat',         # varchar(50) - LLM provider
        'GigaChat-Max',     # varchar(50) - Model name
        'draft',            # varchar(30) - Status
        datetime.now()      # timestamp - Created at
    ))
    conn.commit()
```

### researcher_research Table

**Key Fields:**

```sql
Column            | Type                        | Constraints
------------------+-----------------------------+----------------------------------
research_id       | varchar(100)                | not null, unique (PRIMARY KEY)
session_id        | integer                     | not null, FK ‚Üí sessions
anketa_id         | varchar(50)                 | FK ‚Üí sessions.anketa_id
research_data     | jsonb                       | Full research results
queries           | jsonb                       | Array of queries
created_at        | timestamp                   |
```

**Correct INSERT Query:**

```python
# ITERATION 64 FIX: Make research_id unique with timestamp
timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
research_id = f"{anketa_id}-RS-{timestamp}"

with self.db.connect() as conn:
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO researcher_research (
            research_id, session_id, anketa_id,
            research_data, queries, created_at
        )
        VALUES (%s, %s, %s, %s, %s, %s)
    """, (
        research_id,
        session_id,
        anketa_id,
        json.dumps(research_data),
        json.dumps(queries),
        datetime.now()
    ))
```

---

## üîë Pattern: Timestamp-Based Unique IDs

### Problem: Static IDs Cause Duplicates

**‚ùå BAD Pattern:**
```python
research_id = f"{anketa_id}-RS-001"  # Always same ID!
# ‚Üí duplicate key violation when re-running workflow
```

**Why it fails:**
- E2E workflows may re-run with same anketa_id
- Testing creates duplicate entries
- No uniqueness guarantee

### Solution: Add Timestamp

**‚úÖ GOOD Pattern:**
```python
from datetime import datetime

timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
research_id = f"{anketa_id}-RS-{timestamp}"
# Example: "ANK-20251029031145-RS-20251029031202"
```

**Benefits:**
- ‚úÖ Guaranteed unique per second
- ‚úÖ Human-readable timestamp
- ‚úÖ Sortable chronologically
- ‚úÖ Debugging-friendly

### When to Use

**Use timestamp-based IDs for:**
1. **Research IDs** - Multiple research runs per anketa
2. **Grant IDs** - Multiple grant versions
3. **Audit IDs** - Multiple audits
4. **Review IDs** - Multiple reviews

**Don't use for:**
1. **User IDs** - Already unique (telegram_id)
2. **Session IDs** - Database auto-increment
3. **Anketa IDs** - Already timestamp-based in session creation

### Full Pattern

```python
from datetime import datetime

def generate_unique_id(prefix: str, base_id: str) -> str:
    """
    Generate unique ID with timestamp

    Args:
        prefix: ID type prefix (RS, GR, AU, RV)
        base_id: Base identifier (usually anketa_id)

    Returns:
        Unique ID like: "ANK-123-RS-20251029031145"

    Example:
        >>> generate_unique_id("RS", "ANK-20251029-001")
        "ANK-20251029-001-RS-20251029031145"
    """
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    return f"{base_id}-{prefix}-{timestamp}"

# Usage:
research_id = generate_unique_id("RS", anketa_id)
grant_id = generate_unique_id("GR", anketa_id)
audit_id = generate_unique_id("AU", anketa_id)
review_id = generate_unique_id("RV", anketa_id)
```

---

**–ê–≤—Ç–æ—Ä:** Claude Code
**–î–∞—Ç–∞:** 2025-10-29
**Iteration:** 64
**Impact:** Critical - Resolved duplicate key violations and schema mismatches
**Status:** ‚úÖ Production-tested and documented
