#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Claude Code WebSearch Client –¥–ª—è Researcher Agent

–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ ClaudeCodeClient —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π WebSearch API
–¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è 27 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

API: http://178.236.17.55:8000
–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π: http://5.35.88.251:8000

–ê–≤—Ç–æ—Ä: AI Integration Specialist
–î–∞—Ç–∞: 2025-10-08
"""

import aiohttp
import asyncio
import json
from typing import Optional, Dict, Any, List
from datetime import datetime
import logging
import os

logger = logging.getLogger(__name__)


class ClaudeCodeWebSearchClient:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è WebSearch —á–µ—Ä–µ–∑ Claude Code API"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: str = "http://178.236.17.55:8000",
        timeout: int = 120  # –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–ª—è WebSearch
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞

        Args:
            api_key: API –∫–ª—é—á (–∏–ª–∏ –∏–∑ CLAUDE_CODE_API_KEY env)
            base_url: –ë–∞–∑–æ–≤—ã–π URL API
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self.api_key = api_key or os.getenv('CLAUDE_CODE_API_KEY', '1f79b062cf00b8d28546f5bd283dc59a1c6a7f9e9fe5a8e5ef25b0cc27aa0732')
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.session: Optional[aiohttp.ClientSession] = None
        self.debug_log = []

        logger.info(f"üîß ClaudeCodeWebSearchClient –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {base_url}")

    async def __aenter__(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ HTTP —Å–µ—Å—Å–∏–∏ –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        timeout_config = aiohttp.ClientTimeout(total=self.timeout)

        self.session = aiohttp.ClientSession(
            headers=headers,
            timeout=timeout_config
        )

        logger.info("‚úÖ ClaudeCodeWebSearchClient —Å–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞")
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ HTTP —Å–µ—Å—Å–∏–∏ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if self.session:
            await self.session.close()
            logger.info("üîí ClaudeCodeWebSearchClient —Å–µ—Å—Å–∏—è –∑–∞–∫—Ä—ã—Ç–∞")

    async def websearch(
        self,
        query: str,
        allowed_domains: Optional[List[str]] = None,
        max_results: int = 5,
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å WebSearch –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Claude Code

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            allowed_domains: –°–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä ['rosstat.gov.ru', 'gov.ru'])
            max_results: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (1-10)
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            {
                'query': 'original query',
                'results': [
                    {
                        'title': 'Result title',
                        'url': 'https://...',
                        'snippet': 'Text snippet',
                        'source': 'rosstat.gov.ru',
                        'date': '2024-03-15',
                        'relevance_score': 0.95
                    }
                ],
                'sources': ['rosstat.gov.ru', 'government.ru'],
                'total_results': 5,
                'search_time': 1.23
            }

        Raises:
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–µ API
        """
        url = f"{self.base_url}/websearch"

        payload = {
            "query": query,
            "max_results": min(max_results, 10)  # Limit to 10
        }

        if allowed_domains:
            payload["allowed_domains"] = allowed_domains
        if session_id:
            payload["session_id"] = session_id

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "endpoint": "/websearch",
            "query_length": len(query),
            "max_results": max_results,
            "allowed_domains": allowed_domains,
            "has_session": session_id is not None
        }
        self.debug_log.append(log_entry)

        try:
            start_time = datetime.now()

            async with self.session.post(url, json=payload) as response:
                response_text = await response.text()

                search_time = (datetime.now() - start_time).total_seconds()

                if response.status == 200:
                    data = json.loads(response_text)

                    # –ò–∑–≤–ª–µ—á—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                    sources = list(set([
                        result.get('source', '')
                        for result in data.get('results', [])
                        if result.get('source')
                    ]))

                    result_data = {
                        'status': 'success',
                        'query': query,
                        'content': data.get('content', ''),  # –ö–†–ò–¢–ò–ß–ù–û: —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
                        'results': data.get('results', []),
                        'sources': sources,
                        'total_results': len(data.get('results', [])),
                        'search_time': search_time,
                        'session_id': data.get('session_id'),
                        'cost': data.get('cost', 0),  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å EKATERINA
                        'usage': data.get('usage', {}),  # Token usage
                        'provider': 'claude_code'
                    }

                    log_entry.update({
                        "status": "success",
                        "results_count": result_data['total_results'],
                        "sources_count": len(sources),
                        "search_time": search_time
                    })
                    self.debug_log.append(log_entry)

                    logger.info(f"‚úÖ WebSearch: '{query[:50]}...' ‚Üí {result_data['total_results']} results, {len(sources)} sources ({search_time:.2f}s)")
                    return result_data

                else:
                    error_msg = f"WebSearch error: {response.status} - {response_text}"
                    logger.error(error_msg)

                    log_entry.update({
                        "status": "error",
                        "error": response_text,
                        "status_code": response.status
                    })
                    self.debug_log.append(log_entry)

                    # –í–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–º–µ—Å—Ç–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è (graceful degradation)
                    return {
                        'status': 'error',
                        'query': query,
                        'results': [],
                        'sources': [],
                        'total_results': 0,
                        'search_time': search_time,
                        'error': error_msg
                    }

        except asyncio.TimeoutError:
            error_msg = f"WebSearch timeout ({self.timeout}s)"
            logger.error(f"‚è±Ô∏è {error_msg}")

            return {
                'status': 'error',
                'query': query,
                'results': [],
                'sources': [],
                'total_results': 0,
                'search_time': self.timeout,
                'error': error_msg
            }

        except Exception as e:
            logger.error(f"‚ùå WebSearch error: {e}")

            return {
                'status': 'error',
                'query': query,
                'results': [],
                'sources': [],
                'total_results': 0,
                'search_time': 0,
                'error': str(e)
            }

    async def batch_websearch(
        self,
        queries: List[str],
        allowed_domains: Optional[List[str]] = None,
        max_results: int = 5,
        max_concurrent: int = 3
    ) -> List[Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ WebSearch –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ

        Args:
            queries: –°–ø–∏—Å–æ–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            allowed_domains: –°–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
            max_results: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å
            max_concurrent: –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∏—Ç—å API)

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:
            [
                {
                    'index': 0,
                    'query': 'query text',
                    'result': {...},  # –†–µ–∑—É–ª—å—Ç–∞—Ç websearch()
                    'error': None –∏–ª–∏ 'error message'
                }
            ]
        """
        logger.info(f"üîç Batch WebSearch: {len(queries)} queries, max_concurrent={max_concurrent}")

        semaphore = asyncio.Semaphore(max_concurrent)

        async def _search_with_semaphore(query: str, index: int):
            async with semaphore:
                try:
                    logger.info(f"   [{index+1}/{len(queries)}] Searching: {query[:60]}...")
                    result = await self.websearch(
                        query=query,
                        allowed_domains=allowed_domains,
                        max_results=max_results
                    )

                    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ –æ—à–∏–±–∫–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                    error = result.get('error')
                    if error:
                        logger.warning(f"   [{index+1}/{len(queries)}] Warning: {error}")

                    return {
                        'index': index,
                        'query': query,
                        'result': result,
                        'error': error
                    }

                except Exception as e:
                    logger.error(f"   [{index+1}/{len(queries)}] Error: {e}")
                    return {
                        'index': index,
                        'query': query,
                        'result': {
                            'query': query,
                            'results': [],
                            'sources': [],
                            'total_results': 0,
                            'error': str(e)
                        },
                        'error': str(e)
                    }

        # –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º
        tasks = [_search_with_semaphore(query, i) for i, query in enumerate(queries)]
        batch_results = await asyncio.gather(*tasks)

        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∏–Ω–¥–µ–∫—Å—É (—á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ä—è–¥–æ–∫)
        batch_results.sort(key=lambda x: x['index'])

        # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        successful = len([r for r in batch_results if r['error'] is None])
        failed = len([r for r in batch_results if r['error'] is not None])
        total_sources = sum(len(r['result'].get('sources', [])) for r in batch_results)
        total_results = sum(r['result'].get('total_results', 0) for r in batch_results)

        logger.info(f"‚úÖ Batch WebSearch completed:")
        logger.info(f"   - Successful: {successful}/{len(queries)}")
        logger.info(f"   - Failed: {failed}/{len(queries)}")
        logger.info(f"   - Total sources: {total_sources}")
        logger.info(f"   - Total results: {total_results}")

        return batch_results

    async def check_health(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API

        Returns:
            True –µ—Å–ª–∏ API –¥–æ—Å—Ç—É–ø–µ–Ω, False –∏–Ω–∞—á–µ
        """
        url = f"{self.base_url}/health"

        try:
            async with self.session.get(url) as response:
                healthy = response.status == 200

                if healthy:
                    logger.info("‚úÖ Claude Code API –∑–¥–æ—Ä–æ–≤")
                else:
                    logger.warning(f"‚ö†Ô∏è Claude Code API –Ω–µ–∑–¥–æ—Ä–æ–≤: {response.status}")

                return healthy

        except Exception as e:
            logger.error(f"‚ùå Claude Code API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            return False

    def get_debug_log(self) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥ –æ—Ç–ª–∞–¥–∫–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –ª–æ–≥–∞
        """
        return self.debug_log.copy()

    def clear_debug_log(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥ –æ—Ç–ª–∞–¥–∫–∏"""
        self.debug_log.clear()
        logger.info("üßπ Debug log –æ—á–∏—â–µ–Ω")

    async def get_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞

        Returns:
            Dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        websearch_logs = [log for log in self.debug_log if log.get("endpoint") == "/websearch"]

        total_requests = len(websearch_logs)
        successful = len([log for log in websearch_logs if log.get("status") == "success"])
        failed = len([log for log in websearch_logs if log.get("status") == "error"])

        total_results = sum(log.get("results_count", 0) for log in websearch_logs)
        total_sources = sum(log.get("sources_count", 0) for log in websearch_logs)

        avg_search_time = (
            sum(log.get("search_time", 0) for log in websearch_logs) / total_requests
            if total_requests > 0 else 0
        )

        return {
            "total_websearch_requests": total_requests,
            "successful": successful,
            "failed": failed,
            "success_rate": (successful / total_requests * 100) if total_requests > 0 else 0,
            "total_results": total_results,
            "total_sources": total_sources,
            "avg_results_per_query": total_results / total_requests if total_requests > 0 else 0,
            "avg_search_time": round(avg_search_time, 2)
        }


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def example_researcher_websearch():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è Researcher Agent"""

    api_key = os.getenv('CLAUDE_CODE_API_KEY', '1f79b062cf00b8d28546f5bd283dc59a1c6a7f9e9fe5a8e5ef25b0cc27aa0732')

    async with ClaudeCodeWebSearchClient(api_key=api_key) as client:
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
        healthy = await client.check_health()
        print(f"API Health: {healthy}")

        # 2. –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
        result = await client.websearch(
            query="–ù–∞–π–¥–∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –†–æ—Å—Å—Ç–∞—Ç –ø–æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã—Ö —Å–µ–∫—Ü–∏–π –≤ –ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –∑–∞ 2022-2024",
            allowed_domains=['rosstat.gov.ru', 'fedstat.ru', 'gov.ru'],
            max_results=5
        )

        print(f"\nSingle query result:")
        print(f"  - Query: {result['query'][:80]}...")
        print(f"  - Results: {result['total_results']}")
        print(f"  - Sources: {result['sources']}")
        print(f"  - Time: {result['search_time']:.2f}s")

        # 3. Batch –∑–∞–ø—Ä–æ—Å—ã (–∫–∞–∫ –¥–ª—è –ë–ª–æ–∫–∞ 1)
        block1_queries = [
            "–ù–∞–π–¥–∏ –Ω–∞—Ü–ø—Ä–æ–µ–∫—Ç—ã 2024-2030 —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å–æ —Å–ø–æ—Ä—Ç–æ–º –¥–ª—è –¥–µ—Ç–µ–π",
            "–ù–∞–π–¥–∏ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é –¥–µ—Ç—Å–∫–æ–≥–æ —Å–ø–æ—Ä—Ç–∞",
            "–ù–∞–π–¥–∏ 3 —É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–∞ —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è –¥–µ—Ç–µ–π –≤ –†–§"
        ]

        batch_results = await client.batch_websearch(
            queries=block1_queries,
            allowed_domains=['rosstat.gov.ru', 'gov.ru', 'nationalprojects.ru'],
            max_results=5,
            max_concurrent=3
        )

        print(f"\nBatch search results:")
        for item in batch_results:
            result = item['result']
            print(f"  [{item['index']+1}] {item['query'][:60]}...")
            print(f"      ‚Üí {result['total_results']} results, {len(result['sources'])} sources")

        # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = await client.get_statistics()
        print(f"\nStatistics:")
        print(f"  - Total requests: {stats['total_websearch_requests']}")
        print(f"  - Success rate: {stats['success_rate']:.1f}%")
        print(f"  - Avg results per query: {stats['avg_results_per_query']:.1f}")
        print(f"  - Avg search time: {stats['avg_search_time']:.2f}s")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞
    asyncio.run(example_researcher_websearch())
