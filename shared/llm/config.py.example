"""
Конфигурация для LLM провайдеров и агентов

ВАЖНО: Это пример конфигурации!
Скопируйте этот файл в config.py и заполните реальными API ключами:
  cp config.py.example config.py

Не коммитьте config.py в git! (уже в .gitignore)
"""

# GigaChat настройки
GIGACHAT_BASE_URL = "https://gigachat.devices.sberbank.ru/api/v1"
GIGACHAT_AUTH_URL = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
GIGACHAT_API_KEY = "YOUR_GIGACHAT_API_KEY_HERE"  # Получить на developers.sber.ru
GIGACHAT_CLIENT_ID = "YOUR_CLIENT_ID_HERE"
GIGACHAT_SCOPE = "GIGACHAT_API_PERS"

# Claude Code API настройки
# Если используете wrapper на 178.236.17.55:
CLAUDE_CODE_API_KEY = "YOUR_WRAPPER_API_KEY"  # API key для wrapper авторизации
CLAUDE_CODE_BASE_URL = "http://178.236.17.55:8000"  # Wrapper сервер
CLAUDE_CODE_DEFAULT_MODEL = "sonnet"  # sonnet (быстрый) или opus (мощный)

# ИЛИ если используете прямой Anthropic API:
# CLAUDE_CODE_BASE_URL = "https://api.anthropic.com"
# CLAUDE_CODE_API_KEY = "sk-ant-api03-..."  # Получить на console.anthropic.com

# Perplexity настройки
PERPLEXITY_BASE_URL = "https://api.perplexity.ai"
PERPLEXITY_API_KEY = "pplx-YOUR_API_KEY"  # Получить на perplexity.ai

# Ollama настройки (локальная установка)
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "qwen2.5:3b"

# Общие настройки LLM
DEFAULT_TEMPERATURE = 0.7
MAX_TOKENS = 2000
REQUEST_TIMEOUT = 30

# Настройки асинхронной обработки
ASYNC_CONNECTION_LIMIT = 10
ASYNC_CONNECTION_LIMIT_PER_HOST = 5
ASYNC_REQUEST_TIMEOUT = 120

# Конфигурации агентов
# PRODUCTION конфигурация (все на Claude кроме Interviewer)
AGENT_CONFIGS = {
    "interviewer": {
        "provider": "gigachat",  # Русский язык для общения с пользователем
        "model": "GigaChat",
        "temperature": 0.5,
        "max_tokens": 1000
    },
    "researcher": {
        "provider": "claude",  # Claude Sonnet + WebSearch для исследований
        "model": "sonnet",
        "temperature": 0.3,
        "max_tokens": 1500
    },
    "writer": {
        "provider": "claude",  # Claude Opus 4 - ПРЕМИУМ качество грантов
        "model": "opus",
        "temperature": 0.7,
        "max_tokens": 8000
    },
    "auditor": {
        "provider": "claude",  # Claude Sonnet для оценки и анализа
        "model": "sonnet",
        "temperature": 0.3,
        "max_tokens": 3000
    },
    "planner": {
        "provider": "claude",  # Claude Sonnet для структурирования
        "model": "sonnet",
        "temperature": 0.4,
        "max_tokens": 2000
    }
}

# АЛЬТЕРНАТИВНАЯ конфигурация (без Claude):
# AGENT_CONFIGS = {
#     "interviewer": {
#         "provider": "gigachat",
#         "model": "GigaChat",
#         "temperature": 0.5,
#         "max_tokens": 1000
#     },
#     "researcher": {
#         "provider": "perplexity",
#         "model": "sonar",
#         "temperature": 0.3,
#         "max_tokens": 1500
#     },
#     "writer": {
#         "provider": "perplexity",
#         "model": "sonar",
#         "temperature": 0.7,
#         "max_tokens": 8000
#     },
#     "auditor": {
#         "provider": "gigachat",
#         "model": "GigaChat",
#         "temperature": 0.3,
#         "max_tokens": 3000
#     },
#     "planner": {
#         "provider": "gigachat",
#         "model": "GigaChat",
#         "temperature": 0.4,
#         "max_tokens": 2000
#     }
# }

# Настройки concurrent limits для разных провайдеров
PROVIDER_CONCURRENT_LIMITS = {
    "ollama": 5,      # Ollama может обрабатывать несколько запросов параллельно
    "gigachat": 1,    # GigaChat лучше обрабатывать последовательно из-за rate limits
    "perplexity": 2,  # Perplexity умеренно параллельно
    "claude": 3       # Claude Code - хорошая параллельность
}

# Retry настройки
RETRY_ATTEMPTS = 3
RETRY_DELAY = 1.0
RATE_LIMIT_DELAY = 5.0
