#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analytics Page - GrantService Admin (v3.0)
Comprehensive analytics: –û–±—â–∞—è | –ê–≥–µ–Ω—Ç—ã | –õ–æ–≥–∏
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–∑ üìä_–û–±—â–∞—è_–∞–Ω–∞–ª–∏—Ç–∏–∫–∞.py + üìã_–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥_–ª–æ–≥–æ–≤.py
"""

import streamlit as st
import sys
import os
from pathlib import Path
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta

# PATH SETUP - Import setup_paths FIRST
sys.path.insert(0, str(Path(__file__).parent.parent))
import setup_paths

# IMPORTS
try:
    from utils.database import AdminDatabase
    from utils.postgres_helper import (
        execute_query,
        execute_query_df,
        execute_scalar,
        execute_update
    )
    from utils.logger import setup_logger, get_log_stats
    from utils.charts import create_daily_chart, create_metrics_cards
except ImportError as e:
    st.error(f"Error importing modules: {e}")
    st.info("Please run via launcher.py")
    st.stop()

# PAGE CONFIG
st.set_page_config(page_title="–ê–Ω–∞–ª–∏—Ç–∏–∫–∞", page_icon="üìä", layout="wide")
logger = setup_logger('analytics_page')

# DATABASE
@st.cache_resource
def get_database():
    """Get cached database instance"""
    return AdminDatabase()

db = get_database()

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

@st.cache_data(ttl=300)  # Cache for 5 minutes
def load_system_metrics(_db):
    """Load system metrics with caching"""
    try:
        stats = _db.get_basic_stats()

        # Calculate additional metrics
        total_users = stats.get('total_users', 0)
        completed_apps = stats.get('completed_apps', 0)

        return {
            'total_users': total_users,
            'completed_grants': completed_apps,
            'avg_nps': 0,  # TODO: implement NPS
            'conversion_rate': stats.get('conversion_rate', 0),
            'avg_processing_cost': 0,  # TODO: implement
            'avg_processing_time': 0,  # TODO: implement
            'recent_sessions': stats.get('recent_sessions', 0)
        }
    except Exception as e:
        logger.error(f"Error loading system metrics: {e}", exc_info=True)
        return {
            'total_users': 0,
            'completed_grants': 0,
            'avg_nps': 0,
            'conversion_rate': 0,
            'avg_processing_cost': 0,
            'avg_processing_time': 0,
            'recent_sessions': 0
        }

@st.cache_data(ttl=300)
def load_conversion_funnel(_db):
    """Load conversion funnel data"""
    try:
        # Funnel stages: Registration -> Interview -> Audit -> Plan -> Research -> Text -> Submit
        # Get counts for each stage
        total_users = execute_scalar("SELECT COUNT(*) FROM users") or 0

        # Mock data for now - TODO: implement real stage tracking
        funnel_data = {
            'stages': [
                '–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è',
                '–ò–Ω—Ç–µ—Ä–≤—å—é',
                '–ê—É–¥–∏—Ç',
                '–ü–ª–∞–Ω',
                '–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ',
                '–¢–µ–∫—Å—Ç',
                '–û—Ç–ø—Ä–∞–≤–∫–∞'
            ],
            'counts': [
                total_users,
                int(total_users * 0.85),
                int(total_users * 0.72),
                int(total_users * 0.65),
                int(total_users * 0.58),
                int(total_users * 0.52),
                int(total_users * 0.45)
            ]
        }

        return funnel_data
    except Exception as e:
        logger.error(f"Error loading conversion funnel: {e}", exc_info=True)
        return {
            'stages': ['–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è'],
            'counts': [0]
        }

@st.cache_data(ttl=300)
def load_daily_dynamics(_db, days=30):
    """Load daily dynamics for last N days"""
    try:
        daily_stats = _db.get_daily_stats(days=days)
        return daily_stats
    except Exception as e:
        logger.error(f"Error loading daily dynamics: {e}", exc_info=True)
        return {}

@st.cache_data(ttl=300)
def load_agents_statistics(_db):
    """Load statistics for all AI agents"""
    try:
        # TODO: implement real agent tracking
        agents_data = {
            'Interviewer': {
                'total_runs': 0,
                'successful_runs': 0,
                'avg_time': 0,
                'avg_cost': 0,
                'tokens_used': 0
            },
            'Auditor': {
                'total_runs': 0,
                'successful_runs': 0,
                'avg_time': 0,
                'avg_cost': 0,
                'avg_score': 0
            },
            'Planner': {
                'total_runs': 0,
                'successful_runs': 0,
                'avg_time': 0,
                'avg_cost': 0
            },
            'Researcher': {
                'total_runs': 0,
                'successful_runs': 0,
                'avg_time': 0,
                'avg_cost': 0,
                'tokens_used': 0
            },
            'Writer': {
                'total_runs': 0,
                'successful_runs': 0,
                'avg_time': 0,
                'avg_cost': 0,
                'avg_text_length': 0
            }
        }

        return agents_data
    except Exception as e:
        logger.error(f"Error loading agents statistics: {e}", exc_info=True)
        return {}

@st.cache_data(ttl=30)  # Cache for 30 seconds (pseudo real-time)
def load_logs(log_level='ALL', limit=100, search_text=None):
    """Load system logs"""
    try:
        log_stats = get_log_stats()

        if not log_stats.get('files'):
            return []

        # Find main log file
        log_dir = log_stats.get('log_directory')
        main_log_file = None

        for file_info in log_stats['files']:
            if 'grantservice.log' in file_info['name'].lower() or 'main.log' in file_info['name'].lower():
                main_log_file = file_info['name']
                break

        if not main_log_file and log_stats['files']:
            # Use first log file
            main_log_file = log_stats['files'][0]['name']

        if not main_log_file:
            return []

        log_path = os.path.join(log_dir, main_log_file)

        # Read log file
        with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()

        # Take last N lines
        recent_lines = lines[-limit:] if len(lines) > limit else lines

        # Filter by log level
        if log_level != 'ALL':
            filtered_lines = []
            for line in recent_lines:
                if f" - {log_level} - " in line:
                    filtered_lines.append(line)
            recent_lines = filtered_lines

        # Filter by search text
        if search_text:
            filtered_lines = []
            for line in recent_lines:
                if search_text.lower() in line.lower():
                    filtered_lines.append(line)
            recent_lines = filtered_lines

        return recent_lines

    except Exception as e:
        logger.error(f"Error loading logs: {e}", exc_info=True)
        return []

def analyze_log_errors(log_lines):
    """Analyze errors in logs"""
    errors = []
    warnings = []

    for line in log_lines:
        if " - ERROR - " in line or " - CRITICAL - " in line:
            # Extract error message
            parts = line.split(" - ERROR - ") if " - ERROR - " in line else line.split(" - CRITICAL - ")
            if len(parts) > 1:
                errors.append(parts[1].strip())
        elif " - WARNING - " in line:
            parts = line.split(" - WARNING - ")
            if len(parts) > 1:
                warnings.append(parts[1].strip())

    # Deduplicate
    unique_errors = list(set(errors))
    unique_warnings = list(set(warnings))

    return {
        'total_errors': len(errors),
        'unique_errors': len(unique_errors),
        'total_warnings': len(warnings),
        'unique_warnings': len(unique_warnings),
        'error_list': unique_errors[:10],  # Top 10
        'warning_list': unique_warnings[:10]
    }

# =============================================================================
# MAIN PAGE
# =============================================================================

# Header
chart_emoji = "üìä"
st.title(f"{chart_emoji} –ê–Ω–∞–ª–∏—Ç–∏–∫–∞")
st.markdown("–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã: –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, AI –∞–≥–µ–Ω—Ç—ã, –ª–æ–≥–∏")

st.markdown("---")

# TABS
tab1, tab2, tab3 = st.tabs([
    "üìä –û–±—â–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞",
    "ü§ñ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤",
    "üìã –õ–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã"
])

# =============================================================================
# TAB 1: GENERAL ANALYTICS
# =============================================================================
with tab1:
    st.markdown("### üìä –û–±—â–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã")

    # Load metrics
    metrics = load_system_metrics(db)

    # Metrics Dashboard (6 cards)
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("–í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", metrics['total_users'])
        st.metric("–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –≥—Ä–∞–Ω—Ç–æ–≤", metrics['completed_grants'])

    with col2:
        st.metric("–°—Ä–µ–¥–Ω–∏–π NPS", f"{metrics['avg_nps']}/10")
        conversion_emoji = "üìà"
        st.metric(f"{conversion_emoji} –ö–æ–Ω–≤–µ—Ä—Å–∏—è", f"{metrics['conversion_rate']}%")

    with col3:
        st.metric("–°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å", f"${metrics['avg_processing_cost']:.2f}")
        clock_emoji = "‚è±Ô∏è"
        st.metric(f"{clock_emoji} –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{metrics['avg_processing_time']} —á")

    st.markdown("---")

    # Conversion Funnel
    st.markdown("#### üìä –í–æ—Ä–æ–Ω–∫–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏")

    funnel_data = load_conversion_funnel(db)

    fig_funnel = go.Figure(go.Funnel(
        y=funnel_data['stages'],
        x=funnel_data['counts'],
        textposition="inside",
        textinfo="value+percent initial",
        marker={
            "color": ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b", "#e377c2"]
        }
    ))

    fig_funnel.update_layout(
        title="–í–æ—Ä–æ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —ç—Ç–∞–ø–∞–º",
        height=500
    )

    st.plotly_chart(fig_funnel, use_container_width=True)

    st.markdown("---")

    # Daily Dynamics
    st.markdown("#### üìà –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏")

    col1, col2 = st.columns([1, 1])

    with col1:
        period_days = st.selectbox(
            "–ü–µ—Ä–∏–æ–¥",
            [7, 14, 30, 60, 90],
            format_func=lambda x: f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ {x} –¥–Ω–µ–π",
            index=2
        )

    with col2:
        metric_type = st.selectbox(
            "–ú–µ—Ç—Ä–∏–∫–∞",
            ["–°–µ—Å—Å–∏–∏", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏", "–ì—Ä–∞–Ω—Ç—ã"]
        )

    daily_data = load_daily_dynamics(db, days=period_days)

    if daily_data:
        # Create DataFrame
        df_daily = pd.DataFrame(list(daily_data.items()), columns=['–î–∞—Ç–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
        df_daily['–î–∞—Ç–∞'] = pd.to_datetime(df_daily['–î–∞—Ç–∞'])
        df_daily = df_daily.sort_values('–î–∞—Ç–∞')

        # Create line chart
        fig_daily = px.line(
            df_daily,
            x='–î–∞—Ç–∞',
            y='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
            title=f"{metric_type} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {period_days} –¥–Ω–µ–π",
            markers=True
        )

        fig_daily.update_layout(
            xaxis_title="–î–∞—Ç–∞",
            yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
            hovermode='x unified',
            height=400
        )

        st.plotly_chart(fig_daily, use_container_width=True)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏")

    st.markdown("---")

    # Top Statistics
    st.markdown("#### üèÜ –¢–æ–ø-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**–°–∞–º—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (Top 10)**")
        st.info("TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å —Ç–æ–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")

    with col2:
        st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —á–∞—Å–∞–º –¥–Ω—è**")
        st.info("TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ —á–∞—Å–∞–º")

    st.markdown("---")

    # Export
    st.markdown("#### üì• –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("üìä –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ CSV", use_container_width=True):
            stats_df = pd.DataFrame([metrics])
            csv = stats_df.to_csv(index=False)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            st.download_button(
                label="üíæ –°–∫–∞—á–∞—Ç—å CSV",
                data=csv,
                file_name=f"analytics_stats_{timestamp}.csv",
                mime="text/csv",
                use_container_width=True
            )

    with col2:
        if st.button("üìà –≠–∫—Å–ø–æ—Ä—Ç –≥—Ä–∞—Ñ–∏–∫–æ–≤", use_container_width=True):
            st.info("–≠–∫—Å–ø–æ—Ä—Ç –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ Plotly (–∫–Ω–æ–ø–∫–∞ üì∑ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ)")

# =============================================================================
# TAB 2: AGENTS ANALYTICS
# =============================================================================
with tab2:
    st.markdown("### ü§ñ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ AI –∞–≥–µ–Ω—Ç–∞–º")

    # Load agents data
    agents_data = load_agents_statistics(db)

    # Overall Metrics
    col1, col2, col3, col4 = st.columns(4)

    total_runs = sum(agent.get('total_runs', 0) for agent in agents_data.values())
    total_successful = sum(agent.get('successful_runs', 0) for agent in agents_data.values())
    total_cost = sum(agent.get('avg_cost', 0) for agent in agents_data.values())
    avg_time = sum(agent.get('avg_time', 0) for agent in agents_data.values()) / max(len(agents_data), 1)

    with col1:
        lightning_emoji = "‚ö°"
        st.metric(f"{lightning_emoji} –í—Å–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π", total_runs)

    with col2:
        clock_emoji = "‚è±Ô∏è"
        st.metric(f"{clock_emoji} –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{avg_time:.1f} –º–∏–Ω")

    with col3:
        success_rate = (total_successful / max(total_runs, 1)) * 100
        checkmark_emoji = "‚úÖ"
        st.metric(f"{checkmark_emoji} –£—Å–ø–µ—à–Ω—ã—Ö", f"{success_rate:.1f}%")

    with col4:
        money_emoji = "üí∞"
        st.metric(f"{money_emoji} –†–∞—Å—Ö–æ–¥—ã", f"${total_cost:.2f}")

    st.markdown("---")

    # Agent Selector
    st.markdown("#### üîç –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–≥–µ–Ω—Ç—É")

    agent_name = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞",
        ["–í—Å–µ"] + list(agents_data.keys())
    )

    if agent_name == "–í—Å–µ":
        # Show comparison charts

        # Agent comparison table
        st.markdown("**–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∞–≥–µ–Ω—Ç–æ–≤**")

        agent_df = pd.DataFrame([
            {
                '–ê–≥–µ–Ω—Ç': name,
                '–í—Å–µ–≥–æ –∑–∞–ø—É—Å–∫–æ–≤': data.get('total_runs', 0),
                '–£—Å–ø–µ—à–Ω—ã—Ö': data.get('successful_runs', 0),
                '–£—Å–ø–µ—à–Ω–æ—Å—Ç—å %': f"{(data.get('successful_runs', 0) / max(data.get('total_runs', 1), 1)) * 100:.1f}",
                '–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è (–º–∏–Ω)': data.get('avg_time', 0),
                '–°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å ($)': f"{data.get('avg_cost', 0):.2f}",
                '–¢–æ–∫–µ–Ω—ã': data.get('tokens_used', 0)
            }
            for name, data in agents_data.items()
        ])

        st.dataframe(agent_df, use_container_width=True)

        st.markdown("---")

        # Agent comparison charts
        col1, col2 = st.columns(2)

        with col1:
            # Processing time comparison
            st.markdown("**‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ –∞–≥–µ–Ω—Ç–∞–º**")

            time_data = pd.DataFrame([
                {'–ê–≥–µ–Ω—Ç': name, '–í—Ä–µ–º—è (–º–∏–Ω)': data.get('avg_time', 0)}
                for name, data in agents_data.items()
            ])

            fig_time = px.bar(
                time_data,
                x='–ê–≥–µ–Ω—Ç',
                y='–í—Ä–µ–º—è (–º–∏–Ω)',
                color='–í—Ä–µ–º—è (–º–∏–Ω)',
                color_continuous_scale='Blues'
            )

            st.plotly_chart(fig_time, use_container_width=True)

        with col2:
            # Cost comparison
            st.markdown("**üí∞ –†–∞—Å—Ö–æ–¥—ã –ø–æ –∞–≥–µ–Ω—Ç–∞–º**")

            cost_data = pd.DataFrame([
                {'–ê–≥–µ–Ω—Ç': name, '–°—Ç–æ–∏–º–æ—Å—Ç—å': data.get('avg_cost', 0)}
                for name, data in agents_data.items()
            ])

            fig_cost = px.pie(
                cost_data,
                values='–°—Ç–æ–∏–º–æ—Å—Ç—å',
                names='–ê–≥–µ–Ω—Ç',
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞—Å—Ö–æ–¥–æ–≤'
            )

            st.plotly_chart(fig_cost, use_container_width=True)

    else:
        # Show specific agent details
        agent_info = agents_data.get(agent_name, {})

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("–í—Å–µ–≥–æ –∑–∞–ø—É—Å–∫–æ–≤", agent_info.get('total_runs', 0))
            st.metric("–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤", agent_info.get('successful_runs', 0))

        with col2:
            success_pct = (agent_info.get('successful_runs', 0) / max(agent_info.get('total_runs', 1), 1)) * 100
            st.metric("–£—Å–ø–µ—à–Ω–æ—Å—Ç—å", f"{success_pct:.1f}%")
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{agent_info.get('avg_time', 0):.1f} –º–∏–Ω")

        with col3:
            st.metric("–°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å", f"${agent_info.get('avg_cost', 0):.2f}")
            st.metric("–¢–æ–∫–µ–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ", agent_info.get('tokens_used', 0))

        if agent_name == "Auditor":
            st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{agent_info.get('avg_score', 0):.1f}/10")

        if agent_name == "Writer":
            st.metric("–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞", f"{agent_info.get('avg_text_length', 0)} —Å–∏–º–≤–æ–ª–æ–≤")

    st.markdown("---")

    # Provider Comparison (for Researcher)
    st.markdown("#### üí∞ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ LLM")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**GigaChat**")
        st.metric("–ó–∞–ø—Ä–æ—Å–æ–≤", 0)
        st.metric("–°—Ç–æ–∏–º–æ—Å—Ç—å", "$0.00")
        st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", "0 —Å–µ–∫")

    with col2:
        st.markdown("**GPT-4**")
        st.metric("–ó–∞–ø—Ä–æ—Å–æ–≤", 0)
        st.metric("–°—Ç–æ–∏–º–æ—Å—Ç—å", "$0.00")
        st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", "0 —Å–µ–∫")

# =============================================================================
# TAB 3: SYSTEM LOGS
# =============================================================================
with tab3:
    st.markdown("### üìã –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ª–æ–≥–æ–≤ —Å–∏—Å—Ç–µ–º—ã (Real-time)")

    # Log Controls
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        log_level = st.selectbox(
            "–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–æ–≤",
            ["ALL", "INFO", "WARNING", "ERROR", "CRITICAL"]
        )

    with col2:
        auto_refresh = st.checkbox("üîÑ –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (30 —Å–µ–∫)", value=False)

    with col3:
        search_text = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É")

    with col4:
        lines_count = st.number_input(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫",
            min_value=10,
            max_value=1000,
            value=100,
            step=10
        )

    st.markdown("---")

    # Log Files Info
    log_stats = get_log_stats()

    if not log_stats.get('error'):
        col1, col2, col3 = st.columns(3)

        with col1:
            folder_emoji = "üìÅ"
            st.metric(f"{folder_emoji} –ü–∞–ø–∫–∞ –ª–æ–≥–æ–≤", "")
            st.code(log_stats.get('log_directory', 'N/A'))

        with col2:
            st.metric("–§–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤", len(log_stats.get('files', [])))

        with col3:
            total_size = log_stats.get('total_size', 0)
            total_size_mb = total_size / (1024 * 1024)
            st.metric("–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä", f"{total_size_mb:.1f} MB")

    st.markdown("---")

    # Load and display logs
    st.markdown("#### üìÑ –õ–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã")

    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –ª–æ–≥–∏", use_container_width=True):
        st.cache_data.clear()
        st.rerun()

    log_lines = load_logs(log_level=log_level, limit=lines_count, search_text=search_text)

    if log_lines:
        # Error analysis
        error_analysis = analyze_log_errors(log_lines)

        if error_analysis['total_errors'] > 0 or error_analysis['total_warnings'] > 0:
            col1, col2 = st.columns(2)

            with col1:
                if error_analysis['total_errors'] > 0:
                    error_emoji = "‚ùå"
                    st.error(f"{error_emoji} –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {error_analysis['total_errors']} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {error_analysis['unique_errors']})")

            with col2:
                if error_analysis['total_warnings'] > 0:
                    warning_emoji = "‚ö†Ô∏è"
                    st.warning(f"{warning_emoji} –ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {error_analysis['total_warnings']} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {error_analysis['unique_warnings']})")

        # Display logs with color coding
        log_container = st.container()

        with log_container:
            log_text = ""

            for line in log_lines:
                # Color coding based on level
                if " - ERROR - " in line or " - CRITICAL - " in line:
                    red_circle = "üî¥"
                    log_text += f"{red_circle} {line}"
                elif " - WARNING - " in line:
                    yellow_circle = "üü°"
                    log_text += f"{yellow_circle} {line}"
                elif " - INFO - " in line:
                    green_circle = "üü¢"
                    log_text += f"{green_circle} {line}"
                elif " - DEBUG - " in line:
                    blue_circle = "üîµ"
                    log_text += f"{blue_circle} {line}"
                else:
                    white_circle = "‚ö™"
                    log_text += f"{white_circle} {line}"

            st.code(log_text, language=None)

        info_emoji = "üìä"
        st.info(f"{info_emoji} –û—Ç–æ–±—Ä–∞–∂–µ–Ω–æ: {len(log_lines)} —Å—Ç—Ä–æ–∫")

    else:
        st.info("üìù –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä—É –∏–ª–∏ –ª–æ–≥–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

    st.markdown("---")

    # Error Analysis Detail
    if log_lines:
        st.markdown("#### ‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫")

        error_analysis = analyze_log_errors(log_lines)

        if error_analysis['error_list']:
            st.markdown("**–¢–æ–ø-10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫:**")
            for i, error in enumerate(error_analysis['error_list'], 1):
                st.code(f"{i}. {error}", language=None)
        else:
            checkmark_emoji = "‚úÖ"
            st.success(f"{checkmark_emoji} –û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

    st.markdown("---")

    # Log Actions
    st.markdown("#### üõ†Ô∏è –î–µ–π—Å—Ç–≤–∏—è —Å –ª–æ–≥–∞–º–∏")

    col1, col2, col3 = st.columns(3)

    with col1:
        download_emoji = "üì•"
        if st.button(f"{download_emoji} –°–∫–∞—á–∞—Ç—å –ª–æ–≥–∏", use_container_width=True):
            if log_lines:
                log_content = "".join(log_lines)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                st.download_button(
                    label="üíæ –°–∫–∞—á–∞—Ç—å TXT",
                    data=log_content,
                    file_name=f"grantservice_logs_{timestamp}.txt",
                    mime="text/plain",
                    use_container_width=True
                )
            else:
                st.warning("–ù–µ—Ç –ª–æ–≥–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")

    with col2:
        trash_emoji = "üóëÔ∏è"
        if st.button(f"{trash_emoji} –û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥–∏", use_container_width=True):
            warning_emoji = "‚ö†Ô∏è"
            st.warning(f"{warning_emoji} –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –ª–æ–≥–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")

    with col3:
        test_emoji = "üß™"
        if st.button(f"{test_emoji} –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –æ—à–∏–±–∫—É", use_container_width=True):
            logger.error("üß™ –¢–µ—Å—Ç–æ–≤–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")
            logger.warning("‚ö†Ô∏è –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ")
            logger.info("‚ÑπÔ∏è –¢–µ—Å—Ç–æ–≤–æ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
            checkmark_emoji = "‚úÖ"
            st.success(f"{checkmark_emoji} –¢–µ—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω—ã. –û–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.")

# =============================================================================
# FOOTER
# =============================================================================

st.markdown("---")

footer_text = "–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∞"
rocket_emoji = "üöÄ"
st.info(f"{rocket_emoji} {footer_text} | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–∑ –∞—Ä—Ö–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

# Auto-refresh logic for logs tab
if auto_refresh and st.session_state.get('selected_tab') == 2:
    import time
    time.sleep(30)
    st.rerun()

# Log page view
logger.info("üìä Analytics page loaded successfully")
