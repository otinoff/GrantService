#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Artifact Exporter - —ç–∫—Å–ø–æ—Ä—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏ –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
- TXT - —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª (—á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π)
- PDF - PDF –¥–æ–∫—É–º–µ–Ω—Ç (–¥–ª—è –ø–µ—á–∞—Ç–∏)
- DOCX - Word –¥–æ–∫—É–º–µ–Ω—Ç (–¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
"""

import logging
import io
from typing import Dict, Any, BinaryIO
from datetime import datetime

logger = logging.getLogger(__name__)


class ArtifactExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≥—Ä–∞–Ω—Ç–æ–≤–æ–π –∑–∞—è–≤–∫–∏"""

    def __init__(self, lifecycle_data: Dict[str, Any]):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞

        Args:
            lifecycle_data: –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ—Ç GrantLifecycleManager
        """
        self.data = lifecycle_data
        self.anketa_id = lifecycle_data.get('anketa_id', 'UNKNOWN')
        self.metadata = lifecycle_data.get('metadata', {})
        self.artifacts = lifecycle_data.get('artifacts', {})

    def export_to_txt(self) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç

        Returns:
            –°—Ç—Ä–æ–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –≤—Å–µ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        """
        lines = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        lines.append("=" * 80)
        lines.append(f"–ì–†–ê–ù–¢–û–í–ê–Ø –ó–ê–Ø–í–ö–ê")
        lines.append(f"ID: {self.anketa_id}")
        lines.append("=" * 80)
        lines.append("")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        lines.append("üìã –ú–ï–¢–ê–î–ê–ù–ù–´–ï")
        lines.append("-" * 80)
        username = self.metadata.get('username', 'Unknown')
        first_name = self.metadata.get('first_name', '')
        last_name = self.metadata.get('last_name', '')
        full_name = f"{first_name} {last_name}".strip() or "Unknown"

        lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: @{username} ({full_name})")
        lines.append(f"Telegram ID: {self.metadata.get('telegram_id', 'N/A')}")
        lines.append(f"–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã: {self.metadata.get('session_started', 'N/A')}")
        lines.append(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {self.metadata.get('session_updated', 'N/A')}")
        lines.append(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {self.data.get('progress', 0):.0f}%")
        lines.append(f"–¢–µ–∫—É—â–∏–π —ç—Ç–∞–ø: {self.data.get('current_stage', 'N/A')}")
        lines.append("")

        # –≠—Ç–∞–ø 1: –ò–Ω—Ç–µ—Ä–≤—å—é
        interview = self.artifacts.get('interview', {})
        if interview.get('status') == 'completed':
            lines.append("üìù –≠–¢–ê–ü 1: –ò–ù–¢–ï–†–í–¨–Æ (–ê–ù–ö–ï–¢–ê)")
            lines.append("-" * 80)
            lines.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {interview.get('questions_count', 0)}")
            lines.append(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {interview.get('completed_at', 'N/A')}")
            lines.append("")

            for qa in interview.get('data', []):
                lines.append(f"Q{qa.get('question_id', '?')}: {qa.get('question_text', '')}")
                lines.append(f"A: {qa.get('answer', '')}")
                lines.append("")
        else:
            lines.append("üìù –≠–¢–ê–ü 1: –ò–ù–¢–ï–†–í–¨–Æ - –ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
            lines.append("")

        # –≠—Ç–∞–ø 2: –ê—É–¥–∏—Ç
        auditor = self.artifacts.get('auditor', {})
        if auditor.get('status') == 'completed':
            lines.append("üîç –≠–¢–ê–ü 2: –ê–£–î–ò–¢ –ü–†–û–ï–ö–¢–ê")
            lines.append("-" * 80)
            lines.append(f"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {auditor.get('score', 'N/A')}/10")
            lines.append(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {auditor.get('completed_at', 'N/A')}")
            lines.append("")

            if auditor.get('analysis'):
                lines.append("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:")
                lines.append(str(auditor.get('analysis', '')))
                lines.append("")

            if auditor.get('feasibility'):
                lines.append("–û—Ü–µ–Ω–∫–∞ —Ä–µ–∞–ª–∏–∑—É–µ–º–æ—Å—Ç–∏:")
                lines.append(str(auditor.get('feasibility', '')))
                lines.append("")

            if auditor.get('risks'):
                lines.append("–§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞:")
                lines.append(str(auditor.get('risks', '')))
                lines.append("")

            if auditor.get('recommendations'):
                lines.append("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                lines.append(str(auditor.get('recommendations', '')))
                lines.append("")
        else:
            lines.append("üîç –≠–¢–ê–ü 2: –ê–£–î–ò–¢ - –ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
            lines.append("")

        # –≠—Ç–∞–ø 3: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
        researcher = self.artifacts.get('researcher', {})
        if researcher.get('status') == 'completed':
            lines.append("üìä –≠–¢–ê–ü 3: –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï")
            lines.append("-" * 80)
            lines.append(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {researcher.get('completed_at', 'N/A')}")
            lines.append("")

            if researcher.get('content'):
                lines.append("–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:")
                lines.append(str(researcher.get('content', '')))
                lines.append("")

            if researcher.get('market'):
                lines.append("–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞:")
                lines.append(str(researcher.get('market', '')))
                lines.append("")

            if researcher.get('competitors'):
                lines.append("–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤:")
                lines.append(str(researcher.get('competitors', '')))
                lines.append("")

            if researcher.get('sources'):
                lines.append("–ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
                lines.append(str(researcher.get('sources', '')))
                lines.append("")
        else:
            lines.append("üìä –≠–¢–ê–ü 3: –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï - –ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
            lines.append("")

        # –≠—Ç–∞–ø 4: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        planner = self.artifacts.get('planner', {})
        if planner.get('status') == 'completed':
            lines.append("üìã –≠–¢–ê–ü 4: –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´")
            lines.append("-" * 80)
            lines.append(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {planner.get('completed_at', 'N/A')}")
            lines.append("")

            if planner.get('structure'):
                lines.append("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞—è–≤–∫–∏:")
                lines.append(str(planner.get('structure', '')))
                lines.append("")

            if planner.get('sections'):
                lines.append("–°–µ–∫—Ü–∏–∏:")
                sections = planner.get('sections', [])
                if isinstance(sections, list):
                    for i, section in enumerate(sections, 1):
                        lines.append(f"{i}. {section}")
                else:
                    lines.append(str(sections))
                lines.append("")

            if planner.get('recommendations'):
                lines.append("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                lines.append(str(planner.get('recommendations', '')))
                lines.append("")
        else:
            lines.append("üìã –≠–¢–ê–ü 4: –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï - –ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
            lines.append("")

        # –≠—Ç–∞–ø 5: –§–∏–Ω–∞–ª—å–Ω—ã–π –≥—Ä–∞–Ω—Ç
        writer = self.artifacts.get('writer', {})
        if writer.get('status') == 'completed':
            lines.append("‚úçÔ∏è –≠–¢–ê–ü 5: –§–ò–ù–ê–õ–¨–ù–´–ô –ì–†–ê–ù–¢")
            lines.append("=" * 80)
            lines.append(f"ID –ì—Ä–∞–Ω—Ç–∞: {writer.get('grant_id', 'N/A')}")
            lines.append(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {writer.get('title', 'N/A')}")
            lines.append(f"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {writer.get('quality_score', 'N/A')}/10")
            lines.append(f"LLM: {writer.get('llm_provider', 'N/A')} ({writer.get('model', 'N/A')})")
            lines.append(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {writer.get('completed_at', 'N/A')}")
            lines.append("=" * 80)
            lines.append("")

            # –°–µ–∫—Ü–∏–∏ –≥—Ä–∞–Ω—Ç–∞
            sections = writer.get('sections', [])
            if sections:
                lines.append("–°–û–î–ï–†–ñ–ê–ù–ò–ï –ì–†–ê–ù–¢–ê –ü–û –°–ï–ö–¶–ò–Ø–ú:")
                lines.append("")
                for section in sections:
                    if isinstance(section, dict):
                        title = section.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                        content = section.get('content', '')
                        lines.append(f"## {title}")
                        lines.append("-" * 80)
                        lines.append(content)
                        lines.append("")
                    else:
                        lines.append(str(section))
                        lines.append("")

            # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≥—Ä–∞–Ω—Ç–∞
            if writer.get('content'):
                lines.append("")
                lines.append("–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢ –ì–†–ê–ù–¢–ê:")
                lines.append("=" * 80)
                lines.append(writer.get('content', ''))
                lines.append("")
        else:
            lines.append("‚úçÔ∏è –≠–¢–ê–ü 5: –§–ò–ù–ê–õ–¨–ù–´–ô –ì–†–ê–ù–¢ - –ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
            lines.append("")

        # –§—É—Ç–µ—Ä
        lines.append("")
        lines.append("=" * 80)
        lines.append(f"–î–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"GrantService - AI-Powered Grant Application System")
        lines.append("=" * 80)

        return "\n".join(lines)

    def export_to_pdf(self) -> bytes:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ PDF —Ñ–æ—Ä–º–∞—Ç

        Returns:
            –ë–∞–π—Ç—ã PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        try:
            from reportlab.lib.pagesizes import A4
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import cm
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            from reportlab.lib.enums import TA_LEFT, TA_CENTER

            # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞
            try:
                pdfmetrics.registerFont(TTFont('DejaVuSans', 'DejaVuSans.ttf'))
                font_name = 'DejaVuSans'
            except:
                # Fallback –Ω–∞ –±–∞–∑–æ–≤—ã–π —à—Ä–∏—Ñ—Ç
                font_name = 'Helvetica'

            # –°–æ–∑–¥–∞–Ω–∏–µ PDF –≤ –ø–∞–º—è—Ç–∏
            buffer = io.BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=A4)

            # –°—Ç–∏–ª–∏
            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontName=font_name,
                fontSize=16,
                alignment=TA_CENTER
            )
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontName=font_name,
                fontSize=14
            )
            normal_style = ParagraphStyle(
                'CustomNormal',
                parent=styles['Normal'],
                fontName=font_name,
                fontSize=10
            )

            # –°–±–æ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            story = []

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            story.append(Paragraph("–ì–†–ê–ù–¢–û–í–ê–Ø –ó–ê–Ø–í–ö–ê", title_style))
            story.append(Paragraph(f"ID: {self.anketa_id}", normal_style))
            story.append(Spacer(1, 0.5*cm))

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–∫—Å–ø–æ—Ä—Ç –∫–∞–∫ –æ—Å–Ω–æ–≤—É
            txt_content = self.export_to_txt()

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ PDF
            for line in txt_content.split('\n'):
                if line.strip():
                    if line.startswith('=') or line.startswith('-'):
                        story.append(Spacer(1, 0.3*cm))
                    elif line.startswith('##'):
                        story.append(Paragraph(line.replace('##', ''), heading_style))
                    elif any(line.startswith(emoji) for emoji in ['üìã', 'üìù', 'üîç', 'üìä', '‚úçÔ∏è']):
                        story.append(Spacer(1, 0.5*cm))
                        story.append(Paragraph(line, heading_style))
                    else:
                        story.append(Paragraph(line, normal_style))

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF
            doc.build(story)

            pdf_bytes = buffer.getvalue()
            buffer.close()

            return pdf_bytes

        except ImportError:
            logger.error("reportlab not installed. Install: pip install reportlab")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é –∫–∞–∫ fallback
            return self.export_to_txt().encode('utf-8')
        except Exception as e:
            logger.error(f"Error exporting to PDF: {e}")
            return self.export_to_txt().encode('utf-8')

    def export_to_docx(self) -> bytes:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ DOCX —Ñ–æ—Ä–º–∞—Ç

        Returns:
            –ë–∞–π—Ç—ã DOCX –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        try:
            from docx import Document
            from docx.shared import Pt, RGBColor
            from docx.enum.text import WD_PARAGRAPH_ALIGNMENT

            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            doc = Document()

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = doc.add_heading('–ì–†–ê–ù–¢–û–í–ê–Ø –ó–ê–Ø–í–ö–ê', 0)
            title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

            subtitle = doc.add_paragraph(f'ID: {self.anketa_id}')
            subtitle.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            doc.add_heading('üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ', level=1)

            username = self.metadata.get('username', 'Unknown')
            first_name = self.metadata.get('first_name', '')
            last_name = self.metadata.get('last_name', '')
            full_name = f"{first_name} {last_name}".strip() or "Unknown"

            doc.add_paragraph(f'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: @{username} ({full_name})')
            doc.add_paragraph(f'Telegram ID: {self.metadata.get("telegram_id", "N/A")}')
            doc.add_paragraph(f'–ü—Ä–æ–≥—Ä–µ—Å—Å: {self.data.get("progress", 0):.0f}%')

            # –≠—Ç–∞–ø—ã
            for stage_name, stage_emoji, stage_key in [
                ('–ò–ù–¢–ï–†–í–¨–Æ (–ê–ù–ö–ï–¢–ê)', 'üìù', 'interview'),
                ('–ê–£–î–ò–¢ –ü–†–û–ï–ö–¢–ê', 'üîç', 'auditor'),
                ('–ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï', 'üìä', 'researcher'),
                ('–ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´', 'üìã', 'planner'),
                ('–§–ò–ù–ê–õ–¨–ù–´–ô –ì–†–ê–ù–¢', '‚úçÔ∏è', 'writer')
            ]:
                artifact = self.artifacts.get(stage_key, {})

                doc.add_page_break()
                doc.add_heading(f'{stage_emoji} {stage_name}', level=1)

                if artifact.get('status') == 'completed':
                    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
                    if stage_key == 'interview':
                        doc.add_paragraph(f"–í–æ–ø—Ä–æ—Å–æ–≤: {artifact.get('questions_count', 0)}")
                        for qa in artifact.get('data', []):
                            q = doc.add_paragraph()
                            q.add_run(f"Q{qa.get('question_id', '?')}: ").bold = True
                            q.add_run(qa.get('question_text', ''))

                            a = doc.add_paragraph()
                            a.add_run('A: ').bold = True
                            a.add_run(qa.get('answer', ''))

                    elif stage_key == 'auditor':
                        doc.add_paragraph(f"–û—Ü–µ–Ω–∫–∞: {artifact.get('score', 'N/A')}/10")
                        if artifact.get('analysis'):
                            doc.add_paragraph(str(artifact.get('analysis', '')))

                    elif stage_key == 'writer':
                        doc.add_paragraph(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {artifact.get('title', 'N/A')}")
                        doc.add_paragraph(f"–û—Ü–µ–Ω–∫–∞: {artifact.get('quality_score', 'N/A')}/10")

                        # –°–µ–∫—Ü–∏–∏ –≥—Ä–∞–Ω—Ç–∞
                        for section in artifact.get('sections', []):
                            if isinstance(section, dict):
                                doc.add_heading(section.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'), level=2)
                                doc.add_paragraph(section.get('content', ''))

                        # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
                        if artifact.get('content'):
                            doc.add_heading('–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≥—Ä–∞–Ω—Ç–∞', level=2)
                            doc.add_paragraph(artifact.get('content', ''))

                    else:
                        # –û–±—â–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö —ç—Ç–∞–ø–æ–≤
                        for key, value in artifact.items():
                            if key not in ['status', 'completed_at'] and value:
                                doc.add_paragraph(f'{key}: {value}')
                else:
                    doc.add_paragraph('–≠—Ç–∞–ø –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω')

            # –§—É—Ç–µ—Ä
            doc.add_page_break()
            footer = doc.add_paragraph(f'–î–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
            footer.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å
            buffer = io.BytesIO()
            doc.save(buffer)
            docx_bytes = buffer.getvalue()
            buffer.close()

            return docx_bytes

        except ImportError:
            logger.error("python-docx not installed. Install: pip install python-docx")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é –∫–∞–∫ fallback
            return self.export_to_txt().encode('utf-8')
        except Exception as e:
            logger.error(f"Error exporting to DOCX: {e}")
            return self.export_to_txt().encode('utf-8')


def export_artifact(lifecycle_data: Dict[str, Any], format: str = 'txt') -> bytes:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç

    Args:
        lifecycle_data: –î–∞–Ω–Ω—ã–µ –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ—Ç GrantLifecycleManager
        format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ ('txt', 'pdf', 'docx')

    Returns:
        –ë–∞–π—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    """
    exporter = ArtifactExporter(lifecycle_data)

    if format.lower() == 'pdf':
        return exporter.export_to_pdf()
    elif format.lower() == 'docx':
        return exporter.export_to_docx()
    else:  # txt –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return exporter.export_to_txt().encode('utf-8')
